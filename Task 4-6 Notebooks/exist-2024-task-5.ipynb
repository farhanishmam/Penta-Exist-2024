{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Preamble: Install and Import Packages"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:15:16.598715Z","iopub.status.busy":"2024-05-06T18:15:16.597882Z","iopub.status.idle":"2024-05-06T18:15:25.498522Z","shell.execute_reply":"2024-05-06T18:15:25.497700Z","shell.execute_reply.started":"2024-05-06T18:15:16.598676Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\pachinkomachine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import Resize\n","from torchvision.io import read_image, ImageReadMode\n","from multilingual_clip import Config_MCLIP\n","import open_clip\n","import json\n","import pandas as pd\n","import random\n","from pathlib import Path\n","import cv2\n","import numpy as np\n","import transformers as hf\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score, classification_report\n","from PIL import Image\n","import os\n","import gc\n","import time\n","import math\n","from schedulefree import AdamWScheduleFree"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:15:44.872551Z","iopub.status.busy":"2024-05-06T18:15:44.871975Z","iopub.status.idle":"2024-05-06T18:15:44.877783Z","shell.execute_reply":"2024-05-06T18:15:44.876660Z","shell.execute_reply.started":"2024-05-06T18:15:44.872513Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4.40.1\n"]},{"data":{"text/plain":["<torch.autograd.anomaly_mode.set_detect_anomaly at 0x13d554205d0>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["print(hf.__version__)\n","torch.autograd.set_detect_anomaly(True)"]},{"cell_type":"markdown","metadata":{},"source":["# Initialise the Configuration and Random Seeds"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:38.260806Z","iopub.status.busy":"2024-05-06T18:18:38.259845Z","iopub.status.idle":"2024-05-06T18:18:38.990037Z","shell.execute_reply":"2024-05-06T18:18:38.989149Z","shell.execute_reply.started":"2024-05-06T18:18:38.260764Z"},"trusted":true},"outputs":[],"source":["_text_model_config = {}\n","\n","_image_model_config = {\n","    \"attention_probs_dropout_prob\": 0.0,\n","    \"encoder_stride\": 16,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.0,\n","    \"hidden_size\": 768,\n","    \"image_size\": 224,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"layer_norm_eps\": 1e-12,\n","    \"num_attention_heads\": 12,\n","    \"num_channels\": 3,\n","    \"num_hidden_layers\": 0,\n","    \"patch_size\": 16,\n","    \"qkv_bias\": True,\n","}\n","\n","# Dual encoder/Concat\n","tokeniser_model_id = 'xlm-roberta-base'\n","text_model_id = 'xlm-roberta-base'\n","image_model_id = 'google/vit-base-patch16-224-in21k'\n","\n","# CLIP\n","# multimodal_model_id = 'openai/clip-vit-base-patch32'\n","\n","# M-CLIP\n","# tokeniser_model_id = 'M-CLIP/XLM-Roberta-Large-Vit-B-16Plus'\n","# text_model_id = 'M-CLIP/XLM-Roberta-Large-Vit-B-16Plus'\n","# image_model_id = 'ViT-B-16-plus-240'\n","image_training_id = 'laion400m_e32'\n","\n","# ViLT\n","multimodal_model_id = 'dandelin/vilt-b32-mlm'\n","\n","\n","class CFG:\n","    use_multimodal = True\n","    use_dualencoder = False\n","    split_lang = False\n","    save_models = False\n","    use_lstm = False\n","    use_attn = False\n","    use_mask_split = False\n","    use_modal_attn = False\n","    is_mclip = False\n","    init_weights = False\n","    tokeniser_model_id = tokeniser_model_id\n","    text_model_id = text_model_id\n","    image_model_id = image_model_id\n","    multimodal_model_id = multimodal_model_id\n","    image_training_id = image_training_id\n","    text_model_config = hf.AutoConfig.from_pretrained(text_model_id) if not 'M-CLIP' in text_model_id else None\n","    image_model_config = hf.AutoConfig.from_pretrained(image_model_id) if not 'M-CLIP' in text_model_id else None\n","    multimodal_model_config = hf.AutoConfig.from_pretrained(multimodal_model_id, text_config=_text_model_config, vision_config=_image_model_config)\n","    images_base_path = Path(f'EXIST 2024 Lab/EXIST 2024 Memes Dataset/training/memes')\n","    images_base_path_test = Path('EXIST 2024 Lab/EXIST 2024 Memes Dataset/test/memes')\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    debug = True\n","    print_freq = 300\n","    apex = True # for faster training\n","    epochs = 10\n","    learning_rate = 2e-4  # for adam optimizer\n","    eps = 1e-6\n","    betas = (0.9, 0.999)  # for adam optimizer\n","    batch_size = 32\n","    max_len = 512\n","    weight_decay = 0.01  # for adam optimizer regulaization parameter\n","    gradient_accumulation_steps = 1\n","    max_grad_norm = 1000\n","    seed = 42\n","    train = True\n","    num_class = 3\n","    mlp_hidden_size = 256\n","    mlp_hidden_layers = 0\n","    mlp_dropout = 0.1\n","    mlp_grad_clip = 1.0\n","    mlp_init_range = 0.2\n","    mlp_attn_dim = 256"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:16:08.601112Z","iopub.status.busy":"2024-05-06T18:16:08.600732Z","iopub.status.idle":"2024-05-06T18:16:08.610179Z","shell.execute_reply":"2024-05-06T18:16:08.609275Z","shell.execute_reply.started":"2024-05-06T18:16:08.601082Z"},"trusted":true},"outputs":[],"source":["def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(CFG.seed)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:16:13.511690Z","iopub.status.busy":"2024-05-06T18:16:13.511328Z","iopub.status.idle":"2024-05-06T18:16:13.542982Z","shell.execute_reply":"2024-05-06T18:16:13.542212Z","shell.execute_reply.started":"2024-05-06T18:16:13.511661Z"},"trusted":true},"outputs":[],"source":["class MultilingualCLIP(hf.PreTrainedModel):\n","    config_class = Config_MCLIP.MCLIPConfig\n","\n","    def __init__(self, config, *args, **kwargs):\n","        super().__init__(config, *args, **kwargs)\n","        self.transformer = hf.AutoModel.from_pretrained(config.modelBase, cache_dir=kwargs.get(\"cache_dir\"))\n","        self.LinearTransformation = torch.nn.Linear(in_features=config.transformerDimensions,\n","                                                    out_features=config.numDims)\n","\n","    def forward(self, tokens, mask):\n","        embs = self.transformer(tokens, attention_mask=mask)[0]\n","        embs = (embs * mask.unsqueeze(2)).sum(dim=1) / mask.sum(dim=1)[:, None]\n","        return self.LinearTransformation(embs)\n","\n","    @classmethod\n","    def _load_state_dict_into_model(cls, model, state_dict, pretrained_model_name_or_path, _fast_init=True):\n","        model.load_state_dict(state_dict)\n","        return model, [], [], []"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocess the Dataset"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:08.228459Z","iopub.status.busy":"2024-05-06T18:18:08.227674Z","iopub.status.idle":"2024-05-06T18:18:08.559596Z","shell.execute_reply":"2024-05-06T18:18:08.558616Z","shell.execute_reply.started":"2024-05-06T18:18:08.228415Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(4044, 16)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>lang</th>\n","      <th>text</th>\n","      <th>meme</th>\n","      <th>path_memes</th>\n","      <th>number_annotators</th>\n","      <th>annotators</th>\n","      <th>gender_annotators</th>\n","      <th>age_annotators</th>\n","      <th>ethnicities_annotators</th>\n","      <th>study_levels_annotators</th>\n","      <th>countries_annotators</th>\n","      <th>labels_task4</th>\n","      <th>labels_task5</th>\n","      <th>labels_task6</th>\n","      <th>split</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>110001</th>\n","      <td>110001</td>\n","      <td>es</td>\n","      <td>2+2=5 MITO Albert Einstein tenía bajo rendimie...</td>\n","      <td>110001.jpeg</td>\n","      <td>memes/110001.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[YES, YES, YES, YES, YES, YES]</td>\n","      <td>[DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, DIRECT]</td>\n","      <td>[[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>110002</th>\n","      <td>110002</td>\n","      <td>es</td>\n","      <td>CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS</td>\n","      <td>110002.jpeg</td>\n","      <td>memes/110002.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[YES, YES, YES, YES, YES, YES]</td>\n","      <td>[DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, JUDGE...</td>\n","      <td>[[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>110003</th>\n","      <td>110003</td>\n","      <td>es</td>\n","      <td>ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...</td>\n","      <td>110003.jpeg</td>\n","      <td>memes/110003.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[YES, YES, NO, NO, NO, NO]</td>\n","      <td>[DIRECT, DIRECT, -, -, -, -]</td>\n","      <td>[[STEREOTYPING-DOMINANCE, OBJECTIFICATION, MIS...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>110004</th>\n","      <td>110004</td>\n","      <td>es</td>\n","      <td>Paises que \"apoyan\" los derechos de la mujer A...</td>\n","      <td>110004.jpeg</td>\n","      <td>memes/110004.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[YES, YES, NO, NO, YES, NO]</td>\n","      <td>[JUDGEMENTAL, JUDGEMENTAL, -, -, JUDGEMENTAL, -]</td>\n","      <td>[[IDEOLOGICAL-INEQUALITY], [IDEOLOGICAL-INEQUA...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>110005</th>\n","      <td>110005</td>\n","      <td>es</td>\n","      <td>Ya verás como este 8 de marzo hay uno que te s...</td>\n","      <td>110005.jpeg</td>\n","      <td>memes/110005.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[NO, YES, NO, NO, YES, NO]</td>\n","      <td>[-, JUDGEMENTAL, -, -, DIRECT, -]</td>\n","      <td>[[-], [IDEOLOGICAL-INEQUALITY], [-], [-], [IDE...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id_EXIST lang                                               text  \\\n","110001   110001   es  2+2=5 MITO Albert Einstein tenía bajo rendimie...   \n","110002   110002   es     CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS    \n","110003   110003   es  ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...   \n","110004   110004   es  Paises que \"apoyan\" los derechos de la mujer A...   \n","110005   110005   es  Ya verás como este 8 de marzo hay uno que te s...   \n","\n","               meme         path_memes number_annotators  \\\n","110001  110001.jpeg  memes/110001.jpeg                 6   \n","110002  110002.jpeg  memes/110002.jpeg                 6   \n","110003  110003.jpeg  memes/110003.jpeg                 6   \n","110004  110004.jpeg  memes/110004.jpeg                 6   \n","110005  110005.jpeg  memes/110005.jpeg                 6   \n","\n","                                               annotators   gender_annotators  \\\n","110001  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","110002  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","110003  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","110004  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","110005  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","\n","                                age_annotators  \\\n","110001  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","110002  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","110003  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","110004  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","110005  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","\n","                                   ethnicities_annotators  \\\n","110001  [Hispano or Latino, Hispano or Latino, Hispano...   \n","110002  [Hispano or Latino, Hispano or Latino, Hispano...   \n","110003  [Hispano or Latino, Hispano or Latino, Hispano...   \n","110004  [Hispano or Latino, Hispano or Latino, Hispano...   \n","110005  [Hispano or Latino, Hispano or Latino, Hispano...   \n","\n","                                  study_levels_annotators  \\\n","110001  [High school degree or equivalent, Master’s de...   \n","110002  [High school degree or equivalent, Master’s de...   \n","110003  [High school degree or equivalent, Master’s de...   \n","110004  [High school degree or equivalent, Master’s de...   \n","110005  [High school degree or equivalent, Master’s de...   \n","\n","                                     countries_annotators  \\\n","110001  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","110002  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","110003  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","110004  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","110005  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","\n","                          labels_task4  \\\n","110001  [YES, YES, YES, YES, YES, YES]   \n","110002  [YES, YES, YES, YES, YES, YES]   \n","110003      [YES, YES, NO, NO, NO, NO]   \n","110004     [YES, YES, NO, NO, YES, NO]   \n","110005      [NO, YES, NO, NO, YES, NO]   \n","\n","                                             labels_task5  \\\n","110001   [DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, DIRECT]   \n","110002  [DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, JUDGE...   \n","110003                       [DIRECT, DIRECT, -, -, -, -]   \n","110004   [JUDGEMENTAL, JUDGEMENTAL, -, -, JUDGEMENTAL, -]   \n","110005                  [-, JUDGEMENTAL, -, -, DIRECT, -]   \n","\n","                                             labels_task6          split  \n","110001  [[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...  TRAIN-MEME_ES  \n","110002  [[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...  TRAIN-MEME_ES  \n","110003  [[STEREOTYPING-DOMINANCE, OBJECTIFICATION, MIS...  TRAIN-MEME_ES  \n","110004  [[IDEOLOGICAL-INEQUALITY], [IDEOLOGICAL-INEQUA...  TRAIN-MEME_ES  \n","110005  [[-], [IDEOLOGICAL-INEQUALITY], [-], [-], [IDE...  TRAIN-MEME_ES  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["with open('EXIST 2024 Lab/EXIST 2024 Memes Dataset/training/EXIST2024_training.json', 'r', encoding='utf-8') as fp:\n","    annotations = json.load(fp)\n","df = pd.DataFrame.from_dict(annotations).T\n","print(df.shape)\n","df.head()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:08.962373Z","iopub.status.busy":"2024-05-06T18:18:08.962006Z","iopub.status.idle":"2024-05-06T18:18:08.981050Z","shell.execute_reply":"2024-05-06T18:18:08.980036Z","shell.execute_reply.started":"2024-05-06T18:18:08.962344Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>meme</th>\n","      <th>text</th>\n","      <th>lang</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>110001</td>\n","      <td>110001.jpeg</td>\n","      <td>2+2=5 MITO Albert Einstein tenía bajo rendimie...</td>\n","      <td>es</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>110002</td>\n","      <td>110002.jpeg</td>\n","      <td>CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS</td>\n","      <td>es</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>110003</td>\n","      <td>110003.jpeg</td>\n","      <td>ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...</td>\n","      <td>es</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>110004</td>\n","      <td>110004.jpeg</td>\n","      <td>Paises que \"apoyan\" los derechos de la mujer A...</td>\n","      <td>es</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>110005</td>\n","      <td>110005.jpeg</td>\n","      <td>Ya verás como este 8 de marzo hay uno que te s...</td>\n","      <td>es</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id_EXIST         meme                                               text  \\\n","0    110001  110001.jpeg  2+2=5 MITO Albert Einstein tenía bajo rendimie...   \n","1    110002  110002.jpeg     CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS    \n","2    110003  110003.jpeg  ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...   \n","3    110004  110004.jpeg  Paises que \"apoyan\" los derechos de la mujer A...   \n","4    110005  110005.jpeg  Ya verás como este 8 de marzo hay uno que te s...   \n","\n","  lang  \n","0   es  \n","1   es  \n","2   es  \n","3   es  \n","4   es  "]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["mini_df = df[['id_EXIST', 'meme', 'text', 'lang']].reset_index(drop=True)\n","mini_df['id_EXIST'] = pd.to_numeric(mini_df['id_EXIST'])\n","mini_df.head()"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:09.679379Z","iopub.status.busy":"2024-05-06T18:18:09.678690Z","iopub.status.idle":"2024-05-06T18:18:09.740465Z","shell.execute_reply":"2024-05-06T18:18:09.739514Z","shell.execute_reply.started":"2024-05-06T18:18:09.679345Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4044\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>meme</th>\n","      <th>text</th>\n","      <th>lang</th>\n","      <th>label_task5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>110001</td>\n","      <td>110001.jpeg</td>\n","      <td>2+2=5 MITO Albert Einstein tenía bajo rendimie...</td>\n","      <td>es</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>110002</td>\n","      <td>110002.jpeg</td>\n","      <td>CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS</td>\n","      <td>es</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>110003</td>\n","      <td>110003.jpeg</td>\n","      <td>ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...</td>\n","      <td>es</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>110004</td>\n","      <td>110004.jpeg</td>\n","      <td>Paises que \"apoyan\" los derechos de la mujer A...</td>\n","      <td>es</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>110005</td>\n","      <td>110005.jpeg</td>\n","      <td>Ya verás como este 8 de marzo hay uno que te s...</td>\n","      <td>es</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id_EXIST         meme                                               text  \\\n","0    110001  110001.jpeg  2+2=5 MITO Albert Einstein tenía bajo rendimie...   \n","1    110002  110002.jpeg     CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS    \n","2    110003  110003.jpeg  ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...   \n","3    110004  110004.jpeg  Paises que \"apoyan\" los derechos de la mujer A...   \n","4    110005  110005.jpeg  Ya verás como este 8 de marzo hay uno que te s...   \n","\n","  lang  label_task5  \n","0   es            1  \n","1   es            1  \n","2   es            0  \n","3   es            0  \n","4   es            0  "]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["task4_gold_path = Path('EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task4_gold_hard.json')\n","task5_gold_path = Path('EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task5_gold_hard.json')\n","task6_gold_path = Path('EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task6_gold_hard.json')\n","task5_gold = pd.read_json(task5_gold_path)\n","\n","choices = ['DIRECT', 'JUDGEMENTAL', 'NO']\n","mini_df = pd.merge(mini_df, task5_gold, left_on='id_EXIST', right_on='id', how='left').drop(columns=['id', 'test_case']).rename(columns={'value': 'label_task5'})\n","mini_df['label_task5'] = mini_df['label_task5'].apply(lambda x: np.random.choice(choices) if pd.isna(x) else x)\n","mini_df['label_task5'] = pd.to_numeric(mini_df['label_task5'].map({'DIRECT': 1, 'JUDGEMENTAL': 2, 'NO': 0}))\n","print(len(mini_df))\n","mini_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Initialise the Processors/Tokenisers/Models"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:44.737506Z","iopub.status.busy":"2024-05-06T18:18:44.737103Z","iopub.status.idle":"2024-05-06T18:19:08.560431Z","shell.execute_reply":"2024-05-06T18:19:08.559371Z","shell.execute_reply.started":"2024-05-06T18:18:44.737475Z"},"trusted":true},"outputs":[],"source":["if CFG.is_mclip:\n","    tokenizer = hf.AutoTokenizer.from_pretrained(CFG.tokeniser_model_id)\n","    text_model = MultilingualCLIP.from_pretrained(CFG.text_model_id).to(CFG.device)\n","    image_model, _, image_processor = open_clip.create_model_and_transforms(CFG.image_model_id, pretrained=CFG.image_training_id)\n","    image_model = image_model.to(CFG.device)\n","elif CFG.use_multimodal:\n","    mm_processor = hf.AutoProcessor.from_pretrained(CFG.multimodal_model_id)\n","    mm_model = hf.AutoModel.from_pretrained(CFG.multimodal_model_id).to(CFG.device)\n","elif CFG.use_dualencoder:\n","    tokenizer = hf.AutoTokenizer.from_pretrained(CFG.tokeniser_model_id, padding=True, truncation=True)\n","    processor = hf.AutoImageProcessor.from_pretrained(CFG.image_model_id)\n","    de_processor = hf.VisionTextDualEncoderProcessor(image_processor=processor, tokenizer=tokenizer)\n","    text_model = hf.AutoModel.from_pretrained(CFG.text_model_id).to(CFG.device)\n","    image_model = hf.AutoModel.from_pretrained(CFG.image_model_id).to(CFG.device)\n","    de_model = hf.VisionTextDualEncoderModel(vision_model=image_model, text_model=text_model)\n","else:\n","    tokenizer = hf.AutoTokenizer.from_pretrained(CFG.tokeniser_model_id)\n","    text_model = hf.AutoModel.from_pretrained(CFG.text_model_id).to(CFG.device)\n","    # Adding a config to the image_model gets rid of lots of pretrained weights\n","    image_model = hf.AutoModel.from_pretrained(CFG.image_model_id).to(CFG.device)"]},{"cell_type":"markdown","metadata":{},"source":["# Train/Val Split"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:12.849175Z","iopub.status.busy":"2024-05-06T18:19:12.848090Z","iopub.status.idle":"2024-05-06T18:19:12.871009Z","shell.execute_reply":"2024-05-06T18:19:12.870233Z","shell.execute_reply.started":"2024-05-06T18:19:12.849140Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>meme</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>211600.jpeg</td>\n","      <td>Dating after 25 Learn how to be a step dad 557</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>110150.jpeg</td>\n","      <td>ESTAMOS ENAMORADOS, ASÉ-QUE-NO-DEDORIA TENER S...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>112026.jpeg</td>\n","      <td>BUUU ZORRA!!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>210472.jpeg</td>\n","      <td>Claims to be Feminist FOX STUDT MEN IN 45 HAPP...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>211170.jpeg</td>\n","      <td>NOT ALL MEN NOT ALL MEN, BUT A STATISTICALLY S...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          meme                                               text\n","0  211600.jpeg   Dating after 25 Learn how to be a step dad 557  \n","1  110150.jpeg  ESTAMOS ENAMORADOS, ASÉ-QUE-NO-DEDORIA TENER S...\n","2  112026.jpeg                                      BUUU ZORRA!! \n","3  210472.jpeg  Claims to be Feminist FOX STUDT MEN IN 45 HAPP...\n","4  211170.jpeg  NOT ALL MEN NOT ALL MEN, BUT A STATISTICALLY S..."]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["def dataframe_train_test_split(df, target_label, seed=CFG.seed, test_size=0.2, split_labels=True):\n","    train = df.sample(frac=(1.0 - test_size), random_state=seed).reset_index(drop=True)\n","    test = df.drop(train.index).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n","\n","    if split_labels:\n","        return train.drop(columns=target_label), test.drop(columns=target_label), train[target_label], test[target_label]\n","    else:\n","        return train, test\n","\n","X_train, X_val, y_train, y_val = dataframe_train_test_split(mini_df[['meme', 'text', 'label_task5']], 'label_task5', test_size=0.2, seed=CFG.seed)\n","X_train.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Custom Dataset Definition"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:14.449356Z","iopub.status.busy":"2024-05-06T18:19:14.448759Z","iopub.status.idle":"2024-05-06T18:19:14.463944Z","shell.execute_reply":"2024-05-06T18:19:14.462848Z","shell.execute_reply.started":"2024-05-06T18:19:14.449326Z"},"trusted":true},"outputs":[],"source":["class ExistDataset(Dataset):\n","    def __init__(self, features, img_dir, labels=None, test=False, img_transform=None, caption_transform=None, target_transform=None):\n","        self.features = features\n","        self.labels = labels\n","        self.img_dir = img_dir\n","        self.test = test\n","        self.img_transform = img_transform\n","        self.caption_transform = caption_transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, idx):\n","        img_path = str(self.img_dir.joinpath(self.features['meme'].iloc[idx]))\n","        if CFG.is_mclip:\n","            image = Image.open(img_path)\n","        else:\n","            image = read_image(img_path, mode=ImageReadMode.RGB).to(device=CFG.device)\n","        caption = self.features['text'].iloc[idx]\n","        \n","        if not self.test:\n","            label = self.labels.iloc[idx]\n","        else:\n","            identity = self.features['id_EXIST'].iloc[idx]\n","        \n","        if self.img_transform:\n","            image = self.img_transform(image)\n","        if self.caption_transform:\n","            caption = self.caption_transform(caption)\n","        if not self.test and self.target_transform:\n","            label = self.target_transform(label)\n","            \n","        if CFG.split_lang:\n","            caption = f'Language: {self.features[\"lang\"].iloc[idx]} - {caption}'\n","            \n","        if CFG.is_mclip:\n","            processed = tokenizer(caption, padding=True, return_tensors='pt')\n","            seq = processed['input_ids']\n","            mask = processed['attention_mask']\n","            image = image_processor(image)\n","        elif CFG.use_multimodal:\n","            processed = mm_processor(text=caption, images=image, return_tensors=\"pt\", padding=True, truncation=True)\n","            seq = processed['input_ids']\n","            mask = processed['attention_mask']\n","            image = processed['pixel_values']\n","        elif CFG.use_dualencoder:\n","            processed = de_processor(text=caption, images=image, return_tensors=\"pt\")\n","            seq = processed['input_ids']\n","            mask = processed['attention_mask']\n","            image = processed['pixel_values']\n","        else:\n","            processed = tokenizer.encode_plus(\n","                caption,\n","                padding='longest',\n","                truncation=True,\n","                return_tensors='pt'\n","            )\n","            seq = processed['input_ids']\n","            mask = processed['attention_mask']\n","        \n","        if not self.test:\n","            label = torch.tensor([label]).long()\n","            return image, seq, mask, label\n","        \n","        return identity, image, seq, mask"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:14.912249Z","iopub.status.busy":"2024-05-06T18:19:14.911773Z","iopub.status.idle":"2024-05-06T18:19:14.920983Z","shell.execute_reply":"2024-05-06T18:19:14.919959Z","shell.execute_reply.started":"2024-05-06T18:19:14.912215Z"},"trusted":true},"outputs":[],"source":["class Collator(object):\n","    def __init__(self, test=False):\n","        self.test = test\n","    def __call__(self, batch):\n","        if not self.test:\n","            images, seqs, masks, labels = zip(*batch)\n","            labels = torch.stack(labels)\n","        else:\n","            ids, images, seqs, masks = zip(*batch)\n","\n","        seqs = [seq.squeeze(dim=0) for seq in seqs]\n","        masks = [mask.squeeze(dim=0) for mask in masks]\n","        images = [image.squeeze(dim=0) for image in images]\n","\n","        seqs = nn.utils.rnn.pad_sequence(seqs, batch_first=True)\n","        masks = nn.utils.rnn.pad_sequence(masks, batch_first=True)\n","\n","        images = torch.stack(images)\n","        \n","        if not self.test:\n","            return images, seqs, masks, labels\n","        \n","        return ids, images, seqs, masks"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:15.535724Z","iopub.status.busy":"2024-05-06T18:19:15.535132Z","iopub.status.idle":"2024-05-06T18:19:15.540414Z","shell.execute_reply":"2024-05-06T18:19:15.539547Z","shell.execute_reply.started":"2024-05-06T18:19:15.535690Z"},"trusted":true},"outputs":[],"source":["resizer = Resize((224, 224), antialias=True)\n","\n","def resize_images(img_tensor):\n","    return resizer(img_tensor)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Initialisation"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:21.328625Z","iopub.status.busy":"2024-05-06T18:19:21.328254Z","iopub.status.idle":"2024-05-06T18:19:21.335115Z","shell.execute_reply":"2024-05-06T18:19:21.334215Z","shell.execute_reply.started":"2024-05-06T18:19:21.328596Z"},"trusted":true},"outputs":[{"data":{"text/plain":["3235"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset = ExistDataset(X_train, CFG.images_base_path, labels=y_train, img_transform=resize_images)\n","len(train_dataset)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:21.839823Z","iopub.status.busy":"2024-05-06T18:19:21.839454Z","iopub.status.idle":"2024-05-06T18:19:21.846397Z","shell.execute_reply":"2024-05-06T18:19:21.845390Z","shell.execute_reply.started":"2024-05-06T18:19:21.839793Z"},"trusted":true},"outputs":[{"data":{"text/plain":["809"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["val_dataset = ExistDataset(X_val, CFG.images_base_path, labels=y_val, img_transform=resize_images)\n","len(val_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["# Model Architecture"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:25.859218Z","iopub.status.busy":"2024-05-06T18:19:25.858470Z","iopub.status.idle":"2024-05-06T18:19:25.882149Z","shell.execute_reply":"2024-05-06T18:19:25.881167Z","shell.execute_reply.started":"2024-05-06T18:19:25.859188Z"},"trusted":true},"outputs":[],"source":["class ConcatArch(nn.Module):\n","    def __init__(self, hidden_size, hidden_layers, dropout, num_classes, use_multimodal=False, use_dualencoder=False, is_mclip=False):\n","        super().__init__()\n","        \n","        self.hidden_size = hidden_size\n","        self.hidden_layers = hidden_layers\n","        self.use_multimodal = use_multimodal\n","        self.use_dualencoder = use_dualencoder\n","        self.is_mclip = is_mclip\n","        self.is_vilt = 'ViltForMaskedLM' in CFG.multimodal_model_config.architectures\n","        \n","        if self.is_mclip:\n","            self.text_model = text_model\n","            self.image_model = image_model\n","        elif self.use_multimodal:\n","            self.mm_model = mm_model\n","        elif self.use_dualencoder:\n","            self.de_model = de_model\n","        else:\n","            self.text_model = text_model\n","            self.image_model = image_model\n","        \n","        if self.is_mclip:\n","            self.fc1 = nn.Linear(1280, self.hidden_size)\n","        elif self.use_multimodal:\n","            if self.is_vilt and CFG.use_lstm:\n","                out_channels = CFG.mlp_hidden_size + CFG.multimodal_model_config.hidden_size\n","                self.lstm = nn.LSTM(CFG.multimodal_model_config.hidden_size, CFG.mlp_hidden_size, batch_first=True)\n","            elif self.is_vilt and CFG.use_mask_split:\n","                out_channels = CFG.multimodal_model_config.hidden_size * 3\n","            elif self.is_vilt and CFG.use_attn:\n","                self.attn = nn.Sequential(\n","                    nn.Linear(CFG.multimodal_model_config.hidden_size, CFG.mlp_attn_dim),\n","                    nn.Tanh(),\n","                    nn.Linear(CFG.mlp_attn_dim, 1),\n","                    nn.Softmax(dim=1)\n","                )\n","            elif self.is_vilt and CFG.use_modal_attn:\n","                self.attn1 = nn.Sequential(\n","                    nn.Linear(CFG.multimodal_model_config.hidden_size, CFG.mlp_attn_dim),\n","                    nn.Tanh(),\n","                    nn.Linear(CFG.mlp_attn_dim, 1),\n","                    nn.Softmax(dim=1)\n","                )\n","                self.attn2 = nn.Sequential(\n","                    nn.Linear(CFG.multimodal_model_config.hidden_size, CFG.mlp_attn_dim),\n","                    nn.Tanh(),\n","                    nn.Linear(CFG.mlp_attn_dim, 1),\n","                    nn.Softmax(dim=1)\n","                )\n","                out_channels = CFG.multimodal_model_config.hidden_size * 2\n","            elif self.is_vilt:\n","                out_channels = CFG.multimodal_model_config.hidden_size\n","            else:\n","                out_channels = 2 * CFG.multimodal_model_config.projection_dim\n","            self.fc1 = nn.Linear(out_channels, self.hidden_size)\n","        elif self.use_dualencoder:\n","            self.fc1 = nn.Linear(2 * 512, self.hidden_size)\n","        else:\n","            self.fc1 = nn.Linear(CFG.text_model_config.hidden_size + CFG.image_model_config.hidden_size, self.hidden_size)\n","        self.hiddens = nn.ModuleList([nn.Linear(self.hidden_size, self.hidden_size) for _ in range(self.hidden_layers)])\n","        self.fc2 = nn.Linear(self.hidden_size, num_classes)\n","        self.activation = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","        \n","        if CFG.init_weights:\n","            self._init_weights(self.fc1)\n","            for hidden in self.hiddens:\n","                self._init_weights(hidden)\n","            self._init_weights(self.fc2)\n","\n","    def forward(self, tokens, mask, image):\n","        if self.is_mclip:\n","            emb_text = self.text_model.forward(tokens, mask)\n","            emb_img = self.image_model.encode_image(image)\n","            x = torch.cat([emb_text, emb_img], dim=1)\n","        elif self.use_multimodal:\n","            mm_output = self.mm_model(input_ids=tokens, attention_mask=mask, pixel_values=image, output_hidden_states=True)\n","            cats = [mm_output.pooler_output] if self.is_vilt else [mm_output.text_embeds, mm_output.image_embeds]\n","            \n","            if self.is_vilt and CFG.use_lstm:\n","                # First hidden state is apparently the embedding output\n","                # https://discuss.huggingface.co/t/hidden-states-embedding-tensors/3549/\n","                layerwise_cls = torch.stack([h[:, 0, :] for h in mm_output.hidden_states[1:]], dim=1)\n","                _, (h, _) = self.lstm(layerwise_cls)\n","                h = h.squeeze(dim=0)\n","                cats.append(h)\n","\n","            if self.is_vilt and CFG.use_mask_split:\n","                last_h = mm_output.last_hidden_state\n","                mask_len = mask.shape[1]\n","                mean_pooled_text = torch.mean(last_h[:, :mask_len, :], dim=1)\n","                mean_pooled_img = torch.mean(last_h[:, mask_len:, :], dim=1)\n","                cats += [mean_pooled_text, mean_pooled_img]\n","\n","            if self.is_vilt and CFG.use_attn:\n","                last_h = mm_output.last_hidden_state\n","                attentions = self.attn(last_h)\n","                x = torch.sum(attentions * last_h, dim=1)\n","\n","                cls = last_h[:, 0, :]\n","                x += cls\n","            elif self.is_vilt and CFG.use_modal_attn:\n","                last_h = mm_output.last_hidden_state\n","                mask_len = mask.shape[1]\n","                text_split = last_h[:, :mask_len, :]\n","                img_split = last_h[:, mask_len:, :]\n","                text_attentions = self.attn1(text_split)\n","                img_attentions = self.attn2(img_split)\n","                x1 = torch.sum(text_attentions * text_split, dim=1)\n","                x2 = torch.sum(img_attentions * img_split, dim=1)\n","\n","                x = torch.cat([x1, x2], dim=1)\n","\n","                cls = last_h[:, 0, :]\n","                cls = torch.cat([cls, cls], dim=1)\n","                x += cls\n","            else:\n","                x = torch.cat(cats, dim=1)\n","        elif self.use_dualencoder:\n","            de_output = self.de_model(input_ids=tokens, attention_mask=mask, pixel_values=image)\n","            x = torch.cat([de_output.text_embeds, de_output.image_embeds], dim=1)\n","        else:\n","            cls_text = self.text_model(tokens, attention_mask=mask).last_hidden_state[:, 0, :]\n","            cls_img = self.image_model(image).last_hidden_state[:, 0, :]\n","            x = torch.cat([cls_text, cls_img], dim=1)\n","\n","        x = self.fc1(x)\n","        x = self.activation(x)\n","        x = self.dropout(x)\n","        for hidden in self.hiddens:\n","            x = hidden(x)\n","            x = self.activation(x)\n","            x = self.dropout(x)\n","        x = self.fc2(x)\n","        \n","        output = x\n","        return output.float()\n","    \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=CFG.mlp_init_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=CFG.mlp_init_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)"]},{"cell_type":"markdown","metadata":{},"source":["# Utility Functions"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:31.296299Z","iopub.status.busy":"2024-05-06T18:19:31.295514Z","iopub.status.idle":"2024-05-06T18:19:31.304096Z","shell.execute_reply":"2024-05-06T18:19:31.302978Z","shell.execute_reply.started":"2024-05-06T18:19:31.296263Z"},"trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:31.726713Z","iopub.status.busy":"2024-05-06T18:19:31.726335Z","iopub.status.idle":"2024-05-06T18:19:31.731481Z","shell.execute_reply":"2024-05-06T18:19:31.730490Z","shell.execute_reply.started":"2024-05-06T18:19:31.726682Z"},"trusted":true},"outputs":[],"source":["def get_score(y_trues, y_preds):\n","    macro_f1 = f1_score(y_trues, y_preds, average='macro')\n","    return macro_f1"]},{"cell_type":"markdown","metadata":{},"source":["# Train/Val/Test Loops"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:37.535323Z","iopub.status.busy":"2024-05-06T18:19:37.534953Z","iopub.status.idle":"2024-05-06T18:19:37.547645Z","shell.execute_reply":"2024-05-06T18:19:37.546682Z","shell.execute_reply.started":"2024-05-06T18:19:37.535294Z"},"trusted":true},"outputs":[],"source":["def train_loop(model, optimizer, train_dataloader, epoch, loss_fn):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    train_losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    \n","    for step, (image, seq, mask, label) in enumerate(tqdm(train_dataloader)):\n","        optimizer.zero_grad()\n","        \n","        train_image = image.to(device=CFG.device)\n","        train_seq = seq.to(device=CFG.device)\n","        train_mask = mask.to(device=CFG.device)\n","        \n","        batch_size = train_image.shape[0]\n","        \n","        label = label.squeeze(dim=1).to(device=CFG.device)\n","\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            output = model(train_seq, train_mask, train_image)\n","            \n","        loss = loss_fn(output, label)\n","        \n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","            \n","        loss.backward()\n","        # scaler.scale(loss).backward()\n","        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), CFG.mlp_grad_clip)\n","        optimizer.step()\n","        \n","        train_losses.update(loss.item(), batch_size)\n","        \n","        # if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","        #     scaler.step(optimizer)\n","        #     scaler.update()\n","        #     optimizer.zero_grad()\n","        #     global_step += 1\n","            \n","        end = time.time()\n","\n","        if step % CFG.print_freq == 0 or step == (len(train_dataloader) - 1):\n","            print(f'Epoch: [{epoch + 1}][{step}/{len(train_dataloader)}] '\n","                    f'Elapsed {timeSince(start, float(step + 1) / len(train_dataloader)):s} '\n","                    f'Loss: {train_losses.val:.4f} ({train_losses.avg:.4f}) '\n","                    f'Grad: {grad_norm:.4f}')\n","        \n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        \n","        \n","    return train_losses.avg"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:40.958522Z","iopub.status.busy":"2024-05-06T18:19:40.958120Z","iopub.status.idle":"2024-05-06T18:19:40.969754Z","shell.execute_reply":"2024-05-06T18:19:40.968691Z","shell.execute_reply.started":"2024-05-06T18:19:40.958489Z"},"trusted":true},"outputs":[],"source":["def valid_loop(model, valid_dataloader, loss_fn):\n","    all_preds = []\n","    all_labels = []\n","    \n","    model.eval()\n","    valid_losses = AverageMeter()\n","    start = end = time.time()\n","    \n","    for step, (image, seq, mask, label) in enumerate(tqdm(valid_dataloader)):\n","        valid_image = image.to(device=CFG.device)\n","        valid_seq = seq.to(device=CFG.device)\n","        valid_mask = mask.to(device=CFG.device)\n","\n","        batch_size = valid_image.shape[0]\n","\n","        label = label.squeeze(dim=1).to(device=CFG.device)\n","\n","        with torch.no_grad():\n","            output = model(valid_seq, valid_mask, valid_image)\n","\n","        loss = loss_fn(output, label)\n","\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","\n","        valid_losses.update(loss.item(), batch_size)\n","        predicted = output.argmax(dim=1)\n","\n","        all_labels.append(label)\n","        all_preds.append(predicted)\n","        \n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_dataloader) - 1):\n","            print(f'Validation: [{step}/{len(valid_dataloader)}] '\n","                    f'Elapsed {timeSince(start, float(step + 1) / len(valid_dataloader)):s} '\n","                    f'Loss: {valid_losses.val:.4f} ({valid_losses.avg:.4f})')\n","            \n","    all_preds = torch.cat(all_preds, dim=0)\n","    all_labels = torch.cat(all_labels, dim=0)\n","    \n","    all_preds_np = all_preds.cpu().numpy().astype(int)\n","    all_labels_np = all_labels.cpu().numpy().astype(int)\n","    \n","    return valid_losses.avg, all_preds_np, all_labels_np "]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:41.312411Z","iopub.status.busy":"2024-05-06T18:19:41.311584Z","iopub.status.idle":"2024-05-06T18:19:41.320936Z","shell.execute_reply":"2024-05-06T18:19:41.319856Z","shell.execute_reply.started":"2024-05-06T18:19:41.312379Z"},"trusted":true},"outputs":[],"source":["def test_loop(model, test_dataloader):\n","    all_soft = []\n","    all_hard = []\n","    all_ids = []\n","    \n","    model.eval()\n","    \n","    for identity, image, seq, mask in tqdm(test_dataloader):\n","        test_image = image.to(device=CFG.device)\n","        test_seq = seq.to(device=CFG.device)\n","        test_mask = mask.to(device=CFG.device)\n","\n","        with torch.no_grad():\n","            output = model(test_seq, test_mask, test_image)\n","        \n","        soft = nn.functional.softmax(output, dim=1)\n","        hard = output.argmax(dim=1)\n","        \n","        all_ids += list(identity)\n","        all_soft.append(soft)\n","        all_hard.append(hard)\n","        \n","    all_soft = torch.cat(all_soft, dim=0)\n","    all_hard = torch.cat(all_hard, dim=0)\n","    \n","    return all_ids, all_hard, all_soft"]},{"cell_type":"markdown","metadata":{},"source":["# Training and Validation"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["collate = Collator()\n","train_dataloader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, collate_fn=collate)\n","valid_dataloader = DataLoader(val_dataset, batch_size=CFG.batch_size, collate_fn=collate)\n","\n","model = ConcatArch(\n","    hidden_size=CFG.mlp_hidden_size,\n","    hidden_layers=CFG.mlp_hidden_layers,\n","    dropout=CFG.mlp_dropout,\n","    num_classes=CFG.num_class,\n","    use_multimodal=CFG.use_multimodal,\n","    use_dualencoder=CFG.use_dualencoder,\n","    is_mclip=CFG.is_mclip\n",").to(CFG.device)\n","\n","optim = AdamWScheduleFree(model.parameters(), lr=CFG.learning_rate, eps=CFG.eps, betas=CFG.betas)\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:47.343641Z","iopub.status.busy":"2024-05-06T18:19:47.343264Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  2%|▏         | 1/51 [00:03<02:32,  3.04s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/51] Elapsed 0m 2s (remain 2m 24s) Loss: 0.6685 (0.6685) Grad: 11.1624\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 51/51 [02:11<00:00,  2.57s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][50/51] Elapsed 2m 11s (remain 0m 0s) Loss: 0.4588 (0.5325) Grad: 14.6177\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 1/13 [00:00<00:10,  1.17it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [0/13] Elapsed 0m 0s (remain 0m 10s) Loss: 0.7452 (0.7452)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:10<00:00,  1.28it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [12/13] Elapsed 0m 10s (remain 0m 0s) Loss: 0.4587 (0.6973)\n","[2 2 0 0 1 1 0 0 1 1 1 2 2 2 0 0 1 2 1 0 1 1 1 0 1 0 1 0 1 0 2 2 1 0 1 1 1\n"," 0 2 0 0 0 2 0 2 1 0 1 1 1 1 0 0 1 1 0 1 2 0 1 0 2 1 1 0 1 0 0 1 1 0 0 1 1\n"," 1 0 2 0 1 1 0 1 1 0 2 1 1 0 2 1 0 0 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 0\n"," 1 1 1 0 0 1 2 2 0 1 0 1 0 1 1 0 2 1 0 1 2 2 1 1 0 0 0 1 2 0 1 1 0 0 0 2 2\n"," 0 1 0 2 1 1 1 0 0 2 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 2 0 0 1 0 1 0 1 1 0 1 1 2 0 2 1 1 2 2 1 0 0 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 2 1 0 0 1 0 0 0 1 2 1 1 1 2 0 0 0 0 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 2 1 0 0 1 1 1\n"," 2 1 1 0 0 2 0 2 1 2 1 1 1 1 0 1 0 1 2 0 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 2 0 0 1 2 1 0 0 2 0 1 1 0 1 1 1 2 2 0 1 0 0\n"," 1 0 0 0 2 1 1 1 1 0 0 1 0 2 0 1 1 0 0 0 1 2 0 1 0 2 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 0 2 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 2 0 1 1 0 1 0 0 1 1 0 2 0 1 0 1 1 0 2 0 0 1 1 1 0 0 1 0 1 2 0 1 2\n"," 1 0 0 1 0 0 1 2 0 0 0 0 0 1 2 1 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 0 1 1 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 1 1 0 1 2 0 2 0 1 0 0 1 1 2 1 2 1 0 0 1 2 0 0 1 0 0 2 1 0 2 0 0 1 0\n"," 1 0 2 0 0 0 2 0 0 1 1 1 0 0 1 2 2 0 0 1 0 2 2 2 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 1 2 2 1 2 0 0 1 1 0 1 2 0 2 0 1 1 1 0 0 1 1 0 1 1 2 0 2 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 2 2 1 1 0 0 0 1 1 1 0 2 0 0 1 0 0 2 2 2 0 0 1 0 0 0 0 1 1 1 0 1\n"," 0 1 0 2 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 2 0 1 1 2 0 0 1 0 0 0 1 0 0 2 2 0 2\n"," 1 1 1 0 0 0 0 1 0 1 1 0 2 1 1 0 0 0 0 2 0 2 0 1 2 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","[1 1 1 0 1 1 0 0 0 1 1 2 1 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 0 2 1 0 0 1 1\n"," 0 0 0 0 1 1 0 2 2 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 2 1 1 0 1 0 0 1 0 1 0 1 1\n"," 1 0 2 0 0 1 1 1 1 0 1 2 1 0 2 1 0 1 0 1 2 0 1 0 0 1 0 2 1 1 2 1 1 0 0 0 0\n"," 2 1 1 0 0 1 1 1 0 1 0 0 0 2 0 0 1 1 0 1 2 2 1 1 0 0 1 1 2 0 1 1 0 0 0 0 2\n"," 0 1 0 0 0 1 0 1 0 1 1 0 0 2 2 2 0 0 1 2 0 0 0 1 1 0 1 1 0 2 0 1 1 0 1 1 1\n"," 2 0 0 0 1 0 1 1 1 0 1 1 0 2 0 0 1 1 1 2 1 0 0 1 0 2 1 0 0 0 0 0 0 2 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 1 2 1 1 0 0 2 1 0 0 0 2 2 1 1 1 2 0 0 0 1 0 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 0 1 2 0 0 1 0 2 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1\n"," 2 1 1 0 0 1 0 1 1 2 1 1 0 0 0 0 0 1 2 2 1 1 2 1 1 0 1 0 1 0 1 1 1 0 0 1 1\n"," 0 0 0 1 1 1 0 1 0 0 2 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 2 0 1 0 1\n"," 1 0 0 0 2 1 1 1 1 0 2 1 0 2 1 1 1 0 0 0 1 2 2 1 0 1 0 0 0 1 2 1 0 2 1 0 1\n"," 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 2\n"," 2 0 0 1 0 0 1 2 2 2 2 2 0 1 2 0 2 2 0 0 1 1 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 1 1 1 1 2 1 0 1 0 1 2 2 0 1 1 1 0 1 2 1 0 0\n"," 0 1 0 0 1 0 1 1 0 2 0 1 0 0 0 1 2 2 0 0 0 0 1 0 0 0 0 2 0 2 0 0 2 0 0 1 0\n"," 1 0 2 0 0 0 1 0 1 1 1 1 0 1 2 2 0 0 0 1 0 1 0 0 0 0 1 2 1 0 2 1 1 1 2 0 1\n"," 1 0 1 1 1 0 0 2 0 1 2 1 1 0 1 0 1 2 0 1 0 1 0 1 1 2 2 0 1 0 0 0 2 0 1 1 1\n"," 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 2 2 2 0 0 2 0 0 0 0 0 1 1 1 1\n"," 0 1 0 0 0 1 0 2 1 0 1 0 0 1 1 1 1 2 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 2 2 0 2\n"," 1 2 2 0 1 0 0 0 0 1 2 0 1 1 1 0 0 0 0 1 0 2 0 1 0 1 0 2 2 2 1 2 0 2 0 1 0\n"," 0 0 0 2 2 1 1 0 0 1 0 1 1 2 0 1 0 1 1 2 0 1 0 2 2 0 0 0 1 0 0 0]\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.81      0.80       336\n","           1       0.76      0.81      0.78       329\n","           2       0.63      0.51      0.57       144\n","\n","    accuracy                           0.75       809\n","   macro avg       0.73      0.71      0.72       809\n","weighted avg       0.75      0.75      0.75       809\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Saved model: openai-clip-vit-base-patch32_score_0.7157\n","Epoch 1/10, Train Loss: 0.5325, Validation Loss: 0.6973\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 1/51 [00:02<02:22,  2.84s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][0/51] Elapsed 0m 2s (remain 2m 15s) Loss: 0.4542 (0.4542) Grad: 58.8693\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 51/51 [02:11<00:00,  2.57s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][50/51] Elapsed 2m 10s (remain 0m 0s) Loss: 0.3868 (0.4520) Grad: 3.3542\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 1/13 [00:00<00:10,  1.20it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [0/13] Elapsed 0m 0s (remain 0m 10s) Loss: 0.7895 (0.7895)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:10<00:00,  1.30it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [12/13] Elapsed 0m 10s (remain 0m 0s) Loss: 0.3489 (0.6761)\n","[2 2 0 0 1 1 0 0 1 1 1 2 2 2 0 0 1 2 1 0 1 1 1 0 1 0 1 0 1 0 2 2 1 0 1 1 1\n"," 0 2 0 0 0 2 0 2 1 0 1 1 1 1 0 0 1 1 0 1 2 0 1 0 2 1 1 0 1 0 0 1 1 0 0 1 1\n"," 1 0 2 0 1 1 0 1 1 0 2 1 1 0 2 1 0 0 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 0\n"," 1 1 1 0 0 1 2 2 0 1 0 1 0 1 1 0 2 1 0 1 2 2 1 1 0 0 0 1 2 0 1 1 0 0 0 2 2\n"," 0 1 0 2 1 1 1 0 0 2 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 2 0 0 1 0 1 0 1 1 0 1 1 2 0 2 1 1 2 2 1 0 0 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 2 1 0 0 1 0 0 0 1 2 1 1 1 2 0 0 0 0 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 2 1 0 0 1 1 1\n"," 2 1 1 0 0 2 0 2 1 2 1 1 1 1 0 1 0 1 2 0 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 2 0 0 1 2 1 0 0 2 0 1 1 0 1 1 1 2 2 0 1 0 0\n"," 1 0 0 0 2 1 1 1 1 0 0 1 0 2 0 1 1 0 0 0 1 2 0 1 0 2 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 0 2 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 2 0 1 1 0 1 0 0 1 1 0 2 0 1 0 1 1 0 2 0 0 1 1 1 0 0 1 0 1 2 0 1 2\n"," 1 0 0 1 0 0 1 2 0 0 0 0 0 1 2 1 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 0 1 1 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 1 1 0 1 2 0 2 0 1 0 0 1 1 2 1 2 1 0 0 1 2 0 0 1 0 0 2 1 0 2 0 0 1 0\n"," 1 0 2 0 0 0 2 0 0 1 1 1 0 0 1 2 2 0 0 1 0 2 2 2 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 1 2 2 1 2 0 0 1 1 0 1 2 0 2 0 1 1 1 0 0 1 1 0 1 1 2 0 2 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 2 2 1 1 0 0 0 1 1 1 0 2 0 0 1 0 0 2 2 2 0 0 1 0 0 0 0 1 1 1 0 1\n"," 0 1 0 2 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 2 0 1 1 2 0 0 1 0 0 0 1 0 0 2 2 0 2\n"," 1 1 1 0 0 0 0 1 0 1 1 0 2 1 1 0 0 0 0 2 0 2 0 1 2 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","[0 1 1 0 1 1 0 0 0 1 1 2 1 1 0 0 1 2 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1\n"," 0 0 0 0 1 1 0 2 2 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 2 1 1 0 1 0 0 1 0 1 0 0 1\n"," 1 0 2 0 1 1 1 1 1 0 1 2 1 0 2 1 0 1 0 1 2 0 1 0 0 1 0 2 1 1 2 2 1 0 0 0 0\n"," 2 1 0 0 0 1 2 0 0 1 0 0 0 1 0 0 1 1 0 1 2 1 1 1 0 0 1 0 2 0 1 1 0 0 0 0 2\n"," 0 1 0 0 0 1 1 1 0 1 1 0 0 0 2 2 0 0 1 0 0 0 0 1 1 0 1 1 0 2 0 1 1 0 1 1 1\n"," 2 0 0 0 1 0 1 1 1 0 1 1 1 2 0 1 1 1 1 0 1 0 0 1 0 2 1 0 0 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 2 0 0 0 1 2 1 1 1 2 0 0 0 1 0 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 2 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1\n"," 2 1 1 0 0 2 0 0 1 2 1 1 0 1 0 1 0 1 2 2 1 1 2 0 1 0 1 0 1 0 1 1 1 0 0 0 1\n"," 0 0 0 1 1 1 0 1 1 0 2 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 2 0 1 0 1\n"," 1 0 0 0 2 1 1 1 1 0 2 1 0 2 1 1 1 0 0 0 1 2 2 1 0 1 0 0 0 1 2 1 0 2 1 0 1\n"," 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 1 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 2\n"," 0 0 0 1 0 0 1 2 0 0 1 2 0 1 2 0 2 2 0 0 1 1 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 1 1 1 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 0 1 0 1 1 0 2 0 1 0 0 0 1 2 2 0 0 0 0 1 0 1 0 0 0 0 2 0 0 2 0 0 1 0\n"," 1 0 2 0 0 0 1 0 1 1 1 1 0 1 2 2 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 0 1 2 1 0 0 0 0 1 0 1 1 0 2 1 1 2 0 1 0 1 0 1 1 2 2 0 1 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 2 2 2 0 0 2 0 0 0 0 0 1 1 2 1\n"," 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 2 2 0 1\n"," 1 2 2 0 1 0 0 1 0 1 2 0 2 1 1 0 0 0 0 1 0 2 0 1 0 1 0 2 2 2 1 2 0 2 0 1 0\n"," 0 0 0 1 2 1 1 0 0 1 0 1 1 2 0 1 0 1 1 2 0 1 0 0 2 0 0 0 1 0 0 0]\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.85      0.82       336\n","           1       0.78      0.82      0.80       329\n","           2       0.78      0.55      0.64       144\n","\n","    accuracy                           0.78       809\n","   macro avg       0.78      0.74      0.75       809\n","weighted avg       0.78      0.78      0.78       809\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Saved model: openai-clip-vit-base-patch32_score_0.7548\n","Epoch 2/10, Train Loss: 0.4520, Validation Loss: 0.6761\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 1/51 [00:03<02:30,  3.00s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][0/51] Elapsed 0m 2s (remain 2m 23s) Loss: 0.3163 (0.3163) Grad: 2.5648\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 51/51 [02:11<00:00,  2.57s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][50/51] Elapsed 2m 11s (remain 0m 0s) Loss: 0.2614 (0.3896) Grad: 9.5256\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 1/13 [00:00<00:09,  1.30it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [0/13] Elapsed 0m 0s (remain 0m 9s) Loss: 0.7910 (0.7910)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:09<00:00,  1.31it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [12/13] Elapsed 0m 9s (remain 0m 0s) Loss: 0.2983 (0.6438)\n","[2 2 0 0 1 1 0 0 1 1 1 2 2 2 0 0 1 2 1 0 1 1 1 0 1 0 1 0 1 0 2 2 1 0 1 1 1\n"," 0 2 0 0 0 2 0 2 1 0 1 1 1 1 0 0 1 1 0 1 2 0 1 0 2 1 1 0 1 0 0 1 1 0 0 1 1\n"," 1 0 2 0 1 1 0 1 1 0 2 1 1 0 2 1 0 0 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 0\n"," 1 1 1 0 0 1 2 2 0 1 0 1 0 1 1 0 2 1 0 1 2 2 1 1 0 0 0 1 2 0 1 1 0 0 0 2 2\n"," 0 1 0 2 1 1 1 0 0 2 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 2 0 0 1 0 1 0 1 1 0 1 1 2 0 2 1 1 2 2 1 0 0 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 2 1 0 0 1 0 0 0 1 2 1 1 1 2 0 0 0 0 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 2 1 0 0 1 1 1\n"," 2 1 1 0 0 2 0 2 1 2 1 1 1 1 0 1 0 1 2 0 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 2 0 0 1 2 1 0 0 2 0 1 1 0 1 1 1 2 2 0 1 0 0\n"," 1 0 0 0 2 1 1 1 1 0 0 1 0 2 0 1 1 0 0 0 1 2 0 1 0 2 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 0 2 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 2 0 1 1 0 1 0 0 1 1 0 2 0 1 0 1 1 0 2 0 0 1 1 1 0 0 1 0 1 2 0 1 2\n"," 1 0 0 1 0 0 1 2 0 0 0 0 0 1 2 1 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 0 1 1 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 1 1 0 1 2 0 2 0 1 0 0 1 1 2 1 2 1 0 0 1 2 0 0 1 0 0 2 1 0 2 0 0 1 0\n"," 1 0 2 0 0 0 2 0 0 1 1 1 0 0 1 2 2 0 0 1 0 2 2 2 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 1 2 2 1 2 0 0 1 1 0 1 2 0 2 0 1 1 1 0 0 1 1 0 1 1 2 0 2 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 2 2 1 1 0 0 0 1 1 1 0 2 0 0 1 0 0 2 2 2 0 0 1 0 0 0 0 1 1 1 0 1\n"," 0 1 0 2 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 2 0 1 1 2 0 0 1 0 0 0 1 0 0 2 2 0 2\n"," 1 1 1 0 0 0 0 1 0 1 1 0 2 1 1 0 0 0 0 2 0 2 0 1 2 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","[0 1 1 0 1 1 0 0 2 1 1 2 1 1 0 0 1 2 1 0 1 0 1 0 1 0 1 0 1 0 0 2 1 1 0 1 1\n"," 0 0 0 0 1 1 0 2 2 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 2 1 1 0 1 0 0 1 0 0 0 0 1\n"," 1 0 2 0 1 1 1 1 1 0 1 1 1 0 2 1 0 1 0 1 2 0 1 0 0 1 0 2 1 1 2 2 1 0 0 0 0\n"," 2 1 1 0 0 1 2 1 0 1 0 0 0 1 0 0 1 1 0 1 2 2 1 1 0 0 0 0 2 0 1 1 0 0 0 0 2\n"," 0 1 0 1 1 1 1 1 0 1 1 0 0 0 2 2 0 0 0 2 0 0 0 1 1 1 1 1 0 2 0 1 1 0 1 1 1\n"," 2 0 0 0 1 0 1 1 1 0 1 1 1 2 0 0 1 1 1 2 1 0 0 1 0 2 1 0 0 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 2 1 0 0 0 1 2 1 1 1 2 0 0 0 1 0 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 2 0 0 1 1 1\n"," 2 1 1 0 0 2 0 0 1 2 1 1 0 1 0 1 0 1 2 1 1 1 2 0 1 0 1 0 1 0 1 1 1 0 0 1 1\n"," 0 0 0 1 1 1 0 1 1 0 2 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 2 0 1 0 1\n"," 1 0 0 0 2 1 1 1 1 0 2 1 0 2 1 1 1 0 0 0 1 2 2 1 0 1 0 0 0 1 2 1 0 2 1 0 1\n"," 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 2\n"," 2 0 0 1 0 0 1 2 2 0 1 2 0 1 2 1 0 2 0 0 1 1 2 2 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 1 1 2 1 2 1 0 1 0 1 0 0 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 0 1 0 1 0 0 2 0 1 0 0 0 1 2 2 0 1 0 0 1 0 0 0 1 0 0 2 0 0 2 1 0 1 0\n"," 1 0 2 0 0 0 1 0 1 1 1 1 0 1 1 2 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 0 1 2 1 0 0 1 0 1 1 1 1 0 1 1 1 2 0 1 0 1 0 1 1 2 2 0 1 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 2 2 2 0 0 2 0 0 0 0 0 1 1 2 1\n"," 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 2 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 2 2 0 1\n"," 1 2 1 0 1 0 0 1 0 1 2 0 2 1 1 0 0 0 0 1 0 2 0 1 0 1 0 2 2 2 1 2 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 0 1 0 1 1 2 0 1 0 0 2 1 0 0 1 0 0 0]\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.85      0.83       336\n","           1       0.79      0.86      0.83       329\n","           2       0.76      0.56      0.65       144\n","\n","    accuracy                           0.80       809\n","   macro avg       0.79      0.76      0.77       809\n","weighted avg       0.80      0.80      0.80       809\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Saved model: openai-clip-vit-base-patch32_score_0.7686\n","Epoch 3/10, Train Loss: 0.3896, Validation Loss: 0.6438\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 1/51 [00:02<02:28,  2.96s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][0/51] Elapsed 0m 2s (remain 2m 21s) Loss: 0.3979 (0.3979) Grad: 3.1550\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 51/51 [02:11<00:00,  2.57s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][50/51] Elapsed 2m 11s (remain 0m 0s) Loss: 0.3827 (0.3313) Grad: 17.1887\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 1/13 [00:00<00:09,  1.28it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [0/13] Elapsed 0m 0s (remain 0m 9s) Loss: 0.7175 (0.7175)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:09<00:00,  1.33it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [12/13] Elapsed 0m 9s (remain 0m 0s) Loss: 0.3235 (0.6643)\n","[2 2 0 0 1 1 0 0 1 1 1 2 2 2 0 0 1 2 1 0 1 1 1 0 1 0 1 0 1 0 2 2 1 0 1 1 1\n"," 0 2 0 0 0 2 0 2 1 0 1 1 1 1 0 0 1 1 0 1 2 0 1 0 2 1 1 0 1 0 0 1 1 0 0 1 1\n"," 1 0 2 0 1 1 0 1 1 0 2 1 1 0 2 1 0 0 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 0\n"," 1 1 1 0 0 1 2 2 0 1 0 1 0 1 1 0 2 1 0 1 2 2 1 1 0 0 0 1 2 0 1 1 0 0 0 2 2\n"," 0 1 0 2 1 1 1 0 0 2 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 2 0 0 1 0 1 0 1 1 0 1 1 2 0 2 1 1 2 2 1 0 0 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 2 1 0 0 1 0 0 0 1 2 1 1 1 2 0 0 0 0 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 2 1 0 0 1 1 1\n"," 2 1 1 0 0 2 0 2 1 2 1 1 1 1 0 1 0 1 2 0 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 2 0 0 1 2 1 0 0 2 0 1 1 0 1 1 1 2 2 0 1 0 0\n"," 1 0 0 0 2 1 1 1 1 0 0 1 0 2 0 1 1 0 0 0 1 2 0 1 0 2 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 0 2 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 2 0 1 1 0 1 0 0 1 1 0 2 0 1 0 1 1 0 2 0 0 1 1 1 0 0 1 0 1 2 0 1 2\n"," 1 0 0 1 0 0 1 2 0 0 0 0 0 1 2 1 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 0 1 1 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 1 1 0 1 2 0 2 0 1 0 0 1 1 2 1 2 1 0 0 1 2 0 0 1 0 0 2 1 0 2 0 0 1 0\n"," 1 0 2 0 0 0 2 0 0 1 1 1 0 0 1 2 2 0 0 1 0 2 2 2 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 1 2 2 1 2 0 0 1 1 0 1 2 0 2 0 1 1 1 0 0 1 1 0 1 1 2 0 2 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 2 2 1 1 0 0 0 1 1 1 0 2 0 0 1 0 0 2 2 2 0 0 1 0 0 0 0 1 1 1 0 1\n"," 0 1 0 2 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 2 0 1 1 2 0 0 1 0 0 0 1 0 0 2 2 0 2\n"," 1 1 1 0 0 0 0 1 0 1 1 0 2 1 1 0 0 0 0 2 0 2 0 1 2 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","[0 1 1 0 1 1 0 0 1 1 1 2 1 1 0 0 1 2 1 0 1 0 1 0 1 0 1 0 1 0 0 2 1 1 0 1 1\n"," 0 0 0 0 1 1 0 2 2 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 2 1 1 0 1 0 0 1 0 0 0 0 1\n"," 1 0 2 0 1 1 1 1 1 0 1 1 1 0 2 1 0 1 0 1 2 0 1 0 0 1 0 2 1 1 2 2 1 0 0 0 0\n"," 2 1 0 0 0 1 2 0 0 1 0 0 0 1 0 0 1 1 0 1 2 2 1 1 0 0 0 0 2 0 1 1 0 0 0 0 2\n"," 0 1 0 1 1 1 1 1 0 1 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 1 0 1 1 1\n"," 2 0 0 0 1 0 1 1 1 0 1 1 1 2 0 0 1 1 1 2 1 0 0 1 0 2 1 0 0 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 2 1 0 0 0 1 2 1 1 1 2 0 0 0 1 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 2 2 0 0 1 1 1\n"," 2 1 1 0 0 2 0 1 1 2 1 1 0 1 0 1 0 1 2 2 1 1 2 0 1 0 1 0 1 0 1 1 1 0 0 1 1\n"," 0 0 0 1 1 1 0 1 1 0 2 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 2 0 1 0 1\n"," 1 1 0 0 2 1 1 1 1 0 2 1 0 2 1 1 1 0 0 0 1 2 2 1 0 1 0 0 0 1 2 1 0 2 1 0 1\n"," 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 2 2 0 2 1 0 0 1 0 1 2 0\n"," 1 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 2\n"," 2 0 0 1 0 0 1 2 0 0 2 2 0 1 2 1 0 2 0 0 1 1 2 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 1 0 0 1 0 1 2 2 2 1 1 1 1 2 1 0 1 0 1 2 1 0 1 1 1 0 1 2 1 0 0\n"," 0 1 0 0 1 0 1 0 0 2 0 1 0 0 0 1 2 2 2 1 0 0 1 0 0 0 1 0 0 2 0 0 2 1 0 1 0\n"," 1 0 2 0 0 0 1 0 1 1 1 1 0 1 1 2 0 0 0 1 0 2 0 0 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 0 1 2 1 0 0 1 0 1 1 1 1 0 1 0 1 2 1 2 0 1 0 1 1 2 2 0 1 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 1 2 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1 2 2 2 0 0 1 0 0 0 0 0 1 1 2 1\n"," 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 2 2 0 1\n"," 0 2 1 0 1 0 0 1 0 1 2 0 2 1 1 0 0 0 0 1 0 2 0 1 0 1 0 2 2 2 1 2 0 2 0 1 0\n"," 0 0 2 1 2 1 1 0 0 1 0 1 1 2 0 1 0 1 1 2 0 1 0 0 2 0 0 0 1 0 0 0]\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.84      0.84       336\n","           1       0.81      0.88      0.84       329\n","           2       0.79      0.60      0.68       144\n","\n","    accuracy                           0.81       809\n","   macro avg       0.81      0.77      0.79       809\n","weighted avg       0.81      0.81      0.81       809\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Saved model: openai-clip-vit-base-patch32_score_0.7853\n","Epoch 4/10, Train Loss: 0.3313, Validation Loss: 0.6643\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 1/51 [00:02<02:28,  2.97s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: [5][0/51] Elapsed 0m 2s (remain 2m 21s) Loss: 0.3234 (0.3234) Grad: 7.1236\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 51/51 [02:10<00:00,  2.57s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [5][50/51] Elapsed 2m 10s (remain 0m 0s) Loss: 0.2907 (0.2887) Grad: 10.7329\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 1/13 [00:00<00:09,  1.26it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [0/13] Elapsed 0m 0s (remain 0m 9s) Loss: 0.6382 (0.6382)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:09<00:00,  1.34it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [12/13] Elapsed 0m 9s (remain 0m 0s) Loss: 0.2412 (0.6486)\n","[2 2 0 0 1 1 0 0 1 1 1 2 2 2 0 0 1 2 1 0 1 1 1 0 1 0 1 0 1 0 2 2 1 0 1 1 1\n"," 0 2 0 0 0 2 0 2 1 0 1 1 1 1 0 0 1 1 0 1 2 0 1 0 2 1 1 0 1 0 0 1 1 0 0 1 1\n"," 1 0 2 0 1 1 0 1 1 0 2 1 1 0 2 1 0 0 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 0\n"," 1 1 1 0 0 1 2 2 0 1 0 1 0 1 1 0 2 1 0 1 2 2 1 1 0 0 0 1 2 0 1 1 0 0 0 2 2\n"," 0 1 0 2 1 1 1 0 0 2 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 2 0 0 1 0 1 0 1 1 0 1 1 2 0 2 1 1 2 2 1 0 0 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 2 1 0 0 1 0 0 0 1 2 1 1 1 2 0 0 0 0 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 2 1 0 0 1 1 1\n"," 2 1 1 0 0 2 0 2 1 2 1 1 1 1 0 1 0 1 2 0 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 2 0 0 1 2 1 0 0 2 0 1 1 0 1 1 1 2 2 0 1 0 0\n"," 1 0 0 0 2 1 1 1 1 0 0 1 0 2 0 1 1 0 0 0 1 2 0 1 0 2 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 0 2 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 2 0 1 1 0 1 0 0 1 1 0 2 0 1 0 1 1 0 2 0 0 1 1 1 0 0 1 0 1 2 0 1 2\n"," 1 0 0 1 0 0 1 2 0 0 0 0 0 1 2 1 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 0 1 1 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 1 1 0 1 2 0 2 0 1 0 0 1 1 2 1 2 1 0 0 1 2 0 0 1 0 0 2 1 0 2 0 0 1 0\n"," 1 0 2 0 0 0 2 0 0 1 1 1 0 0 1 2 2 0 0 1 0 2 2 2 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 1 2 2 1 2 0 0 1 1 0 1 2 0 2 0 1 1 1 0 0 1 1 0 1 1 2 0 2 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 2 2 1 1 0 0 0 1 1 1 0 2 0 0 1 0 0 2 2 2 0 0 1 0 0 0 0 1 1 1 0 1\n"," 0 1 0 2 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 2 0 1 1 2 0 0 1 0 0 0 1 0 0 2 2 0 2\n"," 1 1 1 0 0 0 0 1 0 1 1 0 2 1 1 0 0 0 0 2 0 2 0 1 2 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","[0 2 1 0 1 1 0 0 1 1 1 2 2 1 0 0 1 2 1 0 1 0 1 0 1 0 1 0 1 0 0 2 1 1 0 1 1\n"," 0 0 0 0 0 1 0 2 2 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 2 1 1 0 1 0 0 1 0 1 0 0 1\n"," 1 0 2 0 1 1 1 1 1 0 0 1 1 0 2 1 0 1 0 1 2 0 1 0 0 1 0 1 1 1 2 2 1 0 1 0 0\n"," 2 1 0 0 0 1 2 0 0 1 0 1 0 1 1 1 1 1 0 1 2 2 1 1 0 0 0 0 2 0 1 1 0 0 0 0 2\n"," 0 1 0 1 1 1 1 1 0 1 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 1 0 1 1 1\n"," 2 0 0 0 1 0 1 1 1 0 1 1 1 2 0 0 1 1 1 2 1 0 0 1 0 2 1 0 0 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 2 1 1 1 2 0 0 0 1 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 2 0 0 1 1 1\n"," 2 1 1 0 0 1 0 1 1 2 1 1 0 1 0 1 0 1 2 1 1 1 2 0 1 0 1 0 1 0 1 1 1 0 0 1 1\n"," 0 0 0 1 1 1 0 1 1 0 2 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 0 1\n"," 1 0 0 0 2 1 1 1 1 0 2 1 0 2 1 1 1 0 0 0 1 2 1 1 0 1 0 0 0 1 2 1 0 1 1 0 1\n"," 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 2 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 2\n"," 2 0 0 1 0 0 1 2 0 0 1 2 0 1 2 0 0 2 0 0 1 1 2 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 1 0 0 1 0 1 2 2 2 1 1 1 1 1 1 0 1 0 1 2 1 0 1 1 1 0 1 2 1 0 0\n"," 0 1 0 0 1 0 1 0 0 2 0 1 0 0 0 1 2 1 2 1 0 0 1 0 0 0 1 0 0 2 0 1 2 1 0 1 0\n"," 1 0 2 0 0 0 1 0 1 1 1 1 0 1 1 2 0 0 0 1 0 2 0 0 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 0 1 2 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 2 2 0 1 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 1 2 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 2 2 2 0 0 1 0 0 0 0 0 1 1 2 1\n"," 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 2 0 1 1 1 0 0 1 0 0 2 2 0 1\n"," 0 2 1 0 1 0 0 1 0 1 2 0 2 1 1 0 0 0 0 1 0 2 0 1 0 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 1 1 0 1 1 2 0 1 0 1 1 2 0 1 0 0 2 1 0 0 1 0 0 0]\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.83      0.84       336\n","           1       0.79      0.91      0.84       329\n","           2       0.86      0.58      0.69       144\n","\n","    accuracy                           0.82       809\n","   macro avg       0.83      0.77      0.79       809\n","weighted avg       0.82      0.82      0.81       809\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Saved model: openai-clip-vit-base-patch32_score_0.7914\n","Epoch 5/10, Train Loss: 0.2887, Validation Loss: 0.6486\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 1/51 [00:02<02:25,  2.90s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: [6][0/51] Elapsed 0m 2s (remain 2m 18s) Loss: 0.3769 (0.3769) Grad: 9.2370\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 51/51 [02:10<00:00,  2.56s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [6][50/51] Elapsed 2m 10s (remain 0m 0s) Loss: 0.4241 (0.2490) Grad: 36.2116\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 1/13 [00:00<00:09,  1.26it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [0/13] Elapsed 0m 0s (remain 0m 9s) Loss: 0.5432 (0.5432)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:09<00:00,  1.32it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [12/13] Elapsed 0m 9s (remain 0m 0s) Loss: 0.1352 (0.6425)\n","[2 2 0 0 1 1 0 0 1 1 1 2 2 2 0 0 1 2 1 0 1 1 1 0 1 0 1 0 1 0 2 2 1 0 1 1 1\n"," 0 2 0 0 0 2 0 2 1 0 1 1 1 1 0 0 1 1 0 1 2 0 1 0 2 1 1 0 1 0 0 1 1 0 0 1 1\n"," 1 0 2 0 1 1 0 1 1 0 2 1 1 0 2 1 0 0 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 0\n"," 1 1 1 0 0 1 2 2 0 1 0 1 0 1 1 0 2 1 0 1 2 2 1 1 0 0 0 1 2 0 1 1 0 0 0 2 2\n"," 0 1 0 2 1 1 1 0 0 2 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 2 0 0 1 0 1 0 1 1 0 1 1 2 0 2 1 1 2 2 1 0 0 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 2 1 0 0 1 0 0 0 1 2 1 1 1 2 0 0 0 0 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 2 1 0 0 1 1 1\n"," 2 1 1 0 0 2 0 2 1 2 1 1 1 1 0 1 0 1 2 0 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 2 0 0 1 2 1 0 0 2 0 1 1 0 1 1 1 2 2 0 1 0 0\n"," 1 0 0 0 2 1 1 1 1 0 0 1 0 2 0 1 1 0 0 0 1 2 0 1 0 2 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 0 2 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 2 0 1 1 0 1 0 0 1 1 0 2 0 1 0 1 1 0 2 0 0 1 1 1 0 0 1 0 1 2 0 1 2\n"," 1 0 0 1 0 0 1 2 0 0 0 0 0 1 2 1 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 0 1 1 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 1 1 0 1 2 0 2 0 1 0 0 1 1 2 1 2 1 0 0 1 2 0 0 1 0 0 2 1 0 2 0 0 1 0\n"," 1 0 2 0 0 0 2 0 0 1 1 1 0 0 1 2 2 0 0 1 0 2 2 2 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 1 2 2 1 2 0 0 1 1 0 1 2 0 2 0 1 1 1 0 0 1 1 0 1 1 2 0 2 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 2 2 1 1 0 0 0 1 1 1 0 2 0 0 1 0 0 2 2 2 0 0 1 0 0 0 0 1 1 1 0 1\n"," 0 1 0 2 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 2 0 1 1 2 0 0 1 0 0 0 1 0 0 2 2 0 2\n"," 1 1 1 0 0 0 0 1 0 1 1 0 2 1 1 0 0 0 0 2 0 2 0 1 2 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","[2 2 1 0 1 1 0 0 1 1 1 2 2 1 0 0 1 2 1 0 1 0 1 0 1 0 1 0 1 0 0 2 1 0 0 1 1\n"," 0 0 0 0 0 1 0 2 2 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 2 1 1 0 1 0 0 1 0 0 0 0 1\n"," 1 0 2 0 1 1 1 1 1 0 0 1 1 0 2 1 0 1 0 1 2 0 1 0 0 1 0 2 1 1 2 2 1 0 0 0 0\n"," 2 1 0 0 0 1 2 0 0 1 0 0 0 1 0 0 1 1 0 1 2 2 1 1 0 0 0 0 2 0 1 1 0 0 0 0 2\n"," 0 1 0 1 1 1 1 1 0 1 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 1 0 1 1 1\n"," 2 0 0 0 1 0 1 1 1 2 1 1 1 2 0 0 1 1 1 2 1 0 0 1 0 2 1 0 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 2 1 1 1 2 0 0 0 1 0 1 1 1 2 0\n"," 1 1 0 1 1 1 2 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 2 0 0 1 1 1\n"," 2 1 1 0 0 1 0 1 1 2 1 1 0 1 0 1 0 1 2 1 1 1 2 0 1 0 1 0 1 0 1 1 1 0 0 1 1\n"," 0 0 0 1 1 1 0 1 1 0 2 1 0 1 1 0 0 1 1 2 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1\n"," 1 0 0 0 2 1 1 1 1 0 2 1 0 2 1 1 1 0 0 0 1 2 1 1 0 1 0 0 0 1 2 1 0 1 1 0 1\n"," 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 2 1 0 2 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 2\n"," 2 0 0 1 0 0 1 2 0 0 1 2 0 1 2 0 0 2 0 2 1 1 0 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 1 0 0 1 0 1 2 2 2 1 1 1 1 1 1 0 1 0 1 2 1 0 1 1 1 0 1 2 1 0 0\n"," 0 1 0 0 1 0 1 0 0 2 0 1 0 0 0 1 2 1 2 0 0 0 1 0 0 0 1 0 0 2 0 0 2 1 0 1 0\n"," 1 0 2 0 0 0 1 0 1 1 1 1 0 1 1 2 0 0 0 1 0 2 0 0 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 0 1 2 1 2 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 2 2 0 1 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 1 2 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 2 2 2 0 0 1 0 0 0 0 0 1 1 2 1\n"," 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 2 0 1 1 1 0 0 1 0 0 2 2 0 2\n"," 0 2 1 0 0 0 0 1 0 1 2 0 2 1 1 0 0 0 0 1 0 2 0 1 0 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 1 0 0 1 0 0 0]\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.85      0.84       336\n","           1       0.81      0.89      0.85       329\n","           2       0.84      0.63      0.72       144\n","\n","    accuracy                           0.82       809\n","   macro avg       0.83      0.79      0.80       809\n","weighted avg       0.83      0.82      0.82       809\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Saved model: openai-clip-vit-base-patch32_score_0.8029\n","Epoch 6/10, Train Loss: 0.2490, Validation Loss: 0.6425\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 1/51 [00:02<02:27,  2.96s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: [7][0/51] Elapsed 0m 2s (remain 2m 21s) Loss: 0.1594 (0.1594) Grad: 32.8946\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 51/51 [02:10<00:00,  2.56s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [7][50/51] Elapsed 2m 10s (remain 0m 0s) Loss: 0.0668 (0.2056) Grad: 2.5356\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 1/13 [00:00<00:09,  1.23it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [0/13] Elapsed 0m 0s (remain 0m 9s) Loss: 0.6131 (0.6131)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:09<00:00,  1.33it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [12/13] Elapsed 0m 9s (remain 0m 0s) Loss: 0.1745 (0.6216)\n","[2 2 0 0 1 1 0 0 1 1 1 2 2 2 0 0 1 2 1 0 1 1 1 0 1 0 1 0 1 0 2 2 1 0 1 1 1\n"," 0 2 0 0 0 2 0 2 1 0 1 1 1 1 0 0 1 1 0 1 2 0 1 0 2 1 1 0 1 0 0 1 1 0 0 1 1\n"," 1 0 2 0 1 1 0 1 1 0 2 1 1 0 2 1 0 0 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 0\n"," 1 1 1 0 0 1 2 2 0 1 0 1 0 1 1 0 2 1 0 1 2 2 1 1 0 0 0 1 2 0 1 1 0 0 0 2 2\n"," 0 1 0 2 1 1 1 0 0 2 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 2 0 0 1 0 1 0 1 1 0 1 1 2 0 2 1 1 2 2 1 0 0 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 2 1 0 0 1 0 0 0 1 2 1 1 1 2 0 0 0 0 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 2 1 0 0 1 1 1\n"," 2 1 1 0 0 2 0 2 1 2 1 1 1 1 0 1 0 1 2 0 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 2 0 0 1 2 1 0 0 2 0 1 1 0 1 1 1 2 2 0 1 0 0\n"," 1 0 0 0 2 1 1 1 1 0 0 1 0 2 0 1 1 0 0 0 1 2 0 1 0 2 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 0 2 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 2 0 1 1 0 1 0 0 1 1 0 2 0 1 0 1 1 0 2 0 0 1 1 1 0 0 1 0 1 2 0 1 2\n"," 1 0 0 1 0 0 1 2 0 0 0 0 0 1 2 1 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 0 1 1 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 1 1 0 1 2 0 2 0 1 0 0 1 1 2 1 2 1 0 0 1 2 0 0 1 0 0 2 1 0 2 0 0 1 0\n"," 1 0 2 0 0 0 2 0 0 1 1 1 0 0 1 2 2 0 0 1 0 2 2 2 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 1 2 2 1 2 0 0 1 1 0 1 2 0 2 0 1 1 1 0 0 1 1 0 1 1 2 0 2 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 2 2 1 1 0 0 0 1 1 1 0 2 0 0 1 0 0 2 2 2 0 0 1 0 0 0 0 1 1 1 0 1\n"," 0 1 0 2 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 2 0 1 1 2 0 0 1 0 0 0 1 0 0 2 2 0 2\n"," 1 1 1 0 0 0 0 1 0 1 1 0 2 1 1 0 0 0 0 2 0 2 0 1 2 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","[2 2 1 0 1 1 0 0 1 1 1 2 2 1 0 0 1 2 1 0 1 0 1 0 1 0 1 0 1 0 0 2 1 1 0 1 1\n"," 0 0 0 0 1 1 0 2 2 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 2 1 1 0 1 0 0 1 0 1 0 0 1\n"," 1 0 2 0 1 1 1 1 1 0 0 1 1 0 2 1 0 1 0 1 2 0 1 0 0 1 0 1 1 1 2 2 1 0 0 0 0\n"," 2 1 0 0 0 1 2 0 0 1 0 1 0 1 1 0 1 1 0 1 2 2 1 1 0 0 0 0 2 0 1 1 0 0 0 0 2\n"," 0 1 0 1 1 1 1 1 0 1 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 1 0 1 1 1\n"," 2 0 0 0 1 0 1 1 1 1 1 1 1 2 0 0 1 1 1 2 1 0 0 1 0 2 1 0 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 2 1 1 1 2 0 0 0 1 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 1 0 1 2 2 0 0 1 1 1\n"," 2 1 1 0 0 1 0 1 1 2 1 1 1 1 0 1 0 1 2 1 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 1 1 0 1 1 0 2 1 0 1 1 0 0 0 1 2 1 0 0 0 1 0 1 0 1 1 0 1 2 0 1 0 1\n"," 1 2 0 0 2 1 1 1 1 0 2 1 0 2 1 1 1 0 0 0 1 2 2 1 0 1 0 0 0 1 2 1 0 1 1 2 1\n"," 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 2 1 0 2 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 2 1 0 1 0 1 0 0 0 0 1 1 0 1 2\n"," 2 0 0 1 0 0 1 2 0 0 1 2 0 1 2 1 0 2 0 0 1 1 0 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 1 0 0 1 0 1 2 2 2 1 1 1 1 2 1 0 1 0 1 2 1 0 1 1 1 0 1 2 1 0 0\n"," 0 1 0 1 1 0 1 0 2 2 0 1 0 0 0 1 2 1 2 1 0 0 1 2 0 2 1 0 0 2 0 0 2 1 0 1 0\n"," 1 0 2 0 0 0 1 0 1 1 1 1 0 1 1 2 2 0 0 1 0 2 2 0 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 0 1 2 1 2 0 1 0 1 1 1 2 0 1 0 1 1 1 1 0 1 1 2 1 2 2 0 1 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 1 2 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 2 2 2 0 0 1 0 0 0 0 0 1 1 2 1\n"," 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 2 0 1 1 2 0 0 1 0 0 2 2 0 2\n"," 0 2 1 0 0 0 0 1 0 1 2 0 2 1 1 0 0 0 0 1 0 2 0 1 0 1 0 2 2 2 1 1 0 2 0 1 2\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 1 2 0 1 0 0 0]\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.83      0.85       336\n","           1       0.82      0.92      0.87       329\n","           2       0.83      0.72      0.77       144\n","\n","    accuracy                           0.85       809\n","   macro avg       0.84      0.82      0.83       809\n","weighted avg       0.85      0.85      0.85       809\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Saved model: openai-clip-vit-base-patch32_score_0.8309\n","Epoch 7/10, Train Loss: 0.2056, Validation Loss: 0.6216\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 1/51 [00:02<02:26,  2.94s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: [8][0/51] Elapsed 0m 2s (remain 2m 20s) Loss: 0.1173 (0.1173) Grad: 5.6827\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 51/51 [02:11<00:00,  2.58s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [8][50/51] Elapsed 2m 11s (remain 0m 0s) Loss: 0.1462 (0.1805) Grad: 41.7379\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 1/13 [00:00<00:09,  1.22it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [0/13] Elapsed 0m 0s (remain 0m 9s) Loss: 0.5573 (0.5573)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:09<00:00,  1.32it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [12/13] Elapsed 0m 9s (remain 0m 0s) Loss: 0.0420 (0.6264)\n","[2 2 0 0 1 1 0 0 1 1 1 2 2 2 0 0 1 2 1 0 1 1 1 0 1 0 1 0 1 0 2 2 1 0 1 1 1\n"," 0 2 0 0 0 2 0 2 1 0 1 1 1 1 0 0 1 1 0 1 2 0 1 0 2 1 1 0 1 0 0 1 1 0 0 1 1\n"," 1 0 2 0 1 1 0 1 1 0 2 1 1 0 2 1 0 0 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 0\n"," 1 1 1 0 0 1 2 2 0 1 0 1 0 1 1 0 2 1 0 1 2 2 1 1 0 0 0 1 2 0 1 1 0 0 0 2 2\n"," 0 1 0 2 1 1 1 0 0 2 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 2 0 0 1 0 1 0 1 1 0 1 1 2 0 2 1 1 2 2 1 0 0 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 2 1 0 0 1 0 0 0 1 2 1 1 1 2 0 0 0 0 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 2 1 0 0 1 1 1\n"," 2 1 1 0 0 2 0 2 1 2 1 1 1 1 0 1 0 1 2 0 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 2 0 0 1 2 1 0 0 2 0 1 1 0 1 1 1 2 2 0 1 0 0\n"," 1 0 0 0 2 1 1 1 1 0 0 1 0 2 0 1 1 0 0 0 1 2 0 1 0 2 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 0 2 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 2 0 1 1 0 1 0 0 1 1 0 2 0 1 0 1 1 0 2 0 0 1 1 1 0 0 1 0 1 2 0 1 2\n"," 1 0 0 1 0 0 1 2 0 0 0 0 0 1 2 1 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 0 1 1 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 1 1 0 1 2 0 2 0 1 0 0 1 1 2 1 2 1 0 0 1 2 0 0 1 0 0 2 1 0 2 0 0 1 0\n"," 1 0 2 0 0 0 2 0 0 1 1 1 0 0 1 2 2 0 0 1 0 2 2 2 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 1 2 2 1 2 0 0 1 1 0 1 2 0 2 0 1 1 1 0 0 1 1 0 1 1 2 0 2 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 2 2 1 1 0 0 0 1 1 1 0 2 0 0 1 0 0 2 2 2 0 0 1 0 0 0 0 1 1 1 0 1\n"," 0 1 0 2 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 2 0 1 1 2 0 0 1 0 0 0 1 0 0 2 2 0 2\n"," 1 1 1 0 0 0 0 1 0 1 1 0 2 1 1 0 0 0 0 2 0 2 0 1 2 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","[0 2 1 0 1 1 0 0 1 1 1 2 2 1 0 0 1 2 1 0 1 0 1 0 1 0 1 0 1 0 0 2 1 0 0 1 1\n"," 0 0 0 0 0 1 0 2 2 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 2 1 1 0 1 0 0 1 0 0 0 0 1\n"," 1 0 2 0 1 1 1 1 1 0 0 1 1 0 2 1 0 1 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 0\n"," 2 1 0 0 0 1 2 0 0 1 0 0 0 1 0 0 1 1 0 1 2 2 1 1 0 0 0 0 2 0 1 1 0 0 0 0 2\n"," 0 1 0 1 1 1 1 1 0 1 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 0 0 0 1 0 1 1 0 2 1 1 1 2 0 0 1 1 1 2 1 0 0 1 0 2 1 0 0 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 1 2 1 1 1 2 0 0 0 1 0 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 2 2 0 0 1 1 1\n"," 2 1 1 0 0 2 0 0 1 2 1 1 1 1 0 1 0 1 2 1 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 1 1 0 1 1 0 2 0 0 1 1 0 0 0 1 2 1 0 0 0 1 2 1 0 1 1 0 1 2 0 1 0 1\n"," 1 0 0 0 2 1 1 1 1 0 2 1 0 2 1 1 1 0 0 0 1 2 2 1 0 1 0 0 0 1 2 1 0 1 1 2 0\n"," 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 0 1 0 2 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 0 0 0 0 1 1 1 0 0 1 1 0 2 0 1 0 1 1 0 2 1 0 1 0 1 0 0 0 0 1 1 0 1 2\n"," 2 0 0 1 0 0 1 2 0 0 1 2 0 1 2 1 0 2 0 0 1 1 0 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 1 1 0 1 2 1 0 1 0 1 2 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 0 1 0 1 0 2 2 0 1 0 0 0 1 2 1 2 0 0 0 1 2 0 0 2 0 0 1 0 0 2 1 0 1 0\n"," 1 0 2 0 0 0 1 0 1 1 1 1 0 1 1 2 2 0 0 1 0 2 2 0 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 0 1 2 1 2 0 0 0 1 1 1 2 0 1 0 1 1 1 1 0 1 0 2 0 2 2 0 1 0 0 0 2 0 1 1 1\n"," 1 0 0 0 1 1 2 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 2 2 2 0 0 1 0 0 0 0 0 1 1 2 1\n"," 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 2 0 0 1 2 0 0 1 0 0 2 2 0 2\n"," 0 2 1 0 0 0 0 1 0 1 2 0 2 1 1 0 0 0 0 1 0 2 0 1 0 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.88      0.86       336\n","           1       0.85      0.87      0.86       329\n","           2       0.84      0.73      0.78       144\n","\n","    accuracy                           0.85       809\n","   macro avg       0.85      0.83      0.83       809\n","weighted avg       0.85      0.85      0.85       809\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Saved model: openai-clip-vit-base-patch32_score_0.8345\n","Epoch 8/10, Train Loss: 0.1805, Validation Loss: 0.6264\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 1/51 [00:02<02:28,  2.96s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: [9][0/51] Elapsed 0m 2s (remain 2m 21s) Loss: 0.1479 (0.1479) Grad: 3.6130\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 51/51 [02:11<00:00,  2.58s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [9][50/51] Elapsed 2m 11s (remain 0m 0s) Loss: 0.1367 (0.1566) Grad: 10.4167\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 1/13 [00:00<00:09,  1.21it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [0/13] Elapsed 0m 0s (remain 0m 9s) Loss: 0.5694 (0.5694)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:10<00:00,  1.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation: [12/13] Elapsed 0m 10s (remain 0m 0s) Loss: 0.1378 (0.6233)\n","[2 2 0 0 1 1 0 0 1 1 1 2 2 2 0 0 1 2 1 0 1 1 1 0 1 0 1 0 1 0 2 2 1 0 1 1 1\n"," 0 2 0 0 0 2 0 2 1 0 1 1 1 1 0 0 1 1 0 1 2 0 1 0 2 1 1 0 1 0 0 1 1 0 0 1 1\n"," 1 0 2 0 1 1 0 1 1 0 2 1 1 0 2 1 0 0 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 0\n"," 1 1 1 0 0 1 2 2 0 1 0 1 0 1 1 0 2 1 0 1 2 2 1 1 0 0 0 1 2 0 1 1 0 0 0 2 2\n"," 0 1 0 2 1 1 1 0 0 2 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 2 0 0 1 0 1 0 1 1 0 1 1 2 0 2 1 1 2 2 1 0 0 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 2 1 0 0 1 0 0 0 1 2 1 1 1 2 0 0 0 0 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 2 1 0 0 1 1 1\n"," 2 1 1 0 0 2 0 2 1 2 1 1 1 1 0 1 0 1 2 0 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 2 0 0 1 2 1 0 0 2 0 1 1 0 1 1 1 2 2 0 1 0 0\n"," 1 0 0 0 2 1 1 1 1 0 0 1 0 2 0 1 1 0 0 0 1 2 0 1 0 2 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 0 2 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 2 0 1 1 0 1 0 0 1 1 0 2 0 1 0 1 1 0 2 0 0 1 1 1 0 0 1 0 1 2 0 1 2\n"," 1 0 0 1 0 0 1 2 0 0 0 0 0 1 2 1 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 0 1 1 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 1 1 0 1 2 0 2 0 1 0 0 1 1 2 1 2 1 0 0 1 2 0 0 1 0 0 2 1 0 2 0 0 1 0\n"," 1 0 2 0 0 0 2 0 0 1 1 1 0 0 1 2 2 0 0 1 0 2 2 2 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 1 2 2 1 2 0 0 1 1 0 1 2 0 2 0 1 1 1 0 0 1 1 0 1 1 2 0 2 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 2 2 1 1 0 0 0 1 1 1 0 2 0 0 1 0 0 2 2 2 0 0 1 0 0 0 0 1 1 1 0 1\n"," 0 1 0 2 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 2 0 1 1 2 0 0 1 0 0 0 1 0 0 2 2 0 2\n"," 1 1 1 0 0 0 0 1 0 1 1 0 2 1 1 0 0 0 0 2 0 2 0 1 2 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","[2 2 1 0 1 1 0 0 1 1 1 2 1 1 0 0 1 2 1 0 1 0 1 0 1 0 1 0 1 0 2 2 1 1 0 1 1\n"," 0 0 0 0 1 1 0 2 2 0 1 1 1 1 1 0 1 1 0 1 0 0 1 0 2 1 1 0 1 0 0 1 0 1 0 1 1\n"," 1 0 2 0 1 1 1 1 1 0 0 1 1 0 2 1 0 1 0 1 2 0 1 0 0 1 2 1 1 1 2 2 1 0 0 0 0\n"," 2 1 0 0 0 1 2 0 0 1 0 0 0 1 1 0 1 1 0 1 2 2 1 1 0 0 0 0 2 0 1 1 0 0 0 1 2\n"," 0 1 0 1 1 1 1 1 0 1 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 2 0 0 1 0 1 1 1 0 1 1 1 2 0 0 1 1 1 2 1 0 0 1 0 2 1 2 0 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 2 1 1 1 2 0 0 0 1 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 2 2 0 0 1 1 1\n"," 2 1 1 0 0 1 0 1 1 2 1 1 1 1 0 1 0 1 2 1 1 1 2 0 1 0 1 2 1 2 1 1 1 0 0 1 1\n"," 0 0 0 1 1 1 0 1 1 0 2 1 0 1 1 0 0 0 1 2 1 0 0 0 1 2 1 0 1 1 0 1 2 0 1 0 1\n"," 1 0 0 0 2 1 1 1 1 0 2 1 0 2 1 1 1 0 0 0 1 2 2 1 0 1 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 2 1 0 2 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 2 1 0 1 0 1 0 0 0 0 1 1 0 1 2\n"," 2 0 0 1 0 0 1 2 0 0 1 2 0 1 2 1 0 2 0 0 1 1 0 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 1 1 0 1 2 1 0 1 0 1 2 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 0 1 0 1 0 2 2 0 1 0 0 0 1 2 1 2 0 0 0 1 2 0 0 1 0 0 1 0 0 2 1 0 1 0\n"," 1 0 2 0 0 0 1 0 1 1 1 1 0 1 1 2 2 0 0 1 0 2 2 0 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 0 1 2 1 2 0 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 2 1 2 2 0 1 0 0 0 2 0 1 1 1\n"," 1 0 0 1 1 1 2 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 2 2 2 0 0 1 0 0 0 0 0 1 1 2 1\n"," 1 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 2 0 1 1 2 0 0 1 0 0 2 2 0 2\n"," 0 2 1 0 0 0 0 1 0 1 2 0 2 1 1 0 0 0 0 2 0 2 0 1 0 1 0 2 2 0 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.85      0.86       336\n","           1       0.82      0.91      0.86       329\n","           2       0.84      0.72      0.77       144\n","\n","    accuracy                           0.85       809\n","   macro avg       0.85      0.82      0.83       809\n","weighted avg       0.85      0.85      0.85       809\n","\n","Epoch 9/10, Train Loss: 0.1566, Validation Loss: 0.6233\n"]},{"name":"stderr","output_type":"stream","text":["  2%|▏         | 1/51 [00:02<02:22,  2.86s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch: [10][0/51] Elapsed 0m 2s (remain 2m 16s) Loss: 0.0518 (0.0518) Grad: 42.3347\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 51/51 [02:12<00:00,  2.61s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [10][50/51] Elapsed 2m 12s (remain 0m 0s) Loss: 0.0224 (0.1385) Grad: 1.8575\n"]},{"name":"stderr","output_type":"stream","text":["  8%|▊         | 1/13 [00:00<00:09,  1.21it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [0/13] Elapsed 0m 0s (remain 0m 9s) Loss: 0.5171 (0.5171)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:10<00:00,  1.25it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [12/13] Elapsed 0m 10s (remain 0m 0s) Loss: 0.1954 (0.6385)\n","[2 2 0 0 1 1 0 0 1 1 1 2 2 2 0 0 1 2 1 0 1 1 1 0 1 0 1 0 1 0 2 2 1 0 1 1 1\n"," 0 2 0 0 0 2 0 2 1 0 1 1 1 1 0 0 1 1 0 1 2 0 1 0 2 1 1 0 1 0 0 1 1 0 0 1 1\n"," 1 0 2 0 1 1 0 1 1 0 2 1 1 0 2 1 0 0 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 0\n"," 1 1 1 0 0 1 2 2 0 1 0 1 0 1 1 0 2 1 0 1 2 2 1 1 0 0 0 1 2 0 1 1 0 0 0 2 2\n"," 0 1 0 2 1 1 1 0 0 2 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 2 0 0 1 0 1 0 1 1 0 1 1 2 0 2 1 1 2 2 1 0 0 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 2 1 0 0 1 0 0 0 1 2 1 1 1 2 0 0 0 0 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 2 1 0 0 1 1 1\n"," 2 1 1 0 0 2 0 2 1 2 1 1 1 1 0 1 0 1 2 0 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 2 0 0 1 2 1 0 0 2 0 1 1 0 1 1 1 2 2 0 1 0 0\n"," 1 0 0 0 2 1 1 1 1 0 0 1 0 2 0 1 1 0 0 0 1 2 0 1 0 2 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 0 2 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 2 0 1 1 0 1 0 0 1 1 0 2 0 1 0 1 1 0 2 0 0 1 1 1 0 0 1 0 1 2 0 1 2\n"," 1 0 0 1 0 0 1 2 0 0 0 0 0 1 2 1 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 0 1 1 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 1 1 0 1 2 0 2 0 1 0 0 1 1 2 1 2 1 0 0 1 2 0 0 1 0 0 2 1 0 2 0 0 1 0\n"," 1 0 2 0 0 0 2 0 0 1 1 1 0 0 1 2 2 0 0 1 0 2 2 2 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 1 2 2 1 2 0 0 1 1 0 1 2 0 2 0 1 1 1 0 0 1 1 0 1 1 2 0 2 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 2 2 1 1 0 0 0 1 1 1 0 2 0 0 1 0 0 2 2 2 0 0 1 0 0 0 0 1 1 1 0 1\n"," 0 1 0 2 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 2 0 1 1 2 0 0 1 0 0 0 1 0 0 2 2 0 2\n"," 1 1 1 0 0 0 0 1 0 1 1 0 2 1 1 0 0 0 0 2 0 2 0 1 2 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","[2 2 2 0 1 1 0 0 1 1 1 2 1 2 0 0 1 2 1 0 1 0 1 0 1 0 1 0 1 0 2 2 1 0 0 1 1\n"," 0 0 0 0 0 1 0 2 2 0 1 1 1 1 1 0 1 1 0 1 2 0 1 0 2 1 1 0 1 0 0 1 0 0 0 0 1\n"," 1 0 2 0 1 1 1 1 1 0 0 1 1 0 2 1 0 1 0 1 2 0 1 0 0 1 2 1 1 1 2 2 1 0 0 0 0\n"," 2 1 0 0 0 1 2 2 0 1 0 0 0 1 1 0 1 1 0 1 2 2 1 1 0 0 0 0 2 0 1 1 0 0 0 0 2\n"," 0 1 0 1 1 1 1 1 0 0 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 0 2 0 1 1 1\n"," 2 2 0 0 1 0 1 1 1 0 1 1 1 2 0 0 1 1 1 2 1 0 0 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 1 1 0 0 0 1 2 1 1 1 2 0 2 0 1 0 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 0 0 1 1 2 0 0 1 1 1\n"," 2 1 1 0 0 1 0 1 1 2 1 1 1 1 0 1 0 1 2 1 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 1 1 0 1 1 0 2 0 0 1 1 0 0 0 1 2 1 0 0 0 1 2 1 0 1 1 0 1 2 0 1 0 1\n"," 1 0 0 0 2 1 1 1 1 0 2 1 0 2 1 1 1 0 0 0 1 2 2 1 0 2 0 0 0 1 2 1 0 1 1 2 0\n"," 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 2 1 0 2 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 2 2 0 1 0 1 0 0 0 0 1 1 0 1 2\n"," 0 0 0 1 0 0 1 2 0 0 1 2 0 1 2 1 0 2 0 0 1 1 0 1 1 0 0 0 0 1 0 0 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 1 1 0 1 2 1 0 1 0 1 2 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 0 1 0 1 0 1 2 0 1 0 0 0 1 2 1 2 0 0 0 1 2 0 0 1 0 0 1 0 0 2 2 0 1 0\n"," 1 0 2 0 0 0 1 0 1 1 1 1 0 1 0 2 2 0 0 1 0 2 2 0 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 0 1 2 1 2 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 2 0 1 0 0 0 2 0 1 1 1\n"," 1 0 0 0 1 1 2 1 1 0 0 0 1 1 1 0 0 1 0 1 0 1 2 0 2 0 0 1 0 0 0 0 1 1 1 2 1\n"," 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 1 2 0 1 1 2 0 0 1 0 0 2 2 0 2\n"," 0 2 1 0 0 0 0 1 0 1 2 0 2 1 1 0 0 0 0 2 0 2 0 1 0 1 0 2 2 0 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 0 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","              precision    recall  f1-score   support\n","\n","           0       0.85      0.86      0.85       336\n","           1       0.85      0.88      0.86       329\n","           2       0.85      0.73      0.78       144\n","\n","    accuracy                           0.85       809\n","   macro avg       0.85      0.82      0.83       809\n","weighted avg       0.85      0.85      0.85       809\n","\n","Epoch 10/10, Train Loss: 0.1385, Validation Loss: 0.6385\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["best_score = 0\n","\n","for epoch in range(CFG.epochs):\n","    \n","    train_loss = train_loop(model, optim, train_dataloader, epoch, loss_fn)\n","\n","    valid_loss, all_preds_np, all_labels_np = valid_loop(model, valid_dataloader, loss_fn)\n","    \n","    if CFG.debug:\n","        print(all_labels_np)\n","        print(all_preds_np)\n","    \n","    score = get_score(all_labels_np, all_preds_np)\n","    \n","    report = classification_report(all_labels_np, all_preds_np, digits=4)\n","    print(report)\n","    \n","    if CFG.save_models and score > best_score:\n","        model_name = CFG.multimodal_model_id if CFG.use_multimodal else '-'.join([CFG.text_model_id, CFG.image_model_id])\n","        if CFG.use_lstm:\n","            model_name += '-lstm'\n","        if CFG.use_attn:\n","            model_name += '-attn'\n","        elif CFG.use_modal_attn:\n","            model_name += '-mattn'\n","        if CFG.use_mask_split:\n","            model_name += '-msplit'\n","        model_name = model_name.replace('/', '-') + f'_score_{score:.4f}'\n","        torch.save({'model': model.state_dict()}, f'{model_name}.pth')\n","        print(f'Saved model: {model_name}')\n","        with open(f'{model_name}_results.txt', 'w', encoding='utf-8') as fp:\n","            fp.write(report)\n","        best_score = score\n","    \n","    print(f'Epoch {epoch + 1}/{CFG.epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}')\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/plain":["39"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["del model\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Inference From Checkpoint"]},{"cell_type":"code","execution_count":43,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["ConcatArch(\n","  (mm_model): ViltModel(\n","    (embeddings): ViltEmbeddings(\n","      (text_embeddings): TextEmbeddings(\n","        (word_embeddings): Embedding(30522, 768)\n","        (position_embeddings): Embedding(40, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (patch_embeddings): ViltPatchEmbeddings(\n","        (projection): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n","      )\n","      (token_type_embeddings): Embedding(2, 768)\n","      (dropout): Dropout(p=0.0, inplace=False)\n","    )\n","    (encoder): ViltEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x ViltLayer(\n","          (attention): ViltAttention(\n","            (attention): ViltSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViltSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViltIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViltOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (pooler): ViltPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (fc1): Linear(in_features=768, out_features=256, bias=True)\n","  (hiddens): ModuleList()\n","  (fc2): Linear(in_features=256, out_features=3, bias=True)\n","  (activation): ReLU()\n","  (dropout): Dropout(p=0.1, inplace=False)\n",")"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["inf_model_name = 'dandelin-vilt-b32-mlm_score_0.8672'\n","inf_model = ConcatArch(\n","    hidden_size=CFG.mlp_hidden_size,\n","    hidden_layers=CFG.mlp_hidden_layers,\n","    dropout=CFG.mlp_dropout,\n","    num_classes=CFG.num_class,\n","    use_multimodal=CFG.use_multimodal,\n","    use_dualencoder=CFG.use_dualencoder,\n","    is_mclip=CFG.is_mclip\n",").to(CFG.device)\n","inf_model.load_state_dict(torch.load('Task 5/' + inf_model_name + '.pth', map_location=torch.device(CFG.device))['model'])\n","inf_model"]},{"cell_type":"code","execution_count":44,"metadata":{"scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  4%|▍         | 1/26 [00:01<00:40,  1.61s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation: [0/26] Elapsed 0m 1s (remain 0m 40s) Loss: 1.0176 (1.0176)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 26/26 [00:21<00:00,  1.21it/s]"]},{"name":"stdout","output_type":"stream","text":["Validation: [25/26] Elapsed 0m 21s (remain 0m 0s) Loss: 1.2675 (0.8792)\n","[2 2 0 0 1 1 0 0 1 1 1 2 2 2 0 0 1 2 1 0 1 1 1 0 1 0 1 0 1 0 2 2 1 0 1 1 1\n"," 0 2 0 0 0 2 0 2 1 0 1 1 1 1 0 0 1 1 0 1 2 0 1 0 2 1 1 0 1 0 0 1 1 0 0 1 1\n"," 1 0 2 0 1 1 0 1 1 0 2 1 1 0 2 1 0 0 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 0\n"," 1 1 1 0 0 1 2 2 0 1 0 1 0 1 1 0 2 1 0 1 2 2 1 1 0 0 0 1 2 0 1 1 0 0 0 2 2\n"," 0 1 0 2 1 1 1 0 0 2 1 0 0 0 2 2 0 0 0 1 0 0 0 1 1 1 2 1 0 2 0 1 2 0 1 1 1\n"," 2 2 0 0 1 0 1 0 1 1 0 1 1 2 0 2 1 1 2 2 1 0 0 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 2 1 0 0 1 0 0 0 1 2 1 1 1 2 0 0 0 0 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 2 1 0 0 1 1 1\n"," 2 1 1 0 0 2 0 2 1 2 1 1 1 1 0 1 0 1 2 0 1 1 2 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 2 0 0 1 2 1 0 0 2 0 1 1 0 1 1 1 2 2 0 1 0 0\n"," 1 0 0 0 2 1 1 1 1 0 0 1 0 2 0 1 1 0 0 0 1 2 0 1 0 2 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 0 2 0 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 2 2 0 2 1 0 0 1 0 1 2 1\n"," 1 1 0 1 2 0 1 1 0 1 0 0 1 1 0 2 0 1 0 1 1 0 2 0 0 1 1 1 0 0 1 0 1 2 0 1 2\n"," 1 0 0 1 0 0 1 2 0 0 0 0 0 1 2 1 0 2 0 0 0 0 1 1 1 0 0 0 0 1 0 2 2 1 0 1 2\n"," 0 2 0 1 1 0 0 0 0 1 0 1 2 2 2 0 1 1 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 1 1 0 1 2 0 2 0 1 0 0 1 1 2 1 2 1 0 0 1 2 0 0 1 0 0 2 1 0 2 0 0 1 0\n"," 1 0 2 0 0 0 2 0 0 1 1 1 0 0 1 2 2 0 0 1 0 2 2 2 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 1 2 2 1 2 0 0 1 1 0 1 2 0 2 0 1 1 1 0 0 1 1 0 1 1 2 0 2 0 0 0 2 0 1 1 1\n"," 1 1 0 0 1 2 2 1 1 0 0 0 1 1 1 0 2 0 0 1 0 0 2 2 2 0 0 1 0 0 0 0 1 1 1 0 1\n"," 0 1 0 2 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 2 0 1 1 2 0 0 1 0 0 0 1 0 0 2 2 0 2\n"," 1 1 1 0 0 0 0 1 0 1 1 0 2 1 1 0 0 0 0 2 0 2 0 1 2 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 0 2 0 2 0 1 0 0 0]\n","[2 2 0 0 1 1 0 0 1 1 1 2 1 2 2 0 1 2 1 0 1 0 1 0 1 0 1 0 0 0 2 2 1 2 0 1 1\n"," 0 0 0 0 1 2 0 2 2 0 1 1 1 1 2 0 1 1 0 1 0 0 1 0 2 1 1 0 1 0 0 1 1 0 0 0 1\n"," 1 0 2 0 1 1 1 1 1 0 0 2 1 0 2 1 0 1 0 1 2 0 1 0 0 1 2 2 1 1 2 2 1 0 0 0 2\n"," 2 1 0 0 0 1 2 2 0 1 0 1 0 1 0 0 0 1 0 1 2 2 1 1 0 0 1 1 2 0 1 1 0 0 0 0 2\n"," 0 1 0 1 1 1 1 0 0 2 1 0 0 0 2 2 0 0 0 2 0 0 0 1 1 1 2 1 0 2 0 2 2 0 1 1 1\n"," 2 2 0 0 1 0 1 0 2 0 0 1 0 2 0 1 1 1 1 2 1 0 2 1 0 2 1 2 2 0 0 0 0 0 2 1 1\n"," 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 2 1 1 1 2 0 0 0 0 1 1 1 1 2 0\n"," 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 2 1 1 0 0 1 0 1 0 0 1 1 2 0 0 1 1 1\n"," 2 1 1 0 0 1 0 2 1 2 1 1 1 1 0 1 0 1 2 0 1 1 0 0 1 0 1 2 1 2 1 1 1 2 0 1 1\n"," 0 0 0 1 0 1 0 1 0 0 2 0 0 2 1 2 0 0 1 2 1 0 0 2 0 2 1 0 1 1 1 0 2 0 1 0 1\n"," 1 0 0 0 2 1 1 1 1 0 0 1 0 2 0 1 1 0 0 0 1 2 2 1 0 2 0 0 0 1 2 1 0 1 1 2 1\n"," 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 2 2 0 2 1 0 0 2 0 1 2 1\n"," 1 1 0 1 0 0 0 1 0 1 0 0 1 1 0 2 0 2 0 1 1 0 2 0 0 1 1 1 0 0 0 0 1 1 0 1 2\n"," 0 0 0 1 0 0 1 2 0 0 1 1 0 1 2 1 0 2 0 0 2 2 2 1 1 0 0 0 0 1 0 2 2 0 0 1 2\n"," 0 2 1 1 1 0 0 0 0 1 0 2 2 2 2 2 1 0 1 2 1 0 1 0 1 0 1 0 1 1 1 0 0 2 1 0 0\n"," 0 1 0 1 1 0 1 2 0 2 0 1 0 0 2 1 2 1 2 0 0 0 1 2 0 0 1 0 0 2 0 0 2 0 0 1 0\n"," 1 0 2 0 0 0 2 0 1 1 1 1 0 0 0 2 2 0 0 1 0 2 2 0 0 0 1 0 1 0 0 1 1 1 2 0 2\n"," 2 0 0 2 1 2 0 0 0 1 0 1 2 0 0 0 1 1 1 0 2 1 1 0 1 2 2 0 2 0 0 0 2 0 1 1 1\n"," 1 0 0 2 1 2 2 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 2 0 2 0 0 2 0 0 0 0 1 1 1 2 1\n"," 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 2 0 1 1 2 0 1 1 1 0 0 1 0 0 2 2 0 2\n"," 1 2 1 0 0 0 0 1 0 1 2 0 2 1 1 0 0 0 0 2 0 2 2 1 0 1 0 2 2 2 1 1 0 2 0 1 0\n"," 0 0 1 1 2 1 1 0 0 1 0 1 1 2 2 1 0 1 1 2 0 1 0 1 2 0 0 0 1 0 0 0]\n","              precision    recall  f1-score   support\n","\n","           0     0.8886    0.9018    0.8951       336\n","           1     0.9209    0.8845    0.9023       329\n","           2     0.7829    0.8264    0.8041       144\n","\n","    accuracy                         0.8813       809\n","   macro avg     0.8641    0.8709    0.8672       809\n","weighted avg     0.8829    0.8813    0.8818       809\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["valid_loss, all_preds_np, all_labels_np = valid_loop(inf_model, valid_dataloader, loss_fn)\n","if CFG.debug:\n","    print(all_labels_np)\n","    print(all_preds_np)\n","    \n","score = get_score(all_labels_np, all_preds_np)\n","\n","report = classification_report(all_labels_np, all_preds_np, digits=4)\n","print(report)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["with open(f'{inf_model_name}_results.txt', 'w', encoding='utf-8') as fp:\n","    fp.write(report)"]},{"cell_type":"code","execution_count":46,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1053, 13)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>lang</th>\n","      <th>text</th>\n","      <th>meme</th>\n","      <th>path_memes</th>\n","      <th>number_annotators</th>\n","      <th>annotators</th>\n","      <th>gender_annotators</th>\n","      <th>age_annotators</th>\n","      <th>ethnicities_annotators</th>\n","      <th>study_levels_annotators</th>\n","      <th>countries_annotators</th>\n","      <th>split</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>310001</th>\n","      <td>310001</td>\n","      <td>es</td>\n","      <td>Soy como la madre de mi hermano</td>\n","      <td>310001.jpeg</td>\n","      <td>memes/310001.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_888, Annotator_889, Annotator_890, ...</td>\n","      <td>[M, M, M, F, F, F]</td>\n","      <td>[46+, 23-45, 18-22, 46+, 18-22, 23-45]</td>\n","      <td>[White or Caucasian, White or Caucasian, White...</td>\n","      <td>[Master’s degree, Bachelor’s degree, High scho...</td>\n","      <td>[Italy, Spain, Portugal, Mexico, United Kingdo...</td>\n","      <td>TEST-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>310002</th>\n","      <td>310002</td>\n","      <td>es</td>\n","      <td>DESAFI LLEVAR EN IRÁN LAS AUTORIDADES ESTÁN RE...</td>\n","      <td>310002.jpeg</td>\n","      <td>memes/310002.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_888, Annotator_889, Annotator_890, ...</td>\n","      <td>[M, M, M, F, F, F]</td>\n","      <td>[46+, 23-45, 18-22, 46+, 18-22, 23-45]</td>\n","      <td>[White or Caucasian, White or Caucasian, White...</td>\n","      <td>[Master’s degree, Bachelor’s degree, High scho...</td>\n","      <td>[Italy, Spain, Portugal, Mexico, United Kingdo...</td>\n","      <td>TEST-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>310003</th>\n","      <td>310003</td>\n","      <td>es</td>\n","      <td>Vincent Vega @VincentVega677-7h D *** YA VIENE...</td>\n","      <td>310003.jpeg</td>\n","      <td>memes/310003.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_888, Annotator_889, Annotator_890, ...</td>\n","      <td>[M, M, M, F, F, F]</td>\n","      <td>[46+, 23-45, 18-22, 46+, 18-22, 23-45]</td>\n","      <td>[White or Caucasian, White or Caucasian, White...</td>\n","      <td>[Master’s degree, Bachelor’s degree, High scho...</td>\n","      <td>[Italy, Spain, Portugal, Mexico, United Kingdo...</td>\n","      <td>TEST-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>310004</th>\n","      <td>310004</td>\n","      <td>es</td>\n","      <td>A ti Mujer soñadora Feliz Día</td>\n","      <td>310004.jpeg</td>\n","      <td>memes/310004.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_888, Annotator_889, Annotator_890, ...</td>\n","      <td>[M, M, M, F, F, F]</td>\n","      <td>[46+, 23-45, 18-22, 46+, 18-22, 23-45]</td>\n","      <td>[White or Caucasian, White or Caucasian, White...</td>\n","      <td>[Master’s degree, Bachelor’s degree, High scho...</td>\n","      <td>[Italy, Spain, Portugal, Mexico, United Kingdo...</td>\n","      <td>TEST-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>310005</th>\n","      <td>310005</td>\n","      <td>es</td>\n","      <td>Lya Gonzalez @LyaGonzalez1 Aquí hay revolución...</td>\n","      <td>310005.jpeg</td>\n","      <td>memes/310005.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_888, Annotator_889, Annotator_890, ...</td>\n","      <td>[M, M, M, F, F, F]</td>\n","      <td>[46+, 23-45, 18-22, 46+, 18-22, 23-45]</td>\n","      <td>[White or Caucasian, White or Caucasian, White...</td>\n","      <td>[Master’s degree, Bachelor’s degree, High scho...</td>\n","      <td>[Italy, Spain, Portugal, Mexico, United Kingdo...</td>\n","      <td>TEST-MEME_ES</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id_EXIST lang                                               text  \\\n","310001   310001   es                   Soy como la madre de mi hermano    \n","310002   310002   es  DESAFI LLEVAR EN IRÁN LAS AUTORIDADES ESTÁN RE...   \n","310003   310003   es  Vincent Vega @VincentVega677-7h D *** YA VIENE...   \n","310004   310004   es                     A ti Mujer soñadora Feliz Día    \n","310005   310005   es  Lya Gonzalez @LyaGonzalez1 Aquí hay revolución...   \n","\n","               meme         path_memes number_annotators  \\\n","310001  310001.jpeg  memes/310001.jpeg                 6   \n","310002  310002.jpeg  memes/310002.jpeg                 6   \n","310003  310003.jpeg  memes/310003.jpeg                 6   \n","310004  310004.jpeg  memes/310004.jpeg                 6   \n","310005  310005.jpeg  memes/310005.jpeg                 6   \n","\n","                                               annotators   gender_annotators  \\\n","310001  [Annotator_888, Annotator_889, Annotator_890, ...  [M, M, M, F, F, F]   \n","310002  [Annotator_888, Annotator_889, Annotator_890, ...  [M, M, M, F, F, F]   \n","310003  [Annotator_888, Annotator_889, Annotator_890, ...  [M, M, M, F, F, F]   \n","310004  [Annotator_888, Annotator_889, Annotator_890, ...  [M, M, M, F, F, F]   \n","310005  [Annotator_888, Annotator_889, Annotator_890, ...  [M, M, M, F, F, F]   \n","\n","                                age_annotators  \\\n","310001  [46+, 23-45, 18-22, 46+, 18-22, 23-45]   \n","310002  [46+, 23-45, 18-22, 46+, 18-22, 23-45]   \n","310003  [46+, 23-45, 18-22, 46+, 18-22, 23-45]   \n","310004  [46+, 23-45, 18-22, 46+, 18-22, 23-45]   \n","310005  [46+, 23-45, 18-22, 46+, 18-22, 23-45]   \n","\n","                                   ethnicities_annotators  \\\n","310001  [White or Caucasian, White or Caucasian, White...   \n","310002  [White or Caucasian, White or Caucasian, White...   \n","310003  [White or Caucasian, White or Caucasian, White...   \n","310004  [White or Caucasian, White or Caucasian, White...   \n","310005  [White or Caucasian, White or Caucasian, White...   \n","\n","                                  study_levels_annotators  \\\n","310001  [Master’s degree, Bachelor’s degree, High scho...   \n","310002  [Master’s degree, Bachelor’s degree, High scho...   \n","310003  [Master’s degree, Bachelor’s degree, High scho...   \n","310004  [Master’s degree, Bachelor’s degree, High scho...   \n","310005  [Master’s degree, Bachelor’s degree, High scho...   \n","\n","                                     countries_annotators         split  \n","310001  [Italy, Spain, Portugal, Mexico, United Kingdo...  TEST-MEME_ES  \n","310002  [Italy, Spain, Portugal, Mexico, United Kingdo...  TEST-MEME_ES  \n","310003  [Italy, Spain, Portugal, Mexico, United Kingdo...  TEST-MEME_ES  \n","310004  [Italy, Spain, Portugal, Mexico, United Kingdo...  TEST-MEME_ES  \n","310005  [Italy, Spain, Portugal, Mexico, United Kingdo...  TEST-MEME_ES  "]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["with open('EXIST 2024 Lab/EXIST 2024 Memes Dataset/test/EXIST2024_test_clean.json', 'r', encoding='utf-8') as fp:\n","    test_annotations = json.load(fp)\n","test_df = pd.DataFrame.from_dict(test_annotations).T\n","print(test_df.shape)\n","test_df.head()"]},{"cell_type":"code","execution_count":47,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>meme</th>\n","      <th>text</th>\n","      <th>lang</th>\n","      <th>ethnicities_annotators</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>310001</td>\n","      <td>310001.jpeg</td>\n","      <td>Soy como la madre de mi hermano</td>\n","      <td>es</td>\n","      <td>[White or Caucasian, White or Caucasian, White...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>310002</td>\n","      <td>310002.jpeg</td>\n","      <td>DESAFI LLEVAR EN IRÁN LAS AUTORIDADES ESTÁN RE...</td>\n","      <td>es</td>\n","      <td>[White or Caucasian, White or Caucasian, White...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>310003</td>\n","      <td>310003.jpeg</td>\n","      <td>Vincent Vega @VincentVega677-7h D *** YA VIENE...</td>\n","      <td>es</td>\n","      <td>[White or Caucasian, White or Caucasian, White...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>310004</td>\n","      <td>310004.jpeg</td>\n","      <td>A ti Mujer soñadora Feliz Día</td>\n","      <td>es</td>\n","      <td>[White or Caucasian, White or Caucasian, White...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>310005</td>\n","      <td>310005.jpeg</td>\n","      <td>Lya Gonzalez @LyaGonzalez1 Aquí hay revolución...</td>\n","      <td>es</td>\n","      <td>[White or Caucasian, White or Caucasian, White...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  id_EXIST         meme                                               text  \\\n","0   310001  310001.jpeg                   Soy como la madre de mi hermano    \n","1   310002  310002.jpeg  DESAFI LLEVAR EN IRÁN LAS AUTORIDADES ESTÁN RE...   \n","2   310003  310003.jpeg  Vincent Vega @VincentVega677-7h D *** YA VIENE...   \n","3   310004  310004.jpeg                     A ti Mujer soñadora Feliz Día    \n","4   310005  310005.jpeg  Lya Gonzalez @LyaGonzalez1 Aquí hay revolución...   \n","\n","  lang                             ethnicities_annotators  \n","0   es  [White or Caucasian, White or Caucasian, White...  \n","1   es  [White or Caucasian, White or Caucasian, White...  \n","2   es  [White or Caucasian, White or Caucasian, White...  \n","3   es  [White or Caucasian, White or Caucasian, White...  \n","4   es  [White or Caucasian, White or Caucasian, White...  "]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["test_mini_df = test_df[['id_EXIST', 'meme', 'text', 'lang', 'ethnicities_annotators']].reset_index(drop=True)\n","test_mini_df.head()"]},{"cell_type":"code","execution_count":48,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["<__main__.ExistDataset at 0x13d29b94250>"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["test_dataset = ExistDataset(test_mini_df[['id_EXIST', 'meme', 'text']], CFG.images_base_path_test, test=True, img_transform=resize_images)\n","test_dataset"]},{"cell_type":"markdown","metadata":{},"source":["# Test Prediction"]},{"cell_type":"code","execution_count":49,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [00:27<00:00,  1.19it/s]"]},{"name":"stdout","output_type":"stream","text":["['310001', '310002', '310003', '310004', '310005', '310006', '310007', '310008', '310009', '310010', '310011', '310012', '310013', '310014', '310015', '310016', '310017', '310018', '310019', '310020', '310021', '310022', '310023', '310024', '310025', '310026', '310027', '310028', '310029', '310030', '310031', '310032', '310033', '310034', '310035', '310036', '310037', '310038', '310039', '310040', '310041', '310042', '310043', '310044', '310045', '310046', '310047', '310048', '310049', '310050', '310051', '310052', '310053', '310054', '310055', '310056', '310057', '310058', '310059', '310060', '310061', '310062', '310063', '310064', '310065', '310066', '310067', '310068', '310069', '310070', '310071', '310072', '310073', '310074', '310075', '310076', '310077', '310078', '310079', '310080', '310081', '310082', '310083', '310084', '310085', '310086', '310087', '310088', '310089', '310090', '310091', '310092', '310093', '310094', '310095', '310096', '310097', '310098', '310099', '310100', '310101', '310102', '310103', '310104', '310105', '310106', '310107', '310108', '310109', '310110', '310111', '310112', '310113', '310114', '310115', '310116', '310117', '310118', '310119', '310120', '310121', '310122', '310123', '310124', '310125', '310126', '310127', '310128', '310129', '310130', '310131', '310132', '310133', '310134', '310135', '310136', '310137', '310138', '310139', '310140', '310141', '310142', '310143', '310144', '310145', '310146', '310147', '310148', '310149', '310150', '310151', '310152', '310153', '310154', '310155', '310156', '310157', '310158', '310159', '310160', '310161', '310162', '310163', '310164', '310165', '310166', '310167', '310168', '310169', '310170', '310171', '310172', '310173', '310174', '310175', '310176', '310177', '310178', '310179', '310180', '310181', '310182', '310183', '310184', '310185', '310186', '310187', '310188', '310189', '310190', '310191', '310192', '310193', '310194', '310195', '310196', '310197', '310198', '310199', '310200', '310201', '310202', '310203', '310204', '310205', '310206', '310207', '310208', '310209', '310210', '310211', '310212', '310213', '310214', '310215', '310216', '310217', '310218', '310219', '310220', '310221', '310222', '310223', '310224', '310225', '310226', '310227', '310228', '310229', '310230', '310231', '310232', '310233', '310234', '310235', '310236', '310237', '310238', '310239', '310240', '310241', '310242', '310243', '310244', '310245', '310246', '310247', '310248', '310249', '310250', '310251', '310252', '310253', '310254', '310255', '310256', '310257', '310258', '310259', '310260', '310261', '310262', '310263', '310264', '310265', '310266', '310267', '310268', '310269', '310270', '310271', '310272', '310273', '310274', '310275', '310276', '310277', '310278', '310279', '310280', '310281', '310282', '310283', '310284', '310285', '310286', '310287', '310288', '310289', '310290', '310291', '310292', '310293', '310294', '310295', '310296', '310297', '310298', '310299', '310300', '310301', '310302', '310303', '310304', '310305', '310306', '310307', '310308', '310309', '310310', '310311', '310312', '310313', '310314', '310315', '310316', '310317', '310318', '310319', '310320', '310321', '310322', '310323', '310324', '310325', '310326', '310327', '310328', '310329', '310330', '310331', '310332', '310333', '310334', '310335', '310336', '310337', '310338', '310339', '310340', '310341', '310342', '310343', '310344', '310345', '310346', '310347', '310348', '310349', '310350', '310351', '310352', '310353', '310354', '310355', '310356', '310357', '310358', '310359', '310360', '310361', '310362', '310363', '310364', '310365', '310366', '310367', '310368', '310369', '310370', '310371', '310372', '310373', '310374', '310375', '310376', '310377', '310378', '310379', '310380', '310381', '310382', '310383', '310384', '310385', '310386', '310387', '310388', '310389', '310390', '310391', '310392', '310393', '310394', '310395', '310396', '310397', '310398', '310399', '310400', '310401', '310402', '310403', '310404', '310405', '310406', '310407', '310408', '310409', '310410', '310411', '310412', '310413', '310414', '310415', '310416', '310417', '310418', '310419', '310420', '310421', '310422', '310423', '310424', '310425', '310426', '310427', '310428', '310429', '310430', '310431', '310432', '310433', '310434', '310435', '310436', '310437', '310438', '310439', '310440', '310441', '310442', '310443', '310444', '310445', '310446', '310447', '310448', '310449', '310450', '310451', '310452', '310453', '310454', '310455', '310456', '310457', '310458', '310459', '310460', '310461', '310462', '310463', '310464', '310465', '310466', '310467', '310468', '310469', '310470', '310471', '310472', '310473', '310474', '310475', '310476', '310477', '310478', '310479', '310480', '310481', '310482', '310483', '310484', '310485', '310486', '310487', '310488', '310489', '310490', '310491', '310492', '310493', '310494', '310495', '310496', '310497', '310498', '310499', '310500', '310501', '310502', '310503', '310504', '310505', '310506', '310507', '310508', '310509', '310510', '310511', '310512', '310513', '310514', '310515', '310516', '310517', '310518', '310519', '310520', '310521', '310522', '310523', '310524', '310525', '310526', '310527', '310528', '310529', '310530', '310531', '310532', '310533', '310534', '310535', '310536', '310537', '310538', '310539', '310540', '410001', '410002', '410003', '410004', '410005', '410006', '410007', '410008', '410009', '410010', '410011', '410012', '410013', '410014', '410015', '410016', '410017', '410018', '410019', '410020', '410021', '410022', '410023', '410024', '410025', '410026', '410027', '410028', '410029', '410030', '410031', '410032', '410033', '410034', '410035', '410036', '410037', '410038', '410039', '410040', '410041', '410042', '410043', '410044', '410045', '410046', '410047', '410048', '410049', '410050', '410051', '410052', '410053', '410054', '410055', '410056', '410057', '410058', '410059', '410060', '410061', '410062', '410063', '410064', '410065', '410066', '410067', '410068', '410069', '410070', '410071', '410072', '410073', '410074', '410075', '410076', '410077', '410078', '410079', '410080', '410081', '410082', '410083', '410084', '410085', '410086', '410087', '410088', '410089', '410090', '410091', '410092', '410093', '410094', '410095', '410096', '410097', '410098', '410099', '410100', '410101', '410102', '410103', '410104', '410105', '410106', '410107', '410108', '410109', '410110', '410111', '410112', '410113', '410114', '410115', '410116', '410117', '410118', '410119', '410120', '410121', '410122', '410123', '410124', '410125', '410126', '410127', '410128', '410129', '410130', '410131', '410132', '410133', '410134', '410135', '410136', '410137', '410138', '410139', '410140', '410141', '410142', '410143', '410144', '410145', '410146', '410147', '410148', '410149', '410150', '410151', '410152', '410153', '410154', '410155', '410156', '410157', '410158', '410159', '410160', '410161', '410162', '410163', '410164', '410165', '410166', '410167', '410168', '410169', '410170', '410171', '410172', '410173', '410174', '410175', '410176', '410177', '410178', '410179', '410180', '410181', '410182', '410183', '410184', '410185', '410186', '410187', '410188', '410189', '410190', '410191', '410192', '410193', '410194', '410195', '410196', '410197', '410198', '410199', '410200', '410201', '410202', '410203', '410204', '410205', '410206', '410207', '410208', '410209', '410210', '410211', '410212', '410213', '410214', '410215', '410216', '410217', '410218', '410219', '410220', '410221', '410222', '410223', '410224', '410225', '410226', '410227', '410228', '410229', '410230', '410231', '410232', '410233', '410234', '410235', '410236', '410237', '410238', '410239', '410240', '410241', '410242', '410243', '410244', '410245', '410246', '410247', '410248', '410249', '410250', '410251', '410252', '410253', '410254', '410255', '410256', '410257', '410258', '410259', '410260', '410261', '410262', '410263', '410264', '410265', '410266', '410267', '410268', '410269', '410270', '410271', '410272', '410273', '410274', '410275', '410276', '410277', '410278', '410279', '410280', '410281', '410282', '410283', '410284', '410285', '410286', '410287', '410288', '410289', '410290', '410291', '410292', '410293', '410294', '410295', '410296', '410297', '410298', '410299', '410300', '410301', '410302', '410303', '410304', '410305', '410306', '410307', '410308', '410309', '410310', '410311', '410312', '410313', '410314', '410315', '410316', '410317', '410318', '410319', '410320', '410321', '410322', '410323', '410324', '410325', '410326', '410327', '410328', '410329', '410330', '410331', '410332', '410333', '410334', '410335', '410336', '410337', '410338', '410339', '410340', '410341', '410342', '410343', '410344', '410345', '410346', '410347', '410348', '410349', '410350', '410351', '410352', '410353', '410354', '410355', '410356', '410357', '410358', '410359', '410360', '410361', '410362', '410363', '410364', '410365', '410366', '410367', '410368', '410369', '410370', '410371', '410372', '410373', '410374', '410375', '410376', '410377', '410378', '410379', '410380', '410381', '410382', '410383', '410384', '410385', '410386', '410387', '410388', '410389', '410390', '410391', '410392', '410393', '410394', '410395', '410396', '410397', '410398', '410399', '410400', '410401', '410402', '410403', '410404', '410405', '410406', '410407', '410408', '410409', '410410', '410411', '410412', '410413', '410414', '410415', '410416', '410417', '410418', '410419', '410420', '410421', '410422', '410423', '410424', '410425', '410426', '410427', '410428', '410429', '410430', '410431', '410432', '410433', '410434', '410435', '410436', '410437', '410438', '410439', '410440', '410441', '410442', '410443', '410444', '410445', '410446', '410447', '410448', '410449', '410450', '410451', '410452', '410453', '410454', '410455', '410456', '410457', '410458', '410459', '410460', '410461', '410462', '410463', '410464', '410465', '410466', '410467', '410468', '410469', '410470', '410471', '410472', '410473', '410474', '410475', '410476', '410477', '410478', '410479', '410480', '410481', '410482', '410483', '410484', '410485', '410486', '410487', '410488', '410489', '410490', '410491', '410492', '410493', '410494', '410495', '410496', '410497', '410498', '410499', '410500', '410501', '410502', '410503', '410504', '410505', '410506', '410507', '410508', '410509', '410510', '410511', '410512', '410513']\n","[1, 0, 1, 1, 2, 1, 2, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 1, 2, 1, 0, 1, 2, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 2, 0, 1, 1, 0, 2, 0, 1, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 2, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 2, 1, 0, 2, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 2, 1, 0, 1, 0, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 2, 0, 2, 1, 2, 0, 2, 1, 2, 1, 0, 0, 2, 2, 1, 2, 2, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 2, 1, 2, 0, 1, 1, 0, 1, 0, 1, 2, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 2, 0, 0, 2, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 0, 0, 1, 2, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 0, 2, 0, 0, 0, 0, 2, 1, 1, 0, 2, 2, 0, 0, 0, 0, 1, 1, 0, 1, 0, 2, 0, 2, 1, 0, 0, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 2, 1, 0, 0, 0, 0, 1, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 2, 2, 1, 1, 2, 2, 2, 1, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 2, 1, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 2, 1, 2, 2, 0, 1, 1, 0, 0, 2, 2, 1, 0, 1, 1, 2, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 0, 2, 1, 0, 1, 2, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 1, 2, 2, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 2, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 2, 2, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 2, 2, 0, 1, 0, 0, 2, 0, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 0, 0, 2, 2, 2, 0, 2, 2, 1, 0, 0, 0, 2, 1, 0, 1, 1, 2, 0, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 1, 2, 0, 1, 1, 1, 1, 0, 2, 2, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 1, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 1, 2, 1, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 1]\n","[[0.0014530086191371083, 0.9976316690444946, 0.0009153590071946383], [0.9995983242988586, 0.0002495926746632904, 0.00015199607878457755], [0.0004224840668030083, 0.9992561936378479, 0.00032133873901329935], [0.00030025854357518256, 0.9986808896064758, 0.0010188239393755794], [0.0005932700587436557, 0.0012320628156885505, 0.9981746673583984], [0.014764492399990559, 0.9390531778335571, 0.046182289719581604], [0.00011433858162490651, 0.00018516041745897382, 0.9997005462646484], [0.00024415587540715933, 0.9994788765907288, 0.0002769853454083204], [0.917570173740387, 0.05958089232444763, 0.022848954424262047], [0.003132082987576723, 0.986956000328064, 0.009911940433084965], [0.9998801946640015, 7.341144373640418e-05, 4.636616358766332e-05], [0.9990546107292175, 0.0006832919898442924, 0.00026210464420728385], [0.9998703002929688, 8.480771793983877e-05, 4.478994378587231e-05], [0.0003068560326937586, 0.9982596039772034, 0.001433532452210784], [0.00023485736164730042, 0.9994707703590393, 0.0002944372536148876], [0.00026536991936154664, 0.9980950951576233, 0.0016395158600062132], [0.9996045231819153, 0.00027283563395030797, 0.0001225703745149076], [0.00039901287527754903, 0.9969103932380676, 0.0026905566919595003], [0.99641352891922, 0.0024335680063813925, 0.0011528510367497802], [0.0004902348737232387, 0.052053701132535934, 0.9474561214447021], [0.08789630234241486, 0.38197842240333557, 0.5301253199577332], [0.0005499560502357781, 0.9977601766586304, 0.0016898445319384336], [0.0038772739935666323, 0.07215577363967896, 0.9239670634269714], [0.0007883697981014848, 0.9718765020370483, 0.027335193008184433], [0.00029434458701871336, 0.9988817572593689, 0.0008238747250288725], [0.005844241473823786, 0.9934992790222168, 0.0006564818904735148], [0.0007750023505650461, 0.9953193068504333, 0.0039056928362697363], [0.0010053577134385705, 0.9973234534263611, 0.0016712738433852792], [0.6466264724731445, 0.31783831119537354, 0.03553522378206253], [0.007863389328122139, 0.9901214838027954, 0.0020151289645582438], [0.000463813979877159, 0.9988489151000977, 0.000687282532453537], [0.00010042636858997867, 0.00011182182061020285, 0.9997877478599548], [0.9992929697036743, 0.00048311337013728917, 0.00022385199554264545], [0.002189832041040063, 0.9962500929832458, 0.0015601414488628507], [0.9995713829994202, 0.00028669554740190506, 0.0001419033360434696], [0.0006998413591645658, 0.9970870614051819, 0.0022131679579615593], [0.9995450377464294, 0.00030039114062674344, 0.00015452403749804944], [0.8742491006851196, 0.12245934456586838, 0.0032915102783590555], [0.9997068047523499, 0.00019140269432682544, 0.00010171914618695155], [0.00044341516331769526, 0.9988142251968384, 0.000742391508538276], [0.9998175501823425, 0.00011455914500402287, 6.789443432353437e-05], [0.10952294617891312, 0.1493651419878006, 0.7411119341850281], [0.00099084060639143, 0.9963350296020508, 0.0026741574984043837], [0.00013147143181413412, 0.999129593372345, 0.0007389872334897518], [0.9993008375167847, 0.0005416034837253392, 0.00015761605754960328], [0.00020549421606119722, 0.9991559982299805, 0.0006385234300978482], [0.000567737384699285, 0.9732295274734497, 0.0262027308344841], [0.9999030828475952, 6.0322312492644414e-05, 3.662950621219352e-05], [2.497146306268405e-05, 2.992925510625355e-05, 0.9999451637268066], [0.00032575998920947313, 0.9967111349105835, 0.0029630891513079405], [0.9998469352722168, 9.59599346970208e-05, 5.709143806598149e-05], [0.9993133544921875, 0.0004468048282433301, 0.00023981744016055018], [0.9996912479400635, 0.00020572394714690745, 0.00010304592433385551], [0.005524456035345793, 0.5405498147010803, 0.4539256989955902], [6.726739229634404e-05, 0.00017362763173878193, 0.9997591376304626], [0.9994378685951233, 0.0003583822399377823, 0.00020379236957523972], [0.9998811483383179, 7.095697219483554e-05, 4.794463166035712e-05], [0.0003101315232925117, 0.9987743496894836, 0.0009154658764600754], [0.7222306132316589, 0.14067897200584412, 0.13709044456481934], [0.9995809197425842, 0.0002748429251369089, 0.00014415544865187258], [0.21488536894321442, 0.6194412112236023, 0.1656733751296997], [6.747576844645664e-05, 0.00017980554548557848, 0.9997527003288269], [0.00018742545216809958, 0.9995290040969849, 0.00028357183327898383], [0.9994692206382751, 0.0003604210214689374, 0.00017038744408637285], [0.00031232836772687733, 0.9990691542625427, 0.00061859714332968], [0.000864241854287684, 0.12173634767532349, 0.8773993253707886], [0.003537683980539441, 0.9775440096855164, 0.018918339163064957], [0.9998505115509033, 9.021996083902195e-05, 5.919794784858823e-05], [0.0007772303652018309, 0.9096819758415222, 0.08954078704118729], [0.99920254945755, 0.0005856446805410087, 0.00021180063777137548], [0.9997510313987732, 0.00015983532648533583, 8.91448580659926e-05], [0.7992266416549683, 0.18367154896259308, 0.01710180565714836], [0.9995250701904297, 0.0003194154123775661, 0.0001554481132188812], [0.9997326731681824, 0.00017653271788731217, 9.081728057935834e-05], [0.031406860798597336, 0.9477970004081726, 0.020796112716197968], [0.9956032037734985, 0.002873731777071953, 0.0015230939025059342], [0.8897852301597595, 0.07603534311056137, 0.03417941555380821], [0.008845719508826733, 0.9875984787940979, 0.003555823815986514], [0.9921579360961914, 0.005886946339160204, 0.0019550223369151354], [0.999874472618103, 7.74694126448594e-05, 4.797646761289798e-05], [0.002405299339443445, 0.9858012795448303, 0.011793367564678192], [0.9999209642410278, 5.010007225791924e-05, 2.9019818612141535e-05], [0.0008830582955852151, 0.9974592328071594, 0.0016577369533479214], [0.6829077005386353, 0.3111298084259033, 0.00596248172223568], [0.9939132332801819, 0.005186330992728472, 0.0009003545274026692], [0.9625660181045532, 0.02067028172314167, 0.016763722524046898], [0.9988815188407898, 0.0008263965719379485, 0.0002921257691923529], [0.00046391275827772915, 0.996593177318573, 0.002942927647382021], [0.0009628945263102651, 0.9970759153366089, 0.0019612160976976156], [0.0027136693242937326, 0.519748330116272, 0.47753795981407166], [0.9997523427009583, 0.00017125101294368505, 7.636151713086292e-05], [0.003924884833395481, 0.9922239780426025, 0.003851089160889387], [0.5152236223220825, 0.4246329069137573, 0.06014344096183777], [0.9996428489685059, 0.00021568388910964131, 0.00014141887368168682], [0.9991844296455383, 0.0005648776423186064, 0.0002506923337932676], [0.005446982104331255, 0.3686193823814392, 0.6259336471557617], [0.9871541857719421, 0.00922226719558239, 0.003623493481427431], [0.9987437129020691, 0.0008586309850215912, 0.000397631898522377], [0.01053492072969675, 0.02491345815360546, 0.9645516276359558], [0.02410784550011158, 0.928543746471405, 0.047348398715257645], [0.9989288449287415, 0.0007101965602487326, 0.00036088310298509896], [0.9993265867233276, 0.00046222974197007716, 0.00021119597658980638], [0.999765932559967, 0.00015580545004922897, 7.827549416106194e-05], [0.00042930003837682307, 0.9975963234901428, 0.0019743149168789387], [0.0004461494099814445, 0.9992049336433411, 0.00034891843097284436], [0.0009209529380314052, 0.43084102869033813, 0.5682379603385925], [0.9998282194137573, 0.00011175183317391202, 5.998445340082981e-05], [0.0002402497484581545, 0.9980918765068054, 0.0016678690444678068], [0.00043882065801881254, 0.9983550906181335, 0.0012060952140018344], [0.0011445758864283562, 0.9876784682273865, 0.011176983825862408], [0.00027021957794204354, 0.9989081621170044, 0.0008216440910473466], [0.9998750686645508, 8.281914051622152e-05, 4.20476972067263e-05], [0.9988378882408142, 0.000764820200856775, 0.0003973793354816735], [0.9994600415229797, 0.0003621069190558046, 0.00017792099970392883], [0.9990284442901611, 0.0006801196723245084, 0.00029143629944883287], [0.9633485674858093, 0.03413353115320206, 0.0025178499054163694], [0.992177426815033, 0.005708957556635141, 0.0021135788410902023], [0.9996644258499146, 0.00022490817354992032, 0.00011070499749621376], [0.003981627523899078, 0.9926678538322449, 0.0033505428582429886], [0.7577269077301025, 0.2376716583967209, 0.004601386841386557], [0.9997299313545227, 0.00018783983250614256, 8.219742449000478e-05], [0.9986554384231567, 0.0009613261790946126, 0.0003832269867416471], [0.10945683717727661, 0.8869873285293579, 0.003555814502760768], [0.9999327659606934, 4.376609649625607e-05, 2.3470467567676678e-05], [0.0011624781182035804, 0.9975838661193848, 0.0012536338763311505], [0.9999082088470459, 6.222067167982459e-05, 2.9569886464742012e-05], [0.9998493194580078, 0.00010154638584936038, 4.911548603558913e-05], [0.0006695784977637231, 0.9987824559211731, 0.0005479766987264156], [0.9998679161071777, 8.53503224789165e-05, 4.676606840803288e-05], [0.999657392501831, 0.00024201572523452342, 0.00010053793084807694], [0.9869335889816284, 0.010028684511780739, 0.0030377754010260105], [0.0002628298243507743, 0.9993025064468384, 0.00043467868817970157], [0.9998534917831421, 9.238017810275778e-05, 5.414904808276333e-05], [0.9993801116943359, 0.00041775056160986423, 0.00020199990831315517], [0.00015873608936090022, 0.999579131603241, 0.00026208971394225955], [0.013183596543967724, 0.07370328158140182, 0.9131131768226624], [0.9997898936271667, 0.00013952027074992657, 7.05772326909937e-05], [0.0008141272701323032, 0.9617973566055298, 0.037388525903224945], [0.003504064865410328, 0.992784857749939, 0.0037111227866262197], [0.9585200548171997, 0.030351433902978897, 0.011128531768918037], [4.087216075276956e-05, 0.00028220380772836506, 0.9996769428253174], [0.9929293990135193, 0.005981334950774908, 0.0010893308790400624], [0.32393085956573486, 0.5590723156929016, 0.11699683219194412], [0.9991224408149719, 0.0005953783402219415, 0.0002822173701133579], [0.9867739677429199, 0.007962633855640888, 0.005263351369649172], [0.5113846659660339, 0.48178860545158386, 0.006826773285865784], [2.6516745492699556e-05, 4.996164352633059e-05, 0.999923586845398], [0.9992135763168335, 0.0005397103959694505, 0.00024665126693435013], [0.0008745557279326022, 0.9903595447540283, 0.008765889331698418], [0.0015379100805148482, 0.994648277759552, 0.0038138090167194605], [0.2787299156188965, 0.457276314496994, 0.2639937698841095], [0.00028922694036737084, 0.9982393980026245, 0.0014713243581354618], [0.9704924821853638, 0.024904265999794006, 0.004603255540132523], [0.0003008423955179751, 0.9991229176521301, 0.0005762350629083812], [0.9990575909614563, 0.0006141499616205692, 0.0003282513062004], [0.346121609210968, 0.38408470153808594, 0.26979368925094604], [0.0002083529980154708, 0.9991703033447266, 0.0006213201559148729], [0.9990804195404053, 0.0005753426230512559, 0.0003442476154305041], [0.01649637334048748, 0.9719253778457642, 0.011578313075006008], [0.2965431213378906, 0.5488815903663635, 0.15457530319690704], [0.9989491105079651, 0.0006701807724311948, 0.0003807052271440625], [9.624892118154094e-05, 0.00032950719469226897, 0.9995742440223694], [0.9958747029304504, 0.0034880859311670065, 0.0006373329670168459], [0.9936767220497131, 0.004291847813874483, 0.0020314352586865425], [0.9997075200080872, 0.00018333607295062393, 0.00010914514132309705], [0.003291535656899214, 0.004848063923418522, 0.9918604493141174], [0.000490435108076781, 0.998955488204956, 0.0005540061392821372], [0.0002577691921032965, 0.9978811144828796, 0.0018611447885632515], [0.9984549283981323, 0.0009504068293608725, 0.0005946024903096259], [0.00156678247731179, 0.9954723119735718, 0.002960971323773265], [0.9997965693473816, 0.00012900636647827923, 7.449850090779364e-05], [0.9997370839118958, 0.0001623132557142526, 0.00010055257007479668], [0.9998714923858643, 8.133843948598951e-05, 4.719230855698697e-05], [0.00024064609897322953, 0.9990179538726807, 0.0007413850980810821], [0.9996558427810669, 0.00021419278346002102, 0.000130058906506747], [0.9996942281723022, 0.00019774209067691118, 0.00010805538477143273], [0.034424155950546265, 0.9605969786643982, 0.004978831857442856], [0.9993237257003784, 0.0004994709743186831, 0.00017673737602308393], [0.9992434978485107, 0.0005032509798184037, 0.00025326889590360224], [0.0005259883473627269, 0.9924260377883911, 0.0070479861460626125], [0.993093729019165, 0.005646716803312302, 0.0012594693107530475], [0.0012145237997174263, 0.9979459643363953, 0.0008395597105845809], [0.0029248895589262247, 0.9952442049980164, 0.001830874476581812], [0.9836281538009644, 0.013030732050538063, 0.003341137897223234], [0.8945654034614563, 0.07428985834121704, 0.031144795939326286], [0.0013587004505097866, 0.9971785545349121, 0.0014627871569246054], [0.4189789891242981, 0.3421047031879425, 0.23891626298427582], [0.9996799230575562, 0.00021097064018249512, 0.00010918813495663926], [0.0005038481904193759, 0.9961806535720825, 0.003315527457743883], [0.00020004661928396672, 0.9994460940361023, 0.0003538443997967988], [0.9990308284759521, 0.0005552952643483877, 0.0004138012882322073], [0.9997527003288269, 0.00015537724539171904, 9.184190275846049e-05], [0.9996594190597534, 0.00020862644305452704, 0.0001319633302045986], [0.9993928670883179, 0.00039187484071590006, 0.00021531677339226007], [0.0002571787335909903, 0.9987906813621521, 0.0009521568426862359], [0.0013721652794629335, 0.9856858253479004, 0.012942059896886349], [0.9998617172241211, 8.582713053328916e-05, 5.245891952654347e-05], [0.9997518658638, 0.0001678068656474352, 8.034610073082149e-05], [0.9997054934501648, 0.00018907587218564004, 0.00010539445793256164], [0.9923432469367981, 0.005208812188357115, 0.0024478593841195107], [0.9990925788879395, 0.0005320151103660464, 0.0003754378412850201], [0.0019742713775485754, 0.9971330165863037, 0.0008927103481255472], [0.00042941709398292005, 0.9988904595375061, 0.0006801490089856088], [0.0002007085713557899, 0.9993860721588135, 0.00041321502067148685], [0.5597445368766785, 0.43327096104621887, 0.006984556093811989], [0.0007561434176750481, 0.0008351000142283738, 0.998408854007721], [0.19496728479862213, 0.7948055863380432, 0.010227114893496037], [0.9981112480163574, 0.001252706628292799, 0.0006360859260894358], [0.01247796043753624, 0.013356470502912998, 0.9741655588150024], [0.9990881681442261, 0.000666152685880661, 0.00024570850655436516], [0.4916704595088959, 0.2539202570915222, 0.2544093132019043], [0.0015403768047690392, 0.9925310015678406, 0.005928614642471075], [0.030285105109214783, 0.510577917098999, 0.459136962890625], [0.0004800291790161282, 0.9966951608657837, 0.0028247893787920475], [0.5959122776985168, 0.39711982011795044, 0.0069679031148552895], [0.06809073686599731, 0.8450993895530701, 0.08680985122919083], [0.0004139083903282881, 0.9991397857666016, 0.00044629673357121646], [0.9990978240966797, 0.0006265468546189368, 0.00027565271011553705], [0.0046523879282176495, 0.9721144437789917, 0.02323317341506481], [0.0005167095805518329, 0.9989359974861145, 0.0005473395576700568], [0.9981512427330017, 0.001380855799652636, 0.0004678824916481972], [0.002196088433265686, 0.9968464970588684, 0.0009573654970154166], [0.9998047947883606, 0.00013074403977952898, 6.44712126813829e-05], [6.174160080263391e-05, 0.002094957744702697, 0.9978432655334473], [0.0013494010781869292, 0.9977992177009583, 0.0008513594511896372], [0.0002489058824721724, 0.9981986880302429, 0.0015524502377957106], [0.0008312186691910028, 0.9888655543327332, 0.01030315924435854], [0.0011574822710826993, 0.9916919469833374, 0.007150586228817701], [0.0007875522715039551, 0.9912681579589844, 0.007944212295114994], [0.9967697858810425, 0.002432080451399088, 0.0007981701055541635], [0.5948530435562134, 0.3948726952075958, 0.010274272412061691], [0.9993300437927246, 0.0004662653664126992, 0.00020367905381135643], [0.999678373336792, 0.00019747792975977063, 0.00012415144010446966], [0.0013498576590791345, 0.9961047172546387, 0.0025454293936491013], [0.0001400818582624197, 0.9996088147163391, 0.00025116646429523826], [0.001727841212414205, 0.018276946619153023, 0.9799951910972595], [0.0004294168611522764, 0.9988904595375061, 0.0006801473791711032], [0.2742464542388916, 0.7158669829368591, 0.00988655537366867], [0.19496922194957733, 0.7948036193847656, 0.010227124206721783], [0.002081020036712289, 0.9826925992965698, 0.01522639486938715], [0.0002301981730852276, 0.9983179569244385, 0.0014518673997372389], [0.9998651742935181, 7.94444204075262e-05, 5.5253509344765916e-05], [0.002263001399114728, 0.9967064261436462, 0.001030628220178187], [0.0005707742529921234, 0.997899055480957, 0.0015302094398066401], [0.999568521976471, 0.0002840711094904691, 0.00014744892541784793], [0.011729894205927849, 0.9863177537918091, 0.0019523290684446692], [0.004015812184661627, 0.011113614775240421, 0.9848704934120178], [0.9999091625213623, 6.0475784266600385e-05, 3.0349305234267376e-05], [0.0009425205062143505, 0.9724927544593811, 0.026564696803689003], [0.00028532231226563454, 0.9991315007209778, 0.000583142857067287], [0.005900499410927296, 0.008834587410092354, 0.9852649569511414], [0.006121783517301083, 0.9848529100418091, 0.0090253297239542], [0.000259555468801409, 0.00036197761073708534, 0.9993784427642822], [0.8546393513679504, 0.08054003864526749, 0.06482058763504028], [4.164988422417082e-05, 0.00011179972352692857, 0.9998465776443481], [0.00041182266431860626, 0.9942699670791626, 0.005318234208971262], [0.9998319149017334, 9.999748726841062e-05, 6.804489385103807e-05], [0.00014836790796834975, 0.9995637536048889, 0.0002878390369005501], [0.9993866682052612, 0.000388212560210377, 0.00022505507513415068], [0.99978107213974, 0.00014091267075855285, 7.808938244124874e-05], [0.999930739402771, 4.3933407141594216e-05, 2.525129275454674e-05], [0.00025946085224859416, 0.9986541271209717, 0.0010864307405427098], [0.00367002934217453, 0.9794981479644775, 0.016831841319799423], [0.9994667172431946, 0.00034853254328481853, 0.0001848332758527249], [0.00041182246059179306, 0.9942699670791626, 0.005318237002938986], [2.3858092390582897e-05, 0.00021478264534380287, 0.9997614026069641], [0.0768706277012825, 0.9200962781906128, 0.0030330384615808725], [0.9871104955673218, 0.008075217716395855, 0.00481429835781455], [4.382157567306422e-05, 7.544946856796741e-05, 0.9998806715011597], [0.9944320321083069, 0.003783617401495576, 0.0017843360546976328], [0.00096146046416834, 0.9966117739677429, 0.002426768420264125], [0.9990123510360718, 0.0006724397535435855, 0.00031528284307569265], [0.00023978340323083103, 0.9989609718322754, 0.0007992773316800594], [0.9883025288581848, 0.010629814118146896, 0.0010676913661882281], [0.9979812502861023, 0.0012659744825214148, 0.0007527921698056161], [0.0013512370642274618, 0.9978598952293396, 0.0007888088002800941], [0.9395503401756287, 0.05771216005086899, 0.002737495582550764], [0.6310207843780518, 0.3615153133869171, 0.007463894318789244], [0.9997004270553589, 0.00020537612726911902, 9.422255971003324e-05], [0.000431147898780182, 0.9991652965545654, 0.0004035669844597578], [0.0002783669624477625, 0.9992744326591492, 0.00044723015162162483], [0.000486363802338019, 0.0025439728051424026, 0.9969697594642639], [0.00018905547040048987, 0.9994403719902039, 0.0003705975250340998], [0.9992091059684753, 0.0005597362178377807, 0.00023114777286536992], [0.0024436279200017452, 0.9782065153121948, 0.01934986375272274], [0.9995368719100952, 0.00029751486727036536, 0.00016559052164666355], [0.0008312201825901866, 0.9888655543327332, 0.010303173214197159], [0.000441710784798488, 0.0008890708559192717, 0.9986692667007446], [0.913795530796051, 0.05820084735751152, 0.028003569692373276], [0.9995156526565552, 0.00029915160848759115, 0.00018513589748181403], [0.00426670303568244, 0.018394500017166138, 0.9773387312889099], [0.26305535435676575, 0.6340922713279724, 0.10285245627164841], [0.9732347130775452, 0.022597648203372955, 0.004167582839727402], [0.5399104952812195, 0.4534113109111786, 0.006678178906440735], [0.0007055044989101589, 0.9985858201980591, 0.0007087431149557233], [0.5782914757728577, 0.40126365423202515, 0.02044491469860077], [0.9997573494911194, 0.00014546854072250426, 9.71598201431334e-05], [0.00014102354180067778, 0.00016795341798570007, 0.9996911287307739], [0.5803225040435791, 0.41489818692207336, 0.00477933743968606], [0.999775230884552, 0.00014085018483456224, 8.394898031838238e-05], [0.012060844339430332, 0.9783092737197876, 0.009629830718040466], [0.001296286121942103, 0.9813982844352722, 0.017305370420217514], [0.002213570987805724, 0.9918135404586792, 0.00597290089353919], [0.9997290968894958, 0.00017793361621443182, 9.292886534240097e-05], [0.0013056622119620442, 0.9882517457008362, 0.010442548431456089], [0.0010490344138816, 0.9847293496131897, 0.014221584424376488], [0.005050480831414461, 0.6928926110267639, 0.3020569086074829], [0.9995728135108948, 0.00028931928682141006, 0.0001379080058541149], [0.9470425248146057, 0.04202057421207428, 0.01093689352273941], [0.00030903960578143597, 0.9973567724227905, 0.0023342501372098923], [0.00024154936545528471, 0.9994004964828491, 0.0003579427138902247], [0.9998733997344971, 8.807473932392895e-05, 3.846676190732978e-05], [0.9995375871658325, 0.000277042796369642, 0.00018539367010816932], [0.08165707439184189, 0.8382455110549927, 0.08009740710258484], [0.0006385494489222765, 0.0005862400867044926, 0.9987751841545105], [0.999859094619751, 9.390155173605308e-05, 4.695290044764988e-05], [0.019222933799028397, 0.9794753789901733, 0.0013016487937420607], [0.9997820258140564, 0.00014036544598639011, 7.753098907414824e-05], [0.9993025064468384, 0.00044787570368498564, 0.00024960210430435836], [0.9997866749763489, 0.00013961392687633634, 7.375514542218298e-05], [0.0005063429125584662, 0.9933668971061707, 0.006126712076365948], [0.04349979758262634, 0.9533698558807373, 0.003130377968773246], [0.0011235056445002556, 0.9944803714752197, 0.004396066069602966], [0.9956372380256653, 0.00330345518887043, 0.001059281756170094], [0.000451258645625785, 0.9985289573669434, 0.001019711373373866], [0.0010362450266256928, 0.997133731842041, 0.001830032910220325], [0.00014399572683032602, 0.0010092612355947495, 0.9988467693328857], [0.9988903403282166, 0.0008123371517285705, 0.00029738369630649686], [0.0031177194323390722, 0.0206863172352314, 0.9761959314346313], [0.000121230652439408, 0.999580442905426, 0.00029832226573489606], [0.00010141041275346652, 0.00023136161325965077, 0.9996672868728638], [0.9998082518577576, 0.00011345906386850402, 7.831867696950212e-05], [0.00015260626969393343, 0.00050248799379915, 0.9993448853492737], [0.0021809889003634453, 0.949094295501709, 0.048724669963121414], [0.0027277192566543818, 0.2592528462409973, 0.7380194664001465], [0.006074514240026474, 0.935249924659729, 0.05867558345198631], [0.9987493753433228, 0.000900604180060327, 0.0003500943130347878], [0.3920753002166748, 0.26154837012290955, 0.3463762700557709], [0.0053376322612166405, 0.13771416246891022, 0.8569481372833252], [0.00229701679199934, 0.4902838468551636, 0.5074191093444824], [0.00035740004386752844, 0.9874402284622192, 0.012202378362417221], [0.0007953798049129546, 0.23574955761432648, 0.7634550929069519], [0.001853112829849124, 0.018309514969587326, 0.9798373579978943], [0.00019291073840577155, 0.9983978867530823, 0.0014092206256464124], [0.9990707635879517, 0.0006609877455048263, 0.0002682110061869025], [0.9996719360351562, 0.00020980584667995572, 0.00011822497617686167], [0.9998724460601807, 7.301526784431189e-05, 5.4452557378681377e-05], [0.9996490478515625, 0.00022560717479791492, 0.00012533504923339933], [0.9994931221008301, 0.0003826004103757441, 0.00012426204921212047], [0.001577738206833601, 0.9965584874153137, 0.0018637304892763495], [0.9965544939041138, 0.0025460119359195232, 0.0008995931129902601], [0.0006019986467435956, 0.00247529661282897, 0.9969226717948914], [0.9980113506317139, 0.0015368616441264749, 0.00045178525033406913], [0.999772846698761, 0.00016033530118875206, 6.690363807138056e-05], [0.9994112253189087, 0.00037092456477694213, 0.00021795406064484268], [0.00033435062505304813, 0.9990880489349365, 0.0005775870522484183], [0.7214017510414124, 0.27001363039016724, 0.008584633469581604], [0.00027377009973861277, 0.9993826150894165, 0.00034363786107860506], [0.999398946762085, 0.00040497141890227795, 0.0001961589587153867], [0.00048270521801896393, 0.9986868500709534, 0.0008304396760649979], [0.00024667606339789927, 0.9993883371353149, 0.00036502451985143125], [0.9998488426208496, 9.921284072333947e-05, 5.2020634029759094e-05], [0.013247724622488022, 0.4706927537918091, 0.5160595774650574], [0.995053768157959, 0.003733740421012044, 0.001212375471368432], [0.00013548778952099383, 0.9992893934249878, 0.0005751302815042436], [0.9891633987426758, 0.00860631000250578, 0.0022302567958831787], [2.6286612410331145e-05, 3.9593345718458295e-05, 0.9999340772628784], [0.0001713739038677886, 0.9993102550506592, 0.0005183885805308819], [0.0016702747670933604, 0.4404021203517914, 0.5579276084899902], [0.9983910322189331, 0.001110545708797872, 0.000498393434099853], [0.1591762900352478, 0.6067293882369995, 0.2340942919254303], [0.00015742247342132032, 0.999612033367157, 0.00023061355750542134], [0.7688957452774048, 0.22832433879375458, 0.0027799250092357397], [0.00022077091853134334, 0.9992159605026245, 0.0005632681422866881], [0.9902099370956421, 0.007083266973495483, 0.002706873929128051], [0.0003370022459421307, 0.9957931041717529, 0.0038699046708643436], [0.0012566266814246774, 0.0024400195106863976, 0.9963034391403198], [0.9976709485054016, 0.0016463241772726178, 0.000682672718539834], [0.22441864013671875, 0.48257455229759216, 0.2930068373680115], [0.9937103986740112, 0.003993217367678881, 0.0022963450755923986], [0.001995953731238842, 0.9971944093704224, 0.0008096388773992658], [0.0004192118940409273, 0.997742772102356, 0.001838091528043151], [0.00024200842017307878, 0.9993784427642822, 0.00037950632395222783], [0.9997275471687317, 0.00017555270460434258, 9.694885375211015e-05], [0.9827370643615723, 0.010409808717668056, 0.006853154860436916], [0.799331545829773, 0.11576859652996063, 0.0848998874425888], [0.00026615633396431804, 0.9954845905303955, 0.004249282646924257], [0.0007065168465487659, 0.9979960918426514, 0.0012973780976608396], [0.9989043474197388, 0.0008289697580039501, 0.0002666159125510603], [0.00031377648701891303, 0.9983420372009277, 0.0013441316550597548], [0.000687058491166681, 0.0007500614738091826, 0.9985628724098206], [0.9992546439170837, 0.00047370148240588605, 0.0002715543087106198], [0.6543030142784119, 0.3205607831478119, 0.025136305019259453], [0.0003069989616051316, 0.0003463602333795279, 0.9993466734886169], [0.017458729445934296, 0.5610123872756958, 0.4215288758277893], [0.0006688613211736083, 0.997717022895813, 0.0016141656087711453], [0.560373067855835, 0.4164990782737732, 0.023127859458327293], [0.5495844483375549, 0.29910963773727417, 0.1513058990240097], [0.9994698166847229, 0.0003888430946972221, 0.00014135893434286118], [0.0004085024993401021, 0.9989299178123474, 0.0006615238380618393], [0.0009648229461163282, 0.9981743097305298, 0.0008608546922914684], [0.07083447277545929, 0.9237698316574097, 0.005395703483372927], [0.00041810175753198564, 0.9988542795181274, 0.0007276600226759911], [0.0014590044738724828, 0.9972911477088928, 0.0012498523574322462], [0.9999191761016846, 5.073779902886599e-05, 3.0055043680476956e-05], [0.002454578410834074, 0.9959186911582947, 0.0016267618630081415], [0.0032824641093611717, 0.9937048554420471, 0.003012658329680562], [0.9961951971054077, 0.002814672654494643, 0.0009901347802951932], [0.00021496952103916556, 0.9993257522583008, 0.0004592892655637115], [0.9998050332069397, 0.0001306019985349849, 6.44102692604065e-05], [0.0001863394136307761, 0.005982611328363419, 0.9938310384750366], [0.0034548009280115366, 0.9901329278945923, 0.006412310991436243], [0.059116180986166, 0.8803196549415588, 0.06056413799524307], [0.9989653825759888, 0.0007625983562320471, 0.00027195195434615016], [0.9949571490287781, 0.0033735816832631826, 0.0016693394863978028], [0.0008311145938932896, 0.9923135638237, 0.006855329032987356], [0.00045868713641539216, 0.0010183764388784766, 0.9985230565071106], [0.5782864093780518, 0.40126851201057434, 0.02044505812227726], [0.00129121751524508, 0.06571735441684723, 0.9329914450645447], [0.0010772452224045992, 0.9956421852111816, 0.0032806156668812037], [0.0005174006801098585, 0.9978558421134949, 0.0016267503378912807], [0.005688765086233616, 0.9898171424865723, 0.0044941166415810585], [0.9998449087142944, 9.98545074253343e-05, 5.5136952141765505e-05], [0.0005395453190430999, 0.9981728792190552, 0.001287597231566906], [0.000432906934292987, 0.9989198446273804, 0.0006472267559729517], [0.000259213091339916, 0.9988981485366821, 0.0008425925043411553], [0.0012526295613497496, 0.9982744455337524, 0.0004728871281258762], [0.9986968636512756, 0.0009289300651289523, 0.00037417179555632174], [0.012196838855743408, 0.9803669452667236, 0.007436206564307213], [0.9998890161514282, 7.324879697989672e-05, 3.766916415770538e-05], [0.9999109506607056, 5.643987242365256e-05, 3.260818266426213e-05], [0.0008414710755459964, 0.9884580969810486, 0.010700374841690063], [0.9997480511665344, 0.00015682142111472785, 9.51613619690761e-05], [0.9996961355209351, 0.0002106343163177371, 9.327108273282647e-05], [0.9997747540473938, 0.00015595786680933088, 6.92156536388211e-05], [0.00020548539760056883, 0.999221682548523, 0.0005728128599002957], [0.9995280504226685, 0.00030537552083842456, 0.0001665842573856935], [0.0006092572002671659, 0.9973586201667786, 0.002032146556302905], [0.998387336730957, 0.0012775084469467402, 0.0003351452760398388], [0.00593451876193285, 0.9930429458618164, 0.0010225764708593488], [2.5878800443024375e-05, 4.029077535960823e-05, 0.9999338388442993], [0.915214478969574, 0.06703639030456543, 0.017749108374118805], [0.9995570778846741, 0.0002931527851615101, 0.00014972907956689596], [0.0005953790387138724, 0.9827119708061218, 0.016692692413926125], [9.316230716649443e-05, 0.0001369497913401574, 0.9997698664665222], [0.0005104229203425348, 0.9917820692062378, 0.007707538548856974], [0.9998089671134949, 0.00012300099479034543, 6.806773308198899e-05], [0.0003842455625999719, 0.995465099811554, 0.004150714725255966], [0.9998099207878113, 0.00011898584489244968, 7.115575135685503e-05], [0.0011286989320069551, 0.004348458256572485, 0.9945229291915894], [0.9996569156646729, 0.0002186702040489763, 0.00012445297033991665], [0.00024537916760891676, 0.9990772008895874, 0.0006774534122087061], [0.0001907700061565265, 0.9984254837036133, 0.0013837296282872558], [0.9993023872375488, 0.00046043458860367537, 0.0002371972514083609], [0.16256099939346313, 0.8318116664886475, 0.005627267062664032], [0.011872321367263794, 0.9864805340766907, 0.0016471300041303039], [0.9992842078208923, 0.0004927595146000385, 0.00022296245151665062], [8.354790043085814e-05, 0.00015527145296800882, 0.999761164188385], [0.9094110727310181, 0.06189562752842903, 0.02869323268532753], [0.999685525894165, 0.0001972263999050483, 0.000117314382805489], [0.9997956156730652, 0.00012152219278505072, 8.2804101111833e-05], [0.9995155334472656, 0.0003181103675160557, 0.00016637577209621668], [2.7517215130501427e-05, 0.00020965651492588222, 0.9997628331184387], [0.0004226835153531283, 0.9988273978233337, 0.000749868166167289], [0.0006043699686415493, 0.9989186525344849, 0.00047698794514872134], [0.9950010180473328, 0.0030920288991183043, 0.0019069287227466702], [4.605552749126218e-05, 0.0006226153927855194, 0.9993313550949097], [0.057853762060403824, 0.2202255129814148, 0.7219206690788269], [0.997897744178772, 0.0017032434698194265, 0.00039894157089293003], [0.9996978044509888, 0.0002011420001508668, 0.00010110072616953403], [0.999495267868042, 0.0003619460330810398, 0.00014277498121373355], [0.999650239944458, 0.0002290394331794232, 0.00012073639663867652], [0.00023334853176493198, 0.9989216327667236, 0.0008450510213151574], [0.0003319912648294121, 0.9955741167068481, 0.004093833267688751], [0.999692440032959, 0.0001977281499421224, 0.00010991582530550659], [0.369469553232193, 0.5955343246459961, 0.03499613329768181], [0.999859094619751, 8.992129733087495e-05, 5.100574344396591e-05], [0.17224043607711792, 0.3205445110797882, 0.5072150826454163], [0.9998005032539368, 0.00013073698210064322, 6.878404383314773e-05], [0.008471970446407795, 0.03536226600408554, 0.9561657905578613], [0.0003577537427190691, 0.9980829954147339, 0.0015592444688081741], [0.969383180141449, 0.023941384628415108, 0.006675440818071365], [0.9992095232009888, 0.0005016792565584183, 0.0002887772861868143], [0.9997633099555969, 0.00014985953748691827, 8.68635906954296e-05], [0.9998273253440857, 0.00011670272942865267, 5.6013806897681206e-05], [0.030801694840192795, 0.967240035533905, 0.0019582854583859444], [0.0008643451146781445, 0.9941178560256958, 0.005017795599997044], [5.172206510906108e-05, 0.0018700702348724008, 0.9980782270431519], [0.9948354959487915, 0.004298238083720207, 0.000866292102728039], [0.00023350861738435924, 0.9984170198440552, 0.0013494075974449515], [0.002868771320208907, 0.9958428740501404, 0.001288387575186789], [0.00040126731619238853, 0.9983106851577759, 0.0012881035218015313], [0.0006562803173437715, 0.997442364692688, 0.0019013495184481144], [0.0001897690526675433, 0.9994397759437561, 0.0003704151604324579], [0.000544179929420352, 0.9989333748817444, 0.0005224455380812287], [0.999160647392273, 0.0005024013225920498, 0.00033696339232847095], [0.014121762476861477, 0.9826725721359253, 0.0032056858763098717], [0.9991554021835327, 0.0005959711852483451, 0.00024852840579114854], [0.00044293919927440584, 0.0008748193504288793, 0.9986822009086609], [0.9399558901786804, 0.04303968697786331, 0.017004437744617462], [0.9998775720596313, 7.809424278093502e-05, 4.428343891049735e-05], [0.002625530119985342, 0.9848983883857727, 0.012476063333451748], [0.9992762207984924, 0.0005614638212136924, 0.00016231642803177238], [0.9971586465835571, 0.00239268084987998, 0.0004487023106776178], [0.00012966140639036894, 0.9996474981307983, 0.00022277991229202598], [0.025156833231449127, 0.9730306267738342, 0.0018125086789950728], [0.9998953342437744, 6.277146894717589e-05, 4.178340168436989e-05], [0.0022757777478545904, 0.9965969920158386, 0.001127284369431436], [0.9998443126678467, 0.00010327372729079798, 5.250099638942629e-05], [0.9854961037635803, 0.008566761389374733, 0.005937143694609404], [0.9979346990585327, 0.0015627460088580847, 0.0005026498693041503], [0.9699926376342773, 0.027739988639950752, 0.0022673653438687325], [0.9990986585617065, 0.0006410835776478052, 0.00026028777938336134], [0.9981734752655029, 0.0013513962039723992, 0.000475190463475883], [0.0003197174519300461, 0.9865406155586243, 0.013139649294316769], [0.9993126392364502, 0.00042304579983465374, 0.0002642986364662647], [0.00029691722011193633, 0.9993914365768433, 0.0003116212319582701], [0.11264349520206451, 0.8663726449012756, 0.020983891561627388], [0.0002879253588616848, 0.9977383613586426, 0.001973685808479786], [0.00068631925387308, 0.998488187789917, 0.0008254419080913067], [0.00029426420223899186, 0.9992148876190186, 0.000490879057906568], [0.018671268597245216, 0.9163312911987305, 0.06499747931957245], [0.9959355592727661, 0.0031625255942344666, 0.0009019748540595174], [0.0003122998750768602, 0.9990780353546143, 0.0006096757133491337], [0.002448329934850335, 0.9943891167640686, 0.0031625963747501373], [0.0009912553941830993, 0.9602571725845337, 0.038751546293497086], [0.002427224302664399, 0.9915383458137512, 0.0060343933291733265], [0.00012834214430768043, 0.99950110912323, 0.0003705668495967984], [0.9998654127120972, 8.804933895589784e-05, 4.649237962439656e-05], [0.9994316697120667, 0.0003822708677034825, 0.00018595409346744418], [0.9991835951805115, 0.0005987221957184374, 0.00021758503862656653], [0.9996851682662964, 0.00020248827058821917, 0.00011240284948144108], [0.9949753284454346, 0.0038078241050243378, 0.0012168313842266798], [0.9986323714256287, 0.0008440324454568326, 0.0005235319258645177], [0.5056222081184387, 0.4586034417152405, 0.0357743576169014], [0.035138119012117386, 0.9631341695785522, 0.0017277335282415152], [0.9958487749099731, 0.0036621098406612873, 0.0004891183343715966], [0.011380553245544434, 0.983062744140625, 0.005556709133088589], [0.9998757839202881, 8.004019036889076e-05, 4.406080915941857e-05], [0.07502878457307816, 0.9219369888305664, 0.003034246852621436], [0.9993934631347656, 0.00036757808993570507, 0.00023904065892565995], [0.9950141310691833, 0.0034800851717591286, 0.001505774213001132], [0.014688375405967236, 0.9077895283699036, 0.07752206921577454], [0.9995718598365784, 0.0002601100131869316, 0.0001680387940723449], [0.9969556331634521, 0.002103587379679084, 0.0009408182231709361], [0.015938999131321907, 0.026122288778424263, 0.9579387307167053], [8.858988621796016e-06, 1.683451046119444e-05, 0.9999743700027466], [7.040063792373985e-05, 0.9993855953216553, 0.000543978123459965], [0.9997647404670715, 0.00013785914052277803, 9.73875357885845e-05], [0.9995495676994324, 0.00028221495449543, 0.00016824125486891717], [0.9988151788711548, 0.0008425943669863045, 0.00034219675580970943], [0.9997052550315857, 0.00018280281801708043, 0.00011195013939868659], [0.0005823744577355683, 0.993844747543335, 0.005572933237999678], [0.9997023940086365, 0.00018033466767519712, 0.0001172260963357985], [0.9998137354850769, 0.0001239571865880862, 6.228710117284209e-05], [0.0008545465534552932, 0.22827063500881195, 0.7708748579025269], [3.781835766858421e-05, 6.105188367655501e-05, 0.9999011754989624], [0.00014109328913036734, 0.0010497529292479157, 0.9988092184066772], [0.9984951019287109, 0.0007990812882781029, 0.0007058986811898649], [0.0015519583830609918, 0.9368147253990173, 0.061633314937353134], [0.9870484471321106, 0.007385417353361845, 0.005566111765801907], [0.9926018118858337, 0.0050404006615281105, 0.002357744611799717], [0.9993359446525574, 0.00040440057637169957, 0.00025957735488191247], [0.98748779296875, 0.01065633725374937, 0.0018559892196208239], [0.00010795108391903341, 0.997995138168335, 0.0018968777731060982], [0.9995654225349426, 0.0002665116044227034, 0.00016804668121039867], [0.2679891884326935, 0.17958535254001617, 0.5524254441261292], [0.9999065399169922, 5.609554864349775e-05, 3.73223920178134e-05], [0.9998862743377686, 6.922529428265989e-05, 4.444891965249553e-05], [0.9993200302124023, 0.00046204356476664543, 0.00021787159494124353], [0.9997755885124207, 0.0001445173693355173, 7.982597162481397e-05], [0.986541748046875, 0.01228286325931549, 0.001175346551463008], [0.8327733874320984, 0.12005315721035004, 0.04717348888516426], [0.0010295931715518236, 0.9951855540275574, 0.00378485769033432], [0.9993860721588135, 0.000372342619812116, 0.00024159335589502007], [0.9998117089271545, 0.00012672730372287333, 6.16169927525334e-05], [0.8647909760475159, 0.11438870429992676, 0.02082042396068573], [0.9998798370361328, 7.092359737725928e-05, 4.9201938963960856e-05], [0.0005657696165144444, 0.9971529245376587, 0.002281333552673459], [0.008368321694433689, 0.8579035401344299, 0.13372811675071716], [0.001300533302128315, 0.0023966743610799313, 0.9963028430938721], [0.9845771193504333, 0.008747815154492855, 0.0066751521080732346], [0.002946315798908472, 0.006328623741865158, 0.9907251000404358], [5.1476778025971726e-05, 7.215711957542226e-05, 0.9998763799667358], [0.00043001954327337444, 0.9967413544654846, 0.00282868230715394], [0.36661356687545776, 0.5622914433479309, 0.07109499722719193], [8.177155541488901e-05, 9.479453728999943e-05, 0.9998235106468201], [0.06917160749435425, 0.23421983420848846, 0.6966086030006409], [0.001024554600007832, 0.0010109530994668603, 0.9979645013809204], [0.2485557198524475, 0.7348206043243408, 0.016623608767986298], [0.9789051413536072, 0.012738444842398167, 0.008356330916285515], [0.9998492002487183, 9.011871588882059e-05, 6.061153544578701e-05], [0.9997256398200989, 0.00017669332737568766, 9.764570859260857e-05], [0.000328871508827433, 0.04467317461967468, 0.9549978971481323], [0.9995542168617249, 0.0002597709826659411, 0.00018604999058879912], [1.8805780200636946e-05, 0.0011692309053614736, 0.9988119602203369], [0.00434622960165143, 0.9932910203933716, 0.0023627704940736294], [0.9998706579208374, 8.785554382484406e-05, 4.1482329834252596e-05], [0.9997891783714294, 0.00012455825344659388, 8.629049989394844e-05], [0.9974817633628845, 0.001920935814268887, 0.0005972881917841733], [0.9994662404060364, 0.0003245316038373858, 0.00020927394507452846], [0.059788160026073456, 0.7934245467185974, 0.14678728580474854], [0.0002415756753180176, 0.007951746694743633, 0.9918067455291748], [0.00021490069048013538, 0.00045829371083527803, 0.9993268251419067], [1.2866494216723368e-05, 2.5923553039319813e-05, 0.999961256980896], [0.47234392166137695, 0.21918469667434692, 0.3084714114665985], [0.9998761415481567, 8.244954369729385e-05, 4.1352486732648686e-05], [0.9997640252113342, 0.00015756508219055831, 7.837349403416738e-05], [0.9131520986557007, 0.06514593213796616, 0.021701859310269356], [0.9998396635055542, 0.00010489866690477356, 5.541188511415385e-05], [0.9995229244232178, 0.00028751371428370476, 0.00018956343410536647], [0.9998142123222351, 0.00012566169607453048, 6.018622298142873e-05], [0.00054683827329427, 0.9990237951278687, 0.00042930772178806365], [0.9997832179069519, 0.00014460600505117327, 7.2222959715873e-05], [0.9990445971488953, 0.0006225082324817777, 0.00033288306440226734], [0.999685525894165, 0.00019322437583468854, 0.00012131487164879218], [0.9182932376861572, 0.07745532691478729, 0.004251466598361731], [0.0021947037894278765, 0.9799156188964844, 0.01788969710469246], [0.005235860124230385, 0.5526087880134583, 0.4421553909778595], [3.799167097895406e-05, 4.016089587821625e-05, 0.9999217987060547], [2.9694001568714157e-05, 4.195032306597568e-05, 0.99992835521698], [0.0003758282109629363, 0.9985546469688416, 0.0010695138480514288], [1.052500829246128e-05, 2.0645678887376562e-05, 0.9999688863754272], [0.00014992522483225912, 0.0001873472356237471, 0.9996627569198608], [0.038960084319114685, 0.09721284359693527, 0.8638270497322083], [0.06403658539056778, 0.0547625832259655, 0.8812008500099182], [0.9899876713752747, 0.0062064495868980885, 0.0038058634381741285], [0.017918448895215988, 0.2677987813949585, 0.7142828106880188], [0.9989483952522278, 0.0006513221305795014, 0.0004004143120255321], [0.9974669218063354, 0.0014166225446388125, 0.0011164782335981727], [0.9997335076332092, 0.00016475902521051466, 0.00010179698438150808], [0.9997773766517639, 0.00013958920317236334, 8.304600487463176e-05], [0.00771769555285573, 0.9596725106239319, 0.03260977566242218], [0.9997588992118835, 0.0001489765418227762, 9.21316968742758e-05], [0.12172827869653702, 0.14874482154846191, 0.7295268774032593], [0.9998041987419128, 0.00011824061948573217, 7.753218960715458e-05], [0.9996169805526733, 0.0002678618475329131, 0.00011517025268403813], [0.9996786117553711, 0.00021539146837312728, 0.00010607710282783955], [0.9927914142608643, 0.005057574715465307, 0.0021509805228561163], [2.1730464141000994e-05, 4.6985318476799875e-05, 0.9999313354492188], [0.9995948672294617, 0.00024185569782275707, 0.00016323545423801988], [5.6872454479162116e-06, 1.4013462532602716e-05, 0.9999802112579346], [3.671067315735854e-05, 4.791390892933123e-05, 0.999915361404419], [0.00016531972505617887, 0.00018855382222682238, 0.9996461868286133], [0.00016024726210162044, 0.11041729152202606, 0.8894225358963013], [0.9989799857139587, 0.0006336336955428123, 0.0003862681332975626], [0.014861492440104485, 0.22307313978672028, 0.7620654106140137], [5.1361581427045166e-05, 6.289940210990608e-05, 0.9998856782913208], [0.999618411064148, 0.00022544842795468867, 0.00015607244858983904], [0.9996460676193237, 0.00022342383454088122, 0.00013044469233136624], [7.128615834517404e-05, 0.00034757627872750163, 0.9995811581611633], [0.8426920771598816, 0.10027442127466202, 0.057033538818359375], [0.9991393089294434, 0.0005141958245076239, 0.0003464576439000666], [0.0010583034018054605, 0.0011134681990370154, 0.9978281855583191], [0.999768078327179, 0.0001527415297459811, 7.915998867247254e-05], [0.9996345043182373, 0.0002360815997235477, 0.0001294393150601536], [5.9969308495055884e-05, 6.77610223647207e-05, 0.9998723268508911], [0.0006786686135455966, 0.0016377930296584964, 0.9976835250854492], [0.00023903002147562802, 0.9894550442695618, 0.010305885225534439], [0.00019569585856515914, 0.0003589634725358337, 0.9994452595710754], [0.0001108869255403988, 0.00023435594630427659, 0.9996546506881714], [0.9363256692886353, 0.032784849405288696, 0.030889475718140602], [0.0011013624025508761, 0.9940690994262695, 0.0048295906744897366], [0.0031358161941170692, 0.9950950145721436, 0.0017692423425614834], [0.9992250204086304, 0.0005487399757839739, 0.00022621625976171345], [0.9902717471122742, 0.006241951137781143, 0.003486271481961012], [1.8282751625520177e-05, 0.00024868748732842505, 0.999733030796051], [0.0005393311730585992, 0.002311789197847247, 0.9971489310264587], [0.0037254472263157368, 0.7243848443031311, 0.27188974618911743], [0.9996626377105713, 0.00021101749734953046, 0.00012636002793442458], [0.0001374366693198681, 0.9992812275886536, 0.0005813260795548558], [0.00010572832252364606, 0.999457061290741, 0.0004371616814751178], [0.0004412180569488555, 0.0015667157713323832, 0.9979920387268066], [0.00024999945890158415, 0.998149037361145, 0.0016009763348847628], [0.007127190474420786, 0.014504588209092617, 0.9783681631088257], [0.9994695782661438, 0.00032767123775556684, 0.00020279570890124887], [0.0003062492178287357, 0.9992628693580627, 0.00043082170304842293], [0.0006846250034868717, 0.959323525428772, 0.03999180346727371], [0.00010434666910441592, 0.9988710284233093, 0.0010245869634673], [0.9470519423484802, 0.03405765816569328, 0.018890446051955223], [0.9995782971382141, 0.00025623900000937283, 0.00016553692694287747], [0.9997488856315613, 0.00015609282127115875, 9.495429549133405e-05], [0.9998524188995361, 9.466466144658625e-05, 5.290835542837158e-05], [0.9992738366127014, 0.000426536105806008, 0.00029956907383166254], [0.00018727015412878245, 0.9992610812187195, 0.0005516262026503682], [0.017041971907019615, 0.016907930374145508, 0.9660502076148987], [0.998727023601532, 0.0010892323916777968, 0.0001837216696003452], [0.9996356964111328, 0.00022114545572549105, 0.00014317235036287457], [0.996046245098114, 0.002373455325141549, 0.0015802691923454404], [0.9998149275779724, 0.00010939467756543308, 7.569357694592327e-05], [0.00010289588681189343, 0.00034668942680582404, 0.9995502829551697], [0.999356210231781, 0.0004209567268844694, 0.0002227961376775056], [2.666334512468893e-05, 0.00014877392095513642, 0.999824583530426], [0.0002277929161209613, 0.986725926399231, 0.013046257197856903], [0.999711811542511, 0.0001739238650770858, 0.00011428874859120697], [0.03811006620526314, 0.6529608964920044, 0.30892911553382874], [0.00016815945855341852, 0.012516863644123077, 0.9873149394989014], [0.9998084902763367, 0.00012091753160348162, 7.050522253848612e-05], [0.0017760059563443065, 0.001470640185289085, 0.9967532753944397], [1.472821350034792e-05, 0.00010337121784687042, 0.9998818635940552], [0.005140111781656742, 0.005396958906203508, 0.9894629120826721], [0.9998075366020203, 0.00012220852659083903, 7.033356814645231e-05], [0.9998277425765991, 0.00011209740478079766, 6.008777199895121e-05], [0.00020025162666570395, 0.9995548129081726, 0.00024497488630004227], [0.9087233543395996, 0.04450386017560959, 0.04677274450659752], [1.2726904969895259e-05, 0.00011967839964199811, 0.9998675584793091], [0.9885258674621582, 0.007875842973589897, 0.0035983414854854345], [0.003637651912868023, 0.00401387270539999, 0.9923485517501831], [0.3413941264152527, 0.28972360491752625, 0.36888226866722107], [0.9996693134307861, 0.00021160978940315545, 0.00011903516133315861], [0.999664306640625, 0.00023775701993145049, 9.795046935323626e-05], [0.995550274848938, 0.00337896472774446, 0.00107071443926543], [0.998532772064209, 0.0008410176378674805, 0.0006262772949412465], [0.00013614272756967694, 0.005574215203523636, 0.9942896366119385], [0.0005519522819668055, 0.9833670854568481, 0.016080953180789948], [3.991062112618238e-05, 0.0012114745331928134, 0.9987486600875854], [0.0007969493744894862, 0.24511943757534027, 0.7540836930274963], [0.005448958370834589, 0.9926101565361023, 0.0019408348016440868], [7.648356404388323e-05, 0.998931348323822, 0.0009921372402459383], [0.9998615980148315, 8.658363367430866e-05, 5.185561167309061e-05], [0.000550961762201041, 0.9933409094810486, 0.0061081512831151485], [0.05473386123776436, 0.9167823195457458, 0.028483740985393524], [0.9999117851257324, 5.294415313983336e-05, 3.529802052071318e-05], [0.9999182224273682, 5.088976104161702e-05, 3.083442788920365e-05], [0.9999061822891235, 5.780051287729293e-05, 3.603560253395699e-05], [0.9098193645477295, 0.08217964321374893, 0.008000968024134636], [0.9996446371078491, 0.0002268527605338022, 0.0001284357567783445], [0.9998482465744019, 9.668253915151581e-05, 5.507533569470979e-05], [0.9996767044067383, 0.0002109263150487095, 0.00011239965533604845], [0.997092604637146, 0.002387557877227664, 0.0005197877762839198], [0.9988707900047302, 0.0006943720509298146, 0.0004348276706878096], [0.00018636432650964707, 0.03299570828676224, 0.9668179154396057], [0.00035457630292512476, 0.9989326596260071, 0.0007127056014724076], [0.00010987558198394254, 0.9990805387496948, 0.0008096276433207095], [0.0004081530496478081, 0.007338846102356911, 0.9922530055046082], [7.285765605047345e-05, 0.9997496008872986, 0.00017757889872882515], [0.00025819274014793336, 0.0011176298139616847, 0.9986242055892944], [0.8680399656295776, 0.11939472705125809, 0.012565253302454948], [0.9998301267623901, 0.00010925423703156412, 6.0532162024173886e-05], [0.9998310804367065, 0.00010496441245777532, 6.391014176188037e-05], [0.9998039603233337, 0.00013202143600210547, 6.398341793101281e-05], [0.9996923208236694, 0.00021228694822639227, 9.545262582832947e-05], [7.088288384693442e-06, 2.6858951969188638e-05, 0.9999661445617676], [0.997259259223938, 0.0015838982071727514, 0.001156887854449451], [0.9998658895492554, 7.99294066382572e-05, 5.4162937885848805e-05], [0.9995658993721008, 0.0002768211124930531, 0.0001572905166540295], [3.407486656215042e-05, 9.880787547444925e-05, 0.9998670816421509], [0.000351961818523705, 0.9913358688354492, 0.00831210520118475], [6.475791451521218e-05, 6.693683099001646e-05, 0.9998682737350464], [0.7480742335319519, 0.1411011815071106, 0.11082461476325989], [0.9996529817581177, 0.00020997562387492508, 0.00013705554010812193], [0.999866247177124, 8.426625572610646e-05, 4.940717190038413e-05], [0.00017794252198655158, 0.9994055032730103, 0.00041653565131127834], [0.9995824694633484, 0.0002803045208565891, 0.00013731785293202847], [0.9992638230323792, 0.000468583864858374, 0.0002675540454220027], [0.9998934268951416, 6.977265729801729e-05, 3.683983959490433e-05], [0.9998121857643127, 0.00012024433817714453, 6.761390250176191e-05], [0.9998830556869507, 7.61958071961999e-05, 4.079665814060718e-05], [0.9998884201049805, 7.101862138370052e-05, 4.052156873513013e-05], [0.9995276927947998, 0.0002997145929839462, 0.00017260095046367496], [0.9998020529747009, 0.00011793224985012785, 8.007718861335889e-05], [5.925414006924257e-05, 7.608658052049577e-05, 0.9998646974563599], [0.0003638933121692389, 0.9957383871078491, 0.0038977127987891436], [0.22200936079025269, 0.25797948241233826, 0.5200111865997314], [7.785291018080898e-06, 2.1064835891593248e-05, 0.9999711513519287], [0.0703929215669632, 0.0978393480181694, 0.831767737865448], [7.246238237712532e-05, 9.245955152437091e-05, 0.9998350143432617], [0.9994813799858093, 0.0003179332707077265, 0.0002008131123147905], [0.0001328648068010807, 0.9994151592254639, 0.0004519685171544552], [1.4183261555444915e-05, 0.00023818376939743757, 0.9997475743293762], [0.00011150110367452726, 0.00011573886877158657, 0.9997727274894714], [0.00010891682177316397, 0.9990139007568359, 0.000877146958373487], [4.36606424045749e-05, 7.574123446829617e-05, 0.9998806715011597], [0.00132178224157542, 0.002768960315734148, 0.9959093332290649], [0.00045883835991844535, 0.5902853012084961, 0.4092559218406677], [0.0007086787954904139, 0.0006047184579074383, 0.9986866116523743], [0.001408051117323339, 0.025203034281730652, 0.9733889102935791], [0.9996956586837769, 0.00018646017997525632, 0.00011791992437792942], [1.9358107238076627e-05, 2.3972836061147973e-05, 0.9999567270278931], [0.20300227403640747, 0.10795876383781433, 0.6890389919281006], [0.9998749494552612, 8.265571523224935e-05, 4.2412852053530514e-05], [0.9811153411865234, 0.012322913855314255, 0.006561648100614548], [0.015846876427531242, 0.14839759469032288, 0.835755467414856], [0.9995597004890442, 0.0002639117883518338, 0.00017635562107898295], [0.9981282353401184, 0.0011008803267031908, 0.0007708520861342549], [0.5608830451965332, 0.4256729781627655, 0.013443981297314167], [0.9995169639587402, 0.0003589421685319394, 0.00012412809883244336], [3.2578580430708826e-05, 6.633884913753718e-05, 0.9999010562896729], [0.001926703262142837, 0.9961085915565491, 0.00196467200294137], [0.9596997499465942, 0.025472966954112053, 0.01482728123664856], [0.9987295269966125, 0.0008352917502634227, 0.0004351218813098967], [0.9994059801101685, 0.00037715991493314505, 0.000216882792301476], [0.9357027411460876, 0.032266706228256226, 0.032030507922172546], [0.0006359246908687055, 0.9989456534385681, 0.0004184026620350778], [0.0004396963631734252, 0.00655178539454937, 0.9930086135864258], [1.8267426639795303e-05, 2.391175803495571e-05, 0.999957799911499], [0.9939916729927063, 0.004795759450644255, 0.0012125797802582383], [0.0004286576295271516, 0.9972003698348999, 0.002370935631915927], [0.999708354473114, 0.000179343405761756, 0.00011220689339097589], [0.9998413324356079, 9.700077498564497e-05, 6.157088500913233e-05], [1.0570570339041296e-05, 5.93016593484208e-05, 0.9999301433563232], [0.9998925924301147, 6.76079944241792e-05, 3.982375710620545e-05], [0.0009478992433287203, 0.1123921200633049, 0.8866599202156067], [0.994249701499939, 0.003549739485606551, 0.0022004968486726284], [0.9994391798973083, 0.0004029512347187847, 0.00015791428450029343], [0.00022011972032487392, 0.9978118538856506, 0.0019679986871778965], [0.9998531341552734, 9.142055932898074e-05, 5.546158354263753e-05], [0.0006518138106912374, 0.9988538026809692, 0.0004943371750414371], [0.9998832941055298, 7.338373688980937e-05, 4.325389818404801e-05], [0.999714195728302, 0.00016541045624762774, 0.00012038997374475002], [0.9997465014457703, 0.0001549106527818367, 9.861935541266575e-05], [0.9999117851257324, 5.41124572919216e-05, 3.4055468859151006e-05], [0.14850108325481415, 0.48809507489204407, 0.363403856754303], [0.999613344669342, 0.00023168761981651187, 0.0001550360320834443], [0.0010141088860109448, 0.9983561635017395, 0.0006296442006714642], [0.000398447533370927, 0.18600809574127197, 0.8135934472084045], [0.9997720122337341, 0.00014047051081433892, 8.744298975216225e-05], [0.999854326248169, 9.336318908026442e-05, 5.227489964454435e-05], [0.00011398216884117573, 0.0001272005756618455, 0.9997588992118835], [0.9796969294548035, 0.017587292939424515, 0.002715850016102195], [0.9984433054924011, 0.0011680383468046784, 0.00038878509076312184], [0.694837749004364, 0.15589503943920135, 0.14926721155643463], [0.9998832941055298, 7.192951306933537e-05, 4.484938472160138e-05], [0.9999309778213501, 4.6006975026102737e-05, 2.2999658540356904e-05], [0.00039249510155059397, 0.964995801448822, 0.03461171314120293], [0.019544899463653564, 0.9603914022445679, 0.02006368152797222], [0.02643686719238758, 0.9556358456611633, 0.017927303910255432], [0.00010156682401429862, 0.9989629983901978, 0.0009354235953651369], [0.00014744268264621496, 0.9984657764434814, 0.001386767253279686], [0.004174843430519104, 0.0035878883209079504, 0.9922372698783875], [0.00039497253601439297, 0.998590886592865, 0.001014095265418291], [0.0008221036987379193, 0.002473308937624097, 0.996704638004303], [7.228896720334888e-05, 0.00042303468217141926, 0.9995046854019165], [0.0028310567140579224, 0.9204012751579285, 0.07676766812801361], [0.00014515734801534563, 0.00026478327345103025, 0.9995900988578796], [0.0009668027050793171, 0.9982080459594727, 0.0008252098923549056], [0.9997983574867249, 0.0001266237668460235, 7.513759192079306e-05], [0.9991212487220764, 0.0006816621753387153, 0.00019709100888576359], [0.0011927997693419456, 0.001295081921853125, 0.9975121021270752], [2.7529154976946302e-05, 0.0003917640424333513, 0.9995806813240051], [0.326951801776886, 0.23964250087738037, 0.43340569734573364], [0.9998327493667603, 0.00010416612349217758, 6.299494270933792e-05], [0.00022531766444444656, 0.00023664487525820732, 0.9995380640029907], [2.314035373274237e-05, 3.554597060428932e-05, 0.999941349029541], [0.002782986033707857, 0.9946330785751343, 0.0025839703157544136], [0.9998890161514282, 7.220979750854895e-05, 3.876351911458187e-05], [0.999825656414032, 0.0001066614204319194, 6.76954587106593e-05], [0.9964446425437927, 0.0024923731107264757, 0.0010630515171214938], [1.2740169040625915e-05, 1.8311216990696266e-05, 0.9999688863754272], [0.002524720737710595, 0.8257748484611511, 0.17170041799545288], [0.9997208714485168, 0.0001830408291425556, 9.604397200746462e-05], [0.004621577449142933, 0.7801933288574219, 0.21518512070178986], [0.013003374449908733, 0.9788283705711365, 0.008168290369212627], [0.014114515855908394, 0.1371404081583023, 0.8487451076507568], [0.9998348951339722, 0.00010363296314608306, 6.149883847683668e-05], [0.9934982061386108, 0.0036474133376032114, 0.002854409161955118], [0.9995357990264893, 0.0002895359939429909, 0.0001746414345689118], [0.01968989707529545, 0.024866599589586258, 0.9554435610771179], [0.9997625946998596, 0.0001411016855854541, 9.628725092625245e-05], [0.00029108539456501603, 0.0047794971615076065, 0.9949294328689575], [7.919965355540626e-06, 7.548795838374645e-05, 0.999916672706604], [2.2470452677225694e-05, 0.00033257680479437113, 0.9996448755264282], [0.9997829794883728, 0.0001292458618991077, 8.786543912719935e-05], [0.9888777136802673, 0.009420830756425858, 0.001701363013125956], [0.9997703433036804, 0.00014510989421978593, 8.444995182799175e-05], [0.9997164607048035, 0.0001880791096482426, 9.541679901303723e-05], [0.9998619556427002, 8.141185389831662e-05, 5.656858775182627e-05], [0.6330729126930237, 0.12319210916757584, 0.24373497068881989], [0.06764445453882217, 0.9273678660392761, 0.004987720400094986], [0.020507236942648888, 0.9752853512763977, 0.00420738011598587], [0.0005949825863353908, 0.9988968372344971, 0.0005080996197648346], [4.5988886995473877e-05, 5.852351387147792e-05, 0.999895453453064], [8.359584171557799e-06, 7.206408918136731e-05, 0.9999195337295532], [0.006587807089090347, 0.9896089434623718, 0.0038032429292798042], [3.29777249135077e-05, 0.0007830494432710111, 0.9991839528083801], [0.00016535865142941475, 0.00023620978754479438, 0.9995984435081482], [0.9997357726097107, 0.00017122269491665065, 9.301673708250746e-05], [0.9991382360458374, 0.000571130309253931, 0.0002906156878452748], [0.9998384714126587, 0.00010262661089655012, 5.8920413721352816e-05], [0.9998821020126343, 7.473844743799418e-05, 4.3200216168770567e-05], [0.9979192614555359, 0.0014591021463274956, 0.0006216925685293972], [0.9999338388442993, 4.364447886473499e-05, 2.2580998120247386e-05], [0.9984910488128662, 0.0010436753509566188, 0.0004652984789572656], [0.0011862382525578141, 0.9983476400375366, 0.00046610075514763594], [0.9984598159790039, 0.0009396224049851298, 0.0006005571340210736], [0.00470124464482069, 0.005621897988021374, 0.9896768927574158], [1.4827527593297418e-05, 1.8473634554538876e-05, 0.9999667406082153], [0.000510557321831584, 0.9568437337875366, 0.042645689100027084], [0.0004748717765323818, 0.0008868423174135387, 0.9986382126808167], [0.5094354748725891, 0.45539358258247375, 0.035170916467905045], [0.0009197575272992253, 0.5255114436149597, 0.47356879711151123], [6.307145667960867e-05, 0.999613344669342, 0.00032366346567869186], [0.0009436895488761365, 0.9894787669181824, 0.009577533230185509], [0.00022347683261614293, 0.9991111159324646, 0.0006653794553130865], [0.9984331727027893, 0.0009605088853277266, 0.0006063578184694052], [3.687480329972459e-06, 8.218207767640706e-06, 0.9999880790710449], [9.51159108808497e-06, 1.4905196621839423e-05, 0.9999755620956421], [0.0001280194555874914, 0.00011707394878612831, 0.9997549653053284], [0.9998348951339722, 0.00010579230001894757, 5.926130688749254e-05], [0.9994687438011169, 0.0003915774868801236, 0.00013965275138616562], [0.988896369934082, 0.009136994369328022, 0.0019667036831378937], [0.9995669722557068, 0.0002750879211816937, 0.00015794260252732784], [6.672306335531175e-05, 0.0013400771422311664, 0.9985931515693665], [0.05586903169751167, 0.06858932226896286, 0.875541627407074], [0.09316720813512802, 0.8719996809959412, 0.03483309596776962], [0.999799907207489, 0.00012309045996516943, 7.698185072513297e-05], [0.9998362064361572, 0.0001021092539303936, 6.157991447253153e-05], [0.9989724159240723, 0.0006177567411214113, 0.00040992419235408306], [0.996681272983551, 0.0018941275775432587, 0.0014245171332731843], [0.992499053478241, 0.004789135418832302, 0.002711792942136526], [0.024642463773489, 0.958244800567627, 0.017112715169787407], [3.172246942995116e-05, 3.411178113310598e-05, 0.999934196472168], [0.9965435862541199, 0.002164596226066351, 0.0012918019201606512], [9.852836228674278e-06, 1.7981763448915444e-05, 0.9999721050262451], [0.8679109215736389, 0.07930564135313034, 0.05278344452381134], [0.9998559951782227, 8.913653437048197e-05, 5.481841799337417e-05], [0.9537987112998962, 0.03620755299925804, 0.009993845596909523], [0.0007803878397680819, 0.9988197684288025, 0.00039986558840610087], [0.9995067119598389, 0.00031865047640167177, 0.0001747313217492774], [0.0005061659030616283, 0.9984961748123169, 0.000997669412754476], [4.7176145017147064e-05, 8.537430403521284e-05, 0.9998674392700195], [0.999639630317688, 0.00023800456256140023, 0.00012242549564689398], [0.9997988343238831, 0.00012700987281277776, 7.419230678351596e-05], [0.9993320107460022, 0.00040656933560967445, 0.000261354842223227], [0.30619022250175476, 0.41352003812789917, 0.28028976917266846], [0.004992698319256306, 0.9815500974655151, 0.013457197695970535], [0.00029128839378245175, 0.9972176551818848, 0.0024910573847591877], [0.0003513446426950395, 0.04793801158666611, 0.9517106413841248], [0.003798475256189704, 0.8077335953712463, 0.18846799433231354], [0.0021039042621850967, 0.9900326728820801, 0.007863415405154228], [0.00018882456060964614, 0.9725168943405151, 0.027294320985674858], [0.9838729500770569, 0.01162266731262207, 0.004504452925175428], [0.9992613196372986, 0.000498507171869278, 0.00024010748893488199], [0.9998360872268677, 0.00010766992636490613, 5.6258209951920435e-05], [0.9991287589073181, 0.0005328551051206887, 0.00033834591158665717], [0.9997381567955017, 0.0001586258877068758, 0.00010321639274479821], [0.9996649026870728, 0.0002331309806322679, 0.00010206556908087805], [0.999841570854187, 0.00010736578406067565, 5.0992643082281575e-05], [0.00013261844287626445, 0.06250232458114624, 0.9373649954795837], [0.32117170095443726, 0.5618258714675903, 0.1170024424791336], [9.010310895973817e-05, 0.9979938268661499, 0.0019160911906510592], [0.0006024643662385643, 0.9976081848144531, 0.0017893891781568527], [0.00040505899232812226, 0.9992533326148987, 0.00034164520911872387], [0.5281248688697815, 0.3390718102455139, 0.1328033059835434], [0.998469889163971, 0.0011208554496988654, 0.0004091848386451602], [0.0007404852076433599, 0.9959877133369446, 0.00327182631008327], [0.11632221192121506, 0.6980918049812317, 0.18558600544929504], [0.9993723034858704, 0.00041335413698107004, 0.00021435310191009194], [0.9997739195823669, 0.00014759332407265902, 7.852113776607439e-05], [0.0032392723951488733, 0.8354691863059998, 0.1612914800643921], [0.9950560331344604, 0.0036105033941566944, 0.0013333630049601197], [0.999782145023346, 0.00013919068442191929, 7.86423624958843e-05], [0.9995922446250916, 0.0002937628305517137, 0.00011407831334508955], [0.027135232463479042, 0.9710855484008789, 0.001779178623110056], [0.04212091863155365, 0.9522008895874023, 0.005678177811205387], [0.9997575879096985, 0.0001620771363377571, 8.03217408247292e-05], [0.9992554783821106, 0.0005318392068147659, 0.00021264188399072737], [0.983720064163208, 0.010796433314681053, 0.005483438726514578], [0.9998660087585449, 8.378271741094068e-05, 5.012771362089552e-05], [0.9999096393585205, 5.9353063988965005e-05, 3.0940525903133675e-05], [0.9998502731323242, 9.81205448624678e-05, 5.164468166185543e-05], [0.04080978408455849, 0.8491695523262024, 0.11002065241336823], [4.681838981923647e-05, 6.094872151152231e-05, 0.9998922348022461], [0.9993271827697754, 0.00039523321902379394, 0.00027752865571528673], [0.001138096209615469, 0.26742348074913025, 0.7314384579658508], [0.9993712306022644, 0.0004027611284982413, 0.00022604275727644563], [0.49736860394477844, 0.4944413900375366, 0.008190065622329712], [0.010273760184645653, 0.013565515168011189, 0.9761607646942139], [9.140837391896639e-06, 1.1946358426939696e-05, 0.9999788999557495], [0.03601331636309624, 0.1352030634880066, 0.8287836313247681], [0.9971217513084412, 0.0024188868701457977, 0.0004593231715261936], [0.9839392900466919, 0.009518742561340332, 0.006541945971548557], [0.9999161958694458, 5.1602004532469437e-05, 3.219754944439046e-05], [0.2393125593662262, 0.47771334648132324, 0.2829740643501282], [0.9996500015258789, 0.00024527969071641564, 0.00010479838238097727], [8.066132431849837e-05, 0.00010844824282685295, 0.9998108744621277], [0.9994776844978333, 0.0003365552402101457, 0.00018578945309855044], [0.002482987241819501, 0.003312805201858282, 0.9942042231559753], [0.9994588494300842, 0.0003668518038466573, 0.0001743173343129456], [0.00017556028615217656, 0.023660289123654366, 0.9761641621589661], [0.9995137453079224, 0.0003060253511648625, 0.0001803138729883358], [0.9991658926010132, 0.000618078513070941, 0.0002160667208954692], [0.997314989566803, 0.0015851677162572742, 0.0010998561047017574], [0.9994742274284363, 0.0003934702544938773, 0.00013240879343356937], [0.005731185432523489, 0.00530448229983449, 0.988964319229126], [0.9994294047355652, 0.00035655227839015424, 0.00021396442025434226], [0.9975021481513977, 0.0020437990315258503, 0.0004539854999165982], [0.6875704526901245, 0.12551699578762054, 0.18691250681877136], [0.07593964785337448, 0.8430013060569763, 0.08105912059545517], [0.002341005951166153, 0.9477702975273132, 0.049888670444488525], [0.0003071681712754071, 0.9977447986602783, 0.0019481208873912692], [0.9997637867927551, 0.00015111551329027861, 8.51333315949887e-05], [0.8127588629722595, 0.16526632010936737, 0.021974772214889526], [0.9997896552085876, 0.000140770964208059, 6.961839972063899e-05], [0.9929850697517395, 0.004409093409776688, 0.0026058745570480824], [0.9998125433921814, 0.00011311674461467192, 7.442377682309598e-05], [0.0019947125110775232, 0.09811711311340332, 0.899888277053833], [0.0036708596162497997, 0.8703670501708984, 0.12596212327480316], [0.00041043866076506674, 0.9371835589408875, 0.062405988574028015], [0.0008269630488939583, 0.9800319671630859, 0.019141120836138725], [9.750620847626124e-06, 1.4272304724727292e-05, 0.9999759197235107], [0.0001528386346763, 0.00022070074919611216, 0.9996263980865479], [0.0399274080991745, 0.027121905237436295, 0.9329506158828735], [2.0760631741723046e-05, 3.3935095416381955e-05, 0.9999452829360962], [0.04621560499072075, 0.13425825536251068, 0.8195260763168335], [0.05224980041384697, 0.07284767180681229, 0.8749024868011475], [2.737973591138143e-05, 4.374848140287213e-05, 0.9999288320541382], [8.834069012664258e-05, 0.0008487523882649839, 0.9990628361701965], [1.8056240151054226e-05, 2.517020402592607e-05, 0.9999568462371826], [0.9991095662117004, 0.000559584703296423, 0.0003308095911052078], [0.9945641756057739, 0.004185380879789591, 0.0012504436308518052], [0.0002810053701978177, 0.9225229024887085, 0.07719608396291733], [0.00014063918206375092, 0.9994977712631226, 0.0003615950408857316], [0.00015660158533137292, 0.9995317459106445, 0.0003116325824521482], [0.00012685259571298957, 0.9992446899414062, 0.0006284652044996619], [0.015679432079195976, 0.9800080060958862, 0.004312573932111263], [0.999796450138092, 0.00012901336594950408, 7.455251761712134e-05], [0.9998674392700195, 8.01096175564453e-05, 5.2453218813752756e-05], [0.9991835951805115, 0.0005990445497445762, 0.00021740872762165964], [0.00029807843384332955, 0.9946544170379639, 0.005047460086643696], [0.9998249411582947, 0.00011464972340036184, 6.042330278432928e-05], [0.0001119865701184608, 0.9995834231376648, 0.000304587883874774], [0.00016182937542907894, 0.9992703795433044, 0.0005677796434611082], [0.9996631145477295, 0.0002041370898950845, 0.00013277324615046382], [0.0002250693505629897, 0.998754620552063, 0.0010203567799180746], [0.00048447359586134553, 0.9989239573478699, 0.0005914949579164386], [0.00011617198470048606, 0.9987812638282776, 0.001102619105949998], [0.00024346198188140988, 0.00032755706342868507, 0.9994290471076965], [0.07949280738830566, 0.8522866368293762, 0.0682206004858017], [0.00016127356502693146, 0.9988943934440613, 0.0009444087627343833], [0.0006369782495312393, 0.33300650119781494, 0.6663565039634705], [0.00039183703484013677, 0.5795957446098328, 0.4200124442577362], [0.9996218681335449, 0.0002392544993199408, 0.0001388539094477892], [0.00048397647333331406, 0.9905757904052734, 0.008940200321376324], [0.0001426817470928654, 0.0004914096789434552, 0.9993658661842346], [8.662279287818819e-05, 0.9981011748313904, 0.0018121799221262336], [0.9996927976608276, 0.00019245319708716124, 0.00011471725156297907], [0.9991092085838318, 0.0005320208729244769, 0.00035868489067070186], [0.9998227953910828, 0.00011828263086499646, 5.896996663068421e-05], [0.9999089241027832, 5.3271334763849154e-05, 3.784072760026902e-05], [8.712664566701278e-06, 1.698286177997943e-05, 0.9999743700027466], [0.996616542339325, 0.0017877586651593447, 0.0015957081923261285], [0.15741118788719177, 0.11385994404554367, 0.7287288308143616], [2.6070085368701257e-05, 5.134569073561579e-05, 0.999922513961792], [0.001133567187935114, 0.0016781557351350784, 0.9971882700920105], [3.8556710933335125e-05, 0.000150072286487557, 0.9998114705085754], [0.999518632888794, 0.0003081418399233371, 0.00017327112436760217], [5.25066425325349e-05, 0.00027125360793434083, 0.9996762275695801], [7.812924195604865e-06, 1.6811294699436985e-05, 0.999975323677063], [9.497391147306189e-06, 7.254472438944504e-05, 0.9999178647994995], [0.3856222629547119, 0.5441532135009766, 0.07022450864315033], [0.5860956311225891, 0.23017068207263947, 0.18373364210128784], [0.00019499352492857724, 0.9952573180198669, 0.004547696560621262]]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["test_collate = Collator(test=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=CFG.batch_size, collate_fn=test_collate)\n","\n","ids, hards, softs = test_loop(inf_model, test_dataloader)\n","hards = hards.tolist()\n","softs = softs.tolist()\n","print(ids)\n","print(hards)\n","print(softs)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["def mapper(value):\n","    match value:\n","        case 0:\n","            return 'NO'\n","        case 1:\n","            return 'DIRECT'\n","        case 2:\n","            return 'JUDGEMENTAL'\n","\n","hard_dicts = []\n","for identity, hard in zip(ids, hards):\n","    hard_dicts.append({\n","        'test_case': 'EXIST2024',\n","        'id': str(identity),\n","        'value': mapper(hard)\n","    })\n","with open(inf_model_name + '_hard.json', 'w') as fp:\n","    json.dump(hard_dicts, fp)"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["soft_dicts = []\n","for identity, soft in zip(ids, softs):\n","    soft_dicts.append({\n","        'test_case': 'EXIST2024',\n","        'id': str(identity),\n","        'value': {\n","            'DIRECT': soft[1],\n","            'NO': soft[0],\n","            'JUDGEMENTAL': soft[2],\n","        }\n","    })\n","with open(inf_model_name + '_soft.json', 'w') as fp:\n","    json.dump(soft_dicts, fp)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4894786,"sourceId":8249731,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
