{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Preamble: Install and Import Packages"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:15:16.598715Z","iopub.status.busy":"2024-05-06T18:15:16.597882Z","iopub.status.idle":"2024-05-06T18:15:25.498522Z","shell.execute_reply":"2024-05-06T18:15:25.497700Z","shell.execute_reply.started":"2024-05-06T18:15:16.598676Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import Resize\n","from torchvision.io import read_image, ImageReadMode\n","from multilingual_clip import Config_MCLIP\n","import open_clip\n","import json\n","import pandas as pd\n","import random\n","from pathlib import Path\n","import numpy as np\n","import transformers as hf\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from PIL import Image\n","import os\n","import time\n","import math"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:15:44.872551Z","iopub.status.busy":"2024-05-06T18:15:44.871975Z","iopub.status.idle":"2024-05-06T18:15:44.877783Z","shell.execute_reply":"2024-05-06T18:15:44.876660Z","shell.execute_reply.started":"2024-05-06T18:15:44.872513Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4.40.1\n"]},{"data":{"text/plain":["<torch.autograd.anomaly_mode.set_detect_anomaly at 0x2e46016a550>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["print(hf.__version__)\n","torch.autograd.set_detect_anomaly(True)"]},{"cell_type":"markdown","metadata":{},"source":["# Initialise the Configuration and Random Seeds"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:38.260806Z","iopub.status.busy":"2024-05-06T18:18:38.259845Z","iopub.status.idle":"2024-05-06T18:18:38.990037Z","shell.execute_reply":"2024-05-06T18:18:38.989149Z","shell.execute_reply.started":"2024-05-06T18:18:38.260764Z"},"trusted":true},"outputs":[],"source":["_text_model_config = {}\n","\n","_image_model_config = {\n","    \"attention_probs_dropout_prob\": 0.0,\n","    \"encoder_stride\": 16,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.0,\n","    \"hidden_size\": 768,\n","    \"image_size\": 224,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"layer_norm_eps\": 1e-12,\n","    \"num_attention_heads\": 12,\n","    \"num_channels\": 3,\n","    \"num_hidden_layers\": 0,\n","    \"patch_size\": 16,\n","    \"qkv_bias\": True,\n","}\n","\n","# Dual encoder/Concat\n","tokeniser_model_id = 'xlm-roberta-base'\n","text_model_id = 'xlm-roberta-base'\n","image_model_id = 'google/vit-base-patch16-224-in21k'\n","\n","# CLIP\n","multimodal_model_id = 'openai/clip-vit-base-patch32'\n","\n","# M-CLIP\n","# tokeniser_model_id = 'M-CLIP/XLM-Roberta-Large-Vit-B-16Plus'\n","# text_model_id = 'M-CLIP/XLM-Roberta-Large-Vit-B-16Plus'\n","# image_model_id = 'ViT-B-16-plus-240'\n","image_training_id = 'laion400m_e32'\n","\n","# ViLT\n","# multimodal_model_id = 'dandelin/vilt-b32-mlm'\n","\n","\n","class CFG:\n","    use_multimodal = True\n","    use_dualencoder = False\n","    split_lang = False\n","    save_models = False\n","    use_lstm = False\n","    use_attn = False\n","    use_mask_split = False\n","    use_modal_attn = False\n","    is_mclip = False\n","    init_weights = False\n","    tokeniser_model_id = tokeniser_model_id\n","    text_model_id = text_model_id\n","    image_model_id = image_model_id\n","    multimodal_model_id = multimodal_model_id\n","    image_training_id = image_training_id\n","    text_model_config = hf.AutoConfig.from_pretrained(text_model_id) if not 'M-CLIP' in text_model_id else None\n","    image_model_config = hf.AutoConfig.from_pretrained(image_model_id) if not 'M-CLIP' in text_model_id else None\n","    multimodal_model_config = hf.AutoConfig.from_pretrained(multimodal_model_id, text_config=_text_model_config, vision_config=_image_model_config)\n","    images_base_path = Path(f'EXIST 2024 Lab/EXIST 2024 Memes Dataset/training/memes')\n","    images_base_path_test = Path('EXIST 2024 Lab/EXIST 2024 Memes Dataset/test/memes')\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    debug = True\n","    print_freq = 300\n","    apex = True # for faster training\n","    epochs = 10\n","    learning_rate = 2e-4  # for adam optimizer\n","    eps = 1e-6\n","    betas = (0.9, 0.999)  # for adam optimizer\n","    batch_size = 64\n","    max_len = 512\n","    weight_decay = 0.01  # for adam optimizer regulaization parameter\n","    gradient_accumulation_steps = 1\n","    max_grad_norm = 1000\n","    seed = 42\n","    train = True\n","    num_class = 2  # Number of class in your dataset\n","    mlp_hidden_size = 256\n","    mlp_hidden_layers = 0\n","    mlp_dropout = 0.1\n","    mlp_grad_clip = 1.0\n","    mlp_init_range = 0.2\n","    mlp_attn_dim = 256"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:16:08.601112Z","iopub.status.busy":"2024-05-06T18:16:08.600732Z","iopub.status.idle":"2024-05-06T18:16:08.610179Z","shell.execute_reply":"2024-05-06T18:16:08.609275Z","shell.execute_reply.started":"2024-05-06T18:16:08.601082Z"},"trusted":true},"outputs":[],"source":["def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(CFG.seed)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:16:13.511690Z","iopub.status.busy":"2024-05-06T18:16:13.511328Z","iopub.status.idle":"2024-05-06T18:16:13.542982Z","shell.execute_reply":"2024-05-06T18:16:13.542212Z","shell.execute_reply.started":"2024-05-06T18:16:13.511661Z"},"trusted":true},"outputs":[],"source":["class MultilingualCLIP(hf.PreTrainedModel):\n","    config_class = Config_MCLIP.MCLIPConfig\n","\n","    def __init__(self, config, *args, **kwargs):\n","        super().__init__(config, *args, **kwargs)\n","        self.transformer = hf.AutoModel.from_pretrained(config.modelBase, cache_dir=kwargs.get(\"cache_dir\"))\n","        self.LinearTransformation = torch.nn.Linear(in_features=config.transformerDimensions,\n","                                                    out_features=config.numDims)\n","\n","    def forward(self, tokens, mask):\n","        embs = self.transformer(tokens, attention_mask=mask)[0]\n","        embs = (embs * mask.unsqueeze(2)).sum(dim=1) / mask.sum(dim=1)[:, None]\n","        return self.LinearTransformation(embs)\n","\n","    @classmethod\n","    def _load_state_dict_into_model(cls, model, state_dict, pretrained_model_name_or_path, _fast_init=True):\n","        model.load_state_dict(state_dict)\n","        return model, [], [], []"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocess the Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:08.228459Z","iopub.status.busy":"2024-05-06T18:18:08.227674Z","iopub.status.idle":"2024-05-06T18:18:08.559596Z","shell.execute_reply":"2024-05-06T18:18:08.558616Z","shell.execute_reply.started":"2024-05-06T18:18:08.228415Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(4044, 16)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>lang</th>\n","      <th>text</th>\n","      <th>meme</th>\n","      <th>path_memes</th>\n","      <th>number_annotators</th>\n","      <th>annotators</th>\n","      <th>gender_annotators</th>\n","      <th>age_annotators</th>\n","      <th>ethnicities_annotators</th>\n","      <th>study_levels_annotators</th>\n","      <th>countries_annotators</th>\n","      <th>labels_task4</th>\n","      <th>labels_task5</th>\n","      <th>labels_task6</th>\n","      <th>split</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>110001</th>\n","      <td>110001</td>\n","      <td>es</td>\n","      <td>2+2=5 MITO Albert Einstein tenía bajo rendimie...</td>\n","      <td>110001.jpeg</td>\n","      <td>memes/110001.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[YES, YES, YES, YES, YES, YES]</td>\n","      <td>[DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, DIRECT]</td>\n","      <td>[[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>110002</th>\n","      <td>110002</td>\n","      <td>es</td>\n","      <td>CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS</td>\n","      <td>110002.jpeg</td>\n","      <td>memes/110002.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[YES, YES, YES, YES, YES, YES]</td>\n","      <td>[DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, JUDGE...</td>\n","      <td>[[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>110003</th>\n","      <td>110003</td>\n","      <td>es</td>\n","      <td>ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...</td>\n","      <td>110003.jpeg</td>\n","      <td>memes/110003.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[YES, YES, NO, NO, NO, NO]</td>\n","      <td>[DIRECT, DIRECT, -, -, -, -]</td>\n","      <td>[[STEREOTYPING-DOMINANCE, OBJECTIFICATION, MIS...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>110004</th>\n","      <td>110004</td>\n","      <td>es</td>\n","      <td>Paises que \"apoyan\" los derechos de la mujer A...</td>\n","      <td>110004.jpeg</td>\n","      <td>memes/110004.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[YES, YES, NO, NO, YES, NO]</td>\n","      <td>[JUDGEMENTAL, JUDGEMENTAL, -, -, JUDGEMENTAL, -]</td>\n","      <td>[[IDEOLOGICAL-INEQUALITY], [IDEOLOGICAL-INEQUA...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>110005</th>\n","      <td>110005</td>\n","      <td>es</td>\n","      <td>Ya verás como este 8 de marzo hay uno que te s...</td>\n","      <td>110005.jpeg</td>\n","      <td>memes/110005.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[NO, YES, NO, NO, YES, NO]</td>\n","      <td>[-, JUDGEMENTAL, -, -, DIRECT, -]</td>\n","      <td>[[-], [IDEOLOGICAL-INEQUALITY], [-], [-], [IDE...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id_EXIST lang                                               text  \\\n","110001   110001   es  2+2=5 MITO Albert Einstein tenía bajo rendimie...   \n","110002   110002   es     CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS    \n","110003   110003   es  ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...   \n","110004   110004   es  Paises que \"apoyan\" los derechos de la mujer A...   \n","110005   110005   es  Ya verás como este 8 de marzo hay uno que te s...   \n","\n","               meme         path_memes number_annotators  \\\n","110001  110001.jpeg  memes/110001.jpeg                 6   \n","110002  110002.jpeg  memes/110002.jpeg                 6   \n","110003  110003.jpeg  memes/110003.jpeg                 6   \n","110004  110004.jpeg  memes/110004.jpeg                 6   \n","110005  110005.jpeg  memes/110005.jpeg                 6   \n","\n","                                               annotators   gender_annotators  \\\n","110001  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","110002  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","110003  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","110004  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","110005  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","\n","                                age_annotators  \\\n","110001  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","110002  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","110003  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","110004  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","110005  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","\n","                                   ethnicities_annotators  \\\n","110001  [Hispano or Latino, Hispano or Latino, Hispano...   \n","110002  [Hispano or Latino, Hispano or Latino, Hispano...   \n","110003  [Hispano or Latino, Hispano or Latino, Hispano...   \n","110004  [Hispano or Latino, Hispano or Latino, Hispano...   \n","110005  [Hispano or Latino, Hispano or Latino, Hispano...   \n","\n","                                  study_levels_annotators  \\\n","110001  [High school degree or equivalent, Master’s de...   \n","110002  [High school degree or equivalent, Master’s de...   \n","110003  [High school degree or equivalent, Master’s de...   \n","110004  [High school degree or equivalent, Master’s de...   \n","110005  [High school degree or equivalent, Master’s de...   \n","\n","                                     countries_annotators  \\\n","110001  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","110002  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","110003  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","110004  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","110005  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","\n","                          labels_task4  \\\n","110001  [YES, YES, YES, YES, YES, YES]   \n","110002  [YES, YES, YES, YES, YES, YES]   \n","110003      [YES, YES, NO, NO, NO, NO]   \n","110004     [YES, YES, NO, NO, YES, NO]   \n","110005      [NO, YES, NO, NO, YES, NO]   \n","\n","                                             labels_task5  \\\n","110001   [DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, DIRECT]   \n","110002  [DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, JUDGE...   \n","110003                       [DIRECT, DIRECT, -, -, -, -]   \n","110004   [JUDGEMENTAL, JUDGEMENTAL, -, -, JUDGEMENTAL, -]   \n","110005                  [-, JUDGEMENTAL, -, -, DIRECT, -]   \n","\n","                                             labels_task6          split  \n","110001  [[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...  TRAIN-MEME_ES  \n","110002  [[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...  TRAIN-MEME_ES  \n","110003  [[STEREOTYPING-DOMINANCE, OBJECTIFICATION, MIS...  TRAIN-MEME_ES  \n","110004  [[IDEOLOGICAL-INEQUALITY], [IDEOLOGICAL-INEQUA...  TRAIN-MEME_ES  \n","110005  [[-], [IDEOLOGICAL-INEQUALITY], [-], [-], [IDE...  TRAIN-MEME_ES  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["with open('EXIST 2024 Lab/EXIST 2024 Memes Dataset/training/EXIST2024_training.json', 'r', encoding='utf-8') as fp:\n","    annotations = json.load(fp)\n","df = pd.DataFrame.from_dict(annotations).T\n","print(df.shape)\n","df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:08.962373Z","iopub.status.busy":"2024-05-06T18:18:08.962006Z","iopub.status.idle":"2024-05-06T18:18:08.981050Z","shell.execute_reply":"2024-05-06T18:18:08.980036Z","shell.execute_reply.started":"2024-05-06T18:18:08.962344Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>meme</th>\n","      <th>text</th>\n","      <th>lang</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>110001</td>\n","      <td>110001.jpeg</td>\n","      <td>2+2=5 MITO Albert Einstein tenía bajo rendimie...</td>\n","      <td>es</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>110002</td>\n","      <td>110002.jpeg</td>\n","      <td>CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS</td>\n","      <td>es</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>110003</td>\n","      <td>110003.jpeg</td>\n","      <td>ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...</td>\n","      <td>es</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>110004</td>\n","      <td>110004.jpeg</td>\n","      <td>Paises que \"apoyan\" los derechos de la mujer A...</td>\n","      <td>es</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>110005</td>\n","      <td>110005.jpeg</td>\n","      <td>Ya verás como este 8 de marzo hay uno que te s...</td>\n","      <td>es</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id_EXIST         meme                                               text  \\\n","0    110001  110001.jpeg  2+2=5 MITO Albert Einstein tenía bajo rendimie...   \n","1    110002  110002.jpeg     CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS    \n","2    110003  110003.jpeg  ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...   \n","3    110004  110004.jpeg  Paises que \"apoyan\" los derechos de la mujer A...   \n","4    110005  110005.jpeg  Ya verás como este 8 de marzo hay uno que te s...   \n","\n","  lang  \n","0   es  \n","1   es  \n","2   es  \n","3   es  \n","4   es  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["mini_df = df[['id_EXIST', 'meme', 'text', 'lang']].reset_index(drop=True)\n","mini_df['id_EXIST'] = pd.to_numeric(mini_df['id_EXIST'])\n","mini_df.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:09.679379Z","iopub.status.busy":"2024-05-06T18:18:09.678690Z","iopub.status.idle":"2024-05-06T18:18:09.740465Z","shell.execute_reply":"2024-05-06T18:18:09.739514Z","shell.execute_reply.started":"2024-05-06T18:18:09.679345Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4044\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>meme</th>\n","      <th>text</th>\n","      <th>lang</th>\n","      <th>label_task4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>110001</td>\n","      <td>110001.jpeg</td>\n","      <td>2+2=5 MITO Albert Einstein tenía bajo rendimie...</td>\n","      <td>es</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>110002</td>\n","      <td>110002.jpeg</td>\n","      <td>CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS</td>\n","      <td>es</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>110003</td>\n","      <td>110003.jpeg</td>\n","      <td>ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...</td>\n","      <td>es</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>110004</td>\n","      <td>110004.jpeg</td>\n","      <td>Paises que \"apoyan\" los derechos de la mujer A...</td>\n","      <td>es</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>110005</td>\n","      <td>110005.jpeg</td>\n","      <td>Ya verás como este 8 de marzo hay uno que te s...</td>\n","      <td>es</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id_EXIST         meme                                               text  \\\n","0    110001  110001.jpeg  2+2=5 MITO Albert Einstein tenía bajo rendimie...   \n","1    110002  110002.jpeg     CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS    \n","2    110003  110003.jpeg  ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...   \n","3    110004  110004.jpeg  Paises que \"apoyan\" los derechos de la mujer A...   \n","4    110005  110005.jpeg  Ya verás como este 8 de marzo hay uno que te s...   \n","\n","  lang  label_task4  \n","0   es            1  \n","1   es            1  \n","2   es            0  \n","3   es            1  \n","4   es            0  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["task4_gold_path = Path('EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task4_gold_hard.json')\n","task5_gold_path = Path('EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task5_gold_hard.json')\n","task6_gold_path = Path('EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task6_gold_hard.json')\n","task4_gold = pd.read_json(task4_gold_path)\n","\n","choices = ['YES', 'NO']\n","mini_df = pd.merge(mini_df, task4_gold, left_on='id_EXIST', right_on='id', how='left').drop(columns=['id', 'test_case']).rename(columns={'value': 'label_task4'})\n","mini_df['label_task4'] = mini_df['label_task4'].apply(lambda x: np.random.choice(choices) if pd.isna(x) else x)\n","mini_df['label_task4'] = pd.to_numeric(mini_df['label_task4'].map({'YES': 1, 'NO': 0}))\n","print(len(mini_df))\n","mini_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Initialise the Processors/Tokenisers/Models"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:44.737506Z","iopub.status.busy":"2024-05-06T18:18:44.737103Z","iopub.status.idle":"2024-05-06T18:19:08.560431Z","shell.execute_reply":"2024-05-06T18:19:08.559371Z","shell.execute_reply.started":"2024-05-06T18:18:44.737475Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\pachinkomachine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]}],"source":["if CFG.is_mclip:\n","    tokenizer = hf.AutoTokenizer.from_pretrained(CFG.tokeniser_model_id)\n","    text_model = MultilingualCLIP.from_pretrained(CFG.text_model_id).to(CFG.device)\n","    image_model, _, image_processor = open_clip.create_model_and_transforms(CFG.image_model_id, pretrained=CFG.image_training_id)\n","    image_model = image_model.to(CFG.device)\n","elif CFG.use_multimodal:\n","    mm_processor = hf.AutoProcessor.from_pretrained(CFG.multimodal_model_id)\n","    mm_model = hf.AutoModel.from_pretrained(CFG.multimodal_model_id).to(CFG.device)\n","elif CFG.use_dualencoder:\n","    tokenizer = hf.AutoTokenizer.from_pretrained(CFG.tokeniser_model_id, padding=True, truncation=True)\n","    processor = hf.AutoImageProcessor.from_pretrained(CFG.image_model_id)\n","    de_processor = hf.VisionTextDualEncoderProcessor(image_processor=processor, tokenizer=tokenizer)\n","    text_model = hf.AutoModel.from_pretrained(CFG.text_model_id).to(CFG.device)\n","    image_model = hf.AutoModel.from_pretrained(CFG.image_model_id).to(CFG.device)\n","    de_model = hf.VisionTextDualEncoderModel(vision_model=image_model, text_model=text_model)\n","else:\n","    tokenizer = hf.AutoTokenizer.from_pretrained(CFG.tokeniser_model_id)\n","    text_model = hf.AutoModel.from_pretrained(CFG.text_model_id).to(CFG.device)\n","    # Adding a config to the image_model gets rid of lots of pretrained weights\n","    image_model = hf.AutoModel.from_pretrained(CFG.image_model_id).to(CFG.device)"]},{"cell_type":"markdown","metadata":{},"source":["# Train/Val Split"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:12.849175Z","iopub.status.busy":"2024-05-06T18:19:12.848090Z","iopub.status.idle":"2024-05-06T18:19:12.871009Z","shell.execute_reply":"2024-05-06T18:19:12.870233Z","shell.execute_reply.started":"2024-05-06T18:19:12.849140Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>meme</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>110002</td>\n","      <td>110002.jpeg</td>\n","      <td>CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>110005</td>\n","      <td>110005.jpeg</td>\n","      <td>Ya verás como este 8 de marzo hay uno que te s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>110012</td>\n","      <td>110012.jpeg</td>\n","      <td>A LOS QUE NO ME SALUDAN POR EL DIA DE LA MUJER...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>110017</td>\n","      <td>110017.jpeg</td>\n","      <td>SE ACERCA EL DIA DE LA MUJER, SE ACEPTAN POSTR...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>110020</td>\n","      <td>110020.jpeg</td>\n","      <td>Día de la Mujer Expectativa Realidad</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id_EXIST         meme                                               text\n","0    110002  110002.jpeg     CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS \n","1    110005  110005.jpeg  Ya verás como este 8 de marzo hay uno que te s...\n","2    110012  110012.jpeg  A LOS QUE NO ME SALUDAN POR EL DIA DE LA MUJER...\n","3    110017  110017.jpeg  SE ACERCA EL DIA DE LA MUJER, SE ACEPTAN POSTR...\n","4    110020  110020.jpeg              Día de la Mujer Expectativa Realidad "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["def dataframe_train_test_split(df, target_label, seed=CFG.seed, test_size=0.2, split_labels=True):\n","    train = df.sample(frac=(1.0 - test_size), random_state=seed)\n","    test = df.drop(train.index).reset_index(drop=True)\n","\n","    train.reset_index(drop=True, inplace=True)\n","\n","    if split_labels:\n","        return train.drop(columns=target_label), test.drop(columns=target_label), train[target_label], test[target_label]\n","    else:\n","        return train, test\n","\n","X_train, X_val, y_train, y_val = dataframe_train_test_split(mini_df[['id_EXIST', 'meme', 'text', 'label_task4']], 'label_task4', test_size=0.2, seed=CFG.seed)\n","X_val.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Custom Dataset Definition"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:14.449356Z","iopub.status.busy":"2024-05-06T18:19:14.448759Z","iopub.status.idle":"2024-05-06T18:19:14.463944Z","shell.execute_reply":"2024-05-06T18:19:14.462848Z","shell.execute_reply.started":"2024-05-06T18:19:14.449326Z"},"trusted":true},"outputs":[],"source":["class ExistDataset(Dataset):\n","    def __init__(self, features, img_dir, labels=None, test=False, img_transform=None, caption_transform=None, target_transform=None):\n","        self.features = features\n","        self.labels = labels\n","        self.img_dir = img_dir\n","        self.test = test\n","        self.img_transform = img_transform\n","        self.caption_transform = caption_transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, idx):\n","        img_path = str(self.img_dir.joinpath(self.features['meme'].iloc[idx]))\n","        if CFG.is_mclip:\n","            image = Image.open(img_path)\n","        else:\n","            image = read_image(img_path, mode=ImageReadMode.RGB).to(device=CFG.device)\n","        caption = self.features['text'].iloc[idx]\n","        \n","        if not self.test:\n","            label = self.labels.iloc[idx]\n","        else:\n","            identity = self.features['id_EXIST'].iloc[idx]\n","        \n","        if self.img_transform:\n","            image = self.img_transform(image)\n","        if self.caption_transform:\n","            caption = self.caption_transform(caption)\n","        if not self.test and self.target_transform:\n","            label = self.target_transform(label)\n","            \n","        if CFG.split_lang:\n","            caption = f'Language: {self.features[\"lang\"].iloc[idx]} - {caption}'\n","            \n","        if CFG.is_mclip:\n","            processed = tokenizer(caption, padding=True, return_tensors='pt')\n","            seq = processed['input_ids']\n","            mask = processed['attention_mask']\n","            image = image_processor(image)\n","        elif CFG.use_multimodal:\n","            processed = mm_processor(text=caption, images=image, return_tensors=\"pt\", padding=True, truncation=True)\n","            seq = processed['input_ids']\n","            mask = processed['attention_mask']\n","            image = processed['pixel_values']\n","        elif CFG.use_dualencoder:\n","            processed = de_processor(text=caption, images=image, return_tensors=\"pt\")\n","            seq = processed['input_ids']\n","            mask = processed['attention_mask']\n","            image = processed['pixel_values']\n","        else:\n","            processed = tokenizer.encode_plus(\n","                caption,\n","                padding='longest',\n","                truncation=True,\n","                return_tensors='pt'\n","            )\n","            seq = processed['input_ids']\n","            mask = processed['attention_mask']\n","        \n","        if not self.test:\n","            label = torch.tensor([label]).long()\n","            return image, seq, mask, label\n","        \n","        return identity, image, seq, mask"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:14.912249Z","iopub.status.busy":"2024-05-06T18:19:14.911773Z","iopub.status.idle":"2024-05-06T18:19:14.920983Z","shell.execute_reply":"2024-05-06T18:19:14.919959Z","shell.execute_reply.started":"2024-05-06T18:19:14.912215Z"},"trusted":true},"outputs":[],"source":["class Collator(object):\n","    def __init__(self, test=False):\n","        self.test = test\n","    def __call__(self, batch):\n","        if not self.test:\n","            images, seqs, masks, labels = zip(*batch)\n","            labels = torch.stack(labels)\n","        else:\n","            ids, images, seqs, masks = zip(*batch)\n","\n","        seqs = [seq.squeeze(dim=0) for seq in seqs]\n","        masks = [mask.squeeze(dim=0) for mask in masks]\n","        images = [image.squeeze(dim=0) for image in images]\n","\n","        seqs = nn.utils.rnn.pad_sequence(seqs, batch_first=True)\n","        masks = nn.utils.rnn.pad_sequence(masks, batch_first=True)\n","\n","        images = torch.stack(images)\n","        \n","        if not self.test:\n","            return images, seqs, masks, labels\n","        \n","        return ids, images, seqs, masks"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:15.535724Z","iopub.status.busy":"2024-05-06T18:19:15.535132Z","iopub.status.idle":"2024-05-06T18:19:15.540414Z","shell.execute_reply":"2024-05-06T18:19:15.539547Z","shell.execute_reply.started":"2024-05-06T18:19:15.535690Z"},"trusted":true},"outputs":[],"source":["resizer = Resize((224, 224), antialias=True)\n","\n","def resize_images(img_tensor):\n","    return resizer(img_tensor)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Initialisation"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:21.839823Z","iopub.status.busy":"2024-05-06T18:19:21.839454Z","iopub.status.idle":"2024-05-06T18:19:21.846397Z","shell.execute_reply":"2024-05-06T18:19:21.845390Z","shell.execute_reply.started":"2024-05-06T18:19:21.839793Z"},"trusted":true},"outputs":[{"data":{"text/plain":["809"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["val_dataset = ExistDataset(X_val, CFG.images_base_path, labels=y_val, img_transform=resize_images, test=True)\n","len(val_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["# Model Architecture"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:25.859218Z","iopub.status.busy":"2024-05-06T18:19:25.858470Z","iopub.status.idle":"2024-05-06T18:19:25.882149Z","shell.execute_reply":"2024-05-06T18:19:25.881167Z","shell.execute_reply.started":"2024-05-06T18:19:25.859188Z"},"trusted":true},"outputs":[],"source":["class ConcatArch(nn.Module):\n","    def __init__(self, hidden_size, hidden_layers, dropout, num_classes, use_multimodal=False, use_dualencoder=False, is_mclip=False):\n","        super().__init__()\n","        \n","        self.hidden_size = hidden_size\n","        self.hidden_layers = hidden_layers\n","        self.use_multimodal = use_multimodal\n","        self.use_dualencoder = use_dualencoder\n","        self.is_mclip = is_mclip\n","        self.is_vilt = 'ViltForMaskedLM' in CFG.multimodal_model_config.architectures\n","        \n","        if self.is_mclip:\n","            self.text_model = text_model\n","            self.image_model = image_model\n","        elif self.use_multimodal:\n","            self.mm_model = mm_model\n","        elif self.use_dualencoder:\n","            self.de_model = de_model\n","        else:\n","            self.text_model = text_model\n","            self.image_model = image_model\n","        \n","        if self.is_mclip:\n","            self.fc1 = nn.Linear(1280, self.hidden_size)\n","        elif self.use_multimodal:\n","            if self.is_vilt and CFG.use_lstm:\n","                out_channels = CFG.mlp_hidden_size + CFG.multimodal_model_config.hidden_size\n","                self.lstm = nn.LSTM(CFG.multimodal_model_config.hidden_size, CFG.mlp_hidden_size, batch_first=True)\n","            elif self.is_vilt and CFG.use_mask_split:\n","                out_channels = CFG.multimodal_model_config.hidden_size * 3\n","            elif self.is_vilt and CFG.use_attn:\n","                self.attn = nn.Sequential(\n","                    nn.Linear(CFG.multimodal_model_config.hidden_size, CFG.mlp_attn_dim),\n","                    nn.Tanh(),\n","                    nn.Linear(CFG.mlp_attn_dim, 1),\n","                    nn.Softmax(dim=1)\n","                )\n","            elif self.is_vilt and CFG.use_modal_attn:\n","                self.attn1 = nn.Sequential(\n","                    nn.Linear(CFG.multimodal_model_config.hidden_size, CFG.mlp_attn_dim),\n","                    nn.Tanh(),\n","                    nn.Linear(CFG.mlp_attn_dim, 1),\n","                    nn.Softmax(dim=1)\n","                )\n","                self.attn2 = nn.Sequential(\n","                    nn.Linear(CFG.multimodal_model_config.hidden_size, CFG.mlp_attn_dim),\n","                    nn.Tanh(),\n","                    nn.Linear(CFG.mlp_attn_dim, 1),\n","                    nn.Softmax(dim=1)\n","                )\n","                out_channels = CFG.multimodal_model_config.hidden_size * 2\n","            elif self.is_vilt:\n","                out_channels = CFG.multimodal_model_config.hidden_size\n","            else:\n","                out_channels = 2 * CFG.multimodal_model_config.projection_dim\n","            self.fc1 = nn.Linear(out_channels, self.hidden_size)\n","        elif self.use_dualencoder:\n","            self.fc1 = nn.Linear(2 * 512, self.hidden_size)\n","        else:\n","            self.fc1 = nn.Linear(CFG.text_model_config.hidden_size + CFG.image_model_config.hidden_size, self.hidden_size)\n","        self.hiddens = nn.ModuleList([nn.Linear(self.hidden_size, self.hidden_size) for _ in range(self.hidden_layers)])\n","        self.fc2 = nn.Linear(self.hidden_size, num_classes)\n","        self.activation = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","        \n","        if CFG.init_weights:\n","            self._init_weights(self.fc1)\n","            for hidden in self.hiddens:\n","                self._init_weights(hidden)\n","            self._init_weights(self.fc2)\n","\n","    def forward(self, tokens, mask, image):\n","        if self.is_mclip:\n","            emb_text = self.text_model.forward(tokens, mask)\n","            emb_img = self.image_model.encode_image(image)\n","            x = torch.cat([emb_text, emb_img], dim=1)\n","        elif self.use_multimodal:\n","            mm_output = self.mm_model(input_ids=tokens, attention_mask=mask, pixel_values=image, output_hidden_states=True)\n","            cats = [mm_output.pooler_output] if self.is_vilt else [mm_output.text_embeds, mm_output.image_embeds]\n","            \n","            if self.is_vilt and CFG.use_lstm:\n","                # First hidden state is apparently the embedding output\n","                # https://discuss.huggingface.co/t/hidden-states-embedding-tensors/3549/\n","                layerwise_cls = torch.stack([h[:, 0, :] for h in mm_output.hidden_states[1:]], dim=1)\n","                _, (h, _) = self.lstm(layerwise_cls)\n","                h = h.squeeze(dim=0)\n","                cats.append(h)\n","\n","            if self.is_vilt and CFG.use_mask_split:\n","                last_h = mm_output.last_hidden_state\n","                mask_len = mask.shape[1]\n","                mean_pooled_text = torch.mean(last_h[:, :mask_len, :], dim=1)\n","                mean_pooled_img = torch.mean(last_h[:, mask_len:, :], dim=1)\n","                cats += [mean_pooled_text, mean_pooled_img]\n","\n","            if self.is_vilt and CFG.use_attn:\n","                last_h = mm_output.last_hidden_state\n","                attentions = self.attn(last_h)\n","                x = torch.sum(attentions * last_h, dim=1)\n","\n","                cls = last_h[:, 0, :]\n","                x += cls\n","            elif self.is_vilt and CFG.use_modal_attn:\n","                last_h = mm_output.last_hidden_state\n","                mask_len = mask.shape[1]\n","                text_split = last_h[:, :mask_len, :]\n","                img_split = last_h[:, mask_len:, :]\n","                text_attentions = self.attn1(text_split)\n","                img_attentions = self.attn2(img_split)\n","                x1 = torch.sum(text_attentions * text_split, dim=1)\n","                x2 = torch.sum(img_attentions * img_split, dim=1)\n","\n","                x = torch.cat([x1, x2], dim=1)\n","\n","                cls = last_h[:, 0, :]\n","                cls = torch.cat([cls, cls], dim=1)\n","                x += cls\n","            else:\n","                x = torch.cat(cats, dim=1)\n","        elif self.use_dualencoder:\n","            de_output = self.de_model(input_ids=tokens, attention_mask=mask, pixel_values=image)\n","            x = torch.cat([de_output.text_embeds, de_output.image_embeds], dim=1)\n","        else:\n","            cls_text = self.text_model(tokens, attention_mask=mask).last_hidden_state[:, 0, :]\n","            cls_img = self.image_model(image).last_hidden_state[:, 0, :]\n","            x = torch.cat([cls_text, cls_img], dim=1)\n","\n","        x = self.fc1(x)\n","        x = self.activation(x)\n","        x = self.dropout(x)\n","        for hidden in self.hiddens:\n","            x = hidden(x)\n","            x = self.activation(x)\n","            x = self.dropout(x)\n","        x = self.fc2(x)\n","        \n","        output = x\n","        return output.float()\n","    \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=CFG.mlp_init_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=CFG.mlp_init_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)"]},{"cell_type":"markdown","metadata":{},"source":["# Utility Functions"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:31.296299Z","iopub.status.busy":"2024-05-06T18:19:31.295514Z","iopub.status.idle":"2024-05-06T18:19:31.304096Z","shell.execute_reply":"2024-05-06T18:19:31.302978Z","shell.execute_reply.started":"2024-05-06T18:19:31.296263Z"},"trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:31.726713Z","iopub.status.busy":"2024-05-06T18:19:31.726335Z","iopub.status.idle":"2024-05-06T18:19:31.731481Z","shell.execute_reply":"2024-05-06T18:19:31.730490Z","shell.execute_reply.started":"2024-05-06T18:19:31.726682Z"},"trusted":true},"outputs":[],"source":["def get_score(y_trues, y_preds):\n","    macro_f1 = f1_score(y_trues, y_preds, average='macro')\n","    return macro_f1"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:41.312411Z","iopub.status.busy":"2024-05-06T18:19:41.311584Z","iopub.status.idle":"2024-05-06T18:19:41.320936Z","shell.execute_reply":"2024-05-06T18:19:41.319856Z","shell.execute_reply.started":"2024-05-06T18:19:41.312379Z"},"trusted":true},"outputs":[],"source":["def test_loop(model, test_dataloader):\n","    all_soft = []\n","    all_hard = []\n","    all_ids = []\n","    \n","    model.eval()\n","    \n","    for identity, image, seq, mask in tqdm(test_dataloader):\n","        test_image = image.to(device=CFG.device)\n","        test_seq = seq.to(device=CFG.device)\n","        test_mask = mask.to(device=CFG.device)\n","\n","        with torch.no_grad():\n","            output = model(test_seq, test_mask, test_image)\n","        \n","        soft = nn.functional.softmax(output, dim=1)\n","        hard = output.argmax(dim=1)\n","        \n","        all_ids += list(identity)\n","        all_soft.append(soft)\n","        all_hard.append(hard)\n","        \n","    all_soft = torch.cat(all_soft, dim=0)\n","    all_hard = torch.cat(all_hard, dim=0)\n","    \n","    return all_ids, all_hard, all_soft"]},{"cell_type":"markdown","metadata":{},"source":["# Inference From Checkpoint"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["ConcatArch(\n","  (mm_model): CLIPModel(\n","    (text_model): CLIPTextTransformer(\n","      (embeddings): CLIPTextEmbeddings(\n","        (token_embedding): Embedding(49408, 512)\n","        (position_embedding): Embedding(77, 512)\n","      )\n","      (encoder): CLIPEncoder(\n","        (layers): ModuleList(\n","          (0-11): 12 x CLIPEncoderLayer(\n","            (self_attn): CLIPAttention(\n","              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","            )\n","            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): CLIPMLP(\n","              (activation_fn): QuickGELUActivation()\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","            )\n","            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","      )\n","      (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (vision_model): CLIPVisionTransformer(\n","      (embeddings): CLIPVisionEmbeddings(\n","        (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n","        (position_embedding): Embedding(50, 768)\n","      )\n","      (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (encoder): CLIPEncoder(\n","        (layers): ModuleList(\n","          (0-11): 12 x CLIPEncoderLayer(\n","            (self_attn): CLIPAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (mlp): CLIPMLP(\n","              (activation_fn): QuickGELUActivation()\n","              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","      )\n","      (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n","    (text_projection): Linear(in_features=512, out_features=512, bias=False)\n","  )\n","  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n","  (hiddens): ModuleList()\n","  (fc2): Linear(in_features=256, out_features=2, bias=True)\n","  (activation): ReLU()\n","  (dropout): Dropout(p=0.1, inplace=False)\n",")"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["collate = Collator(test=True)\n","valid_dataloader = DataLoader(val_dataset, batch_size=CFG.batch_size, collate_fn=collate)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","inf_model_name = 'openai-clip-vit-base-patch32_score_0.8837'\n","inf_model = ConcatArch(\n","    hidden_size=CFG.mlp_hidden_size,\n","    hidden_layers=CFG.mlp_hidden_layers,\n","    dropout=CFG.mlp_dropout,\n","    num_classes=CFG.num_class,\n","    use_multimodal=CFG.use_multimodal,\n","    use_dualencoder=CFG.use_dualencoder,\n","    is_mclip=CFG.is_mclip\n",").to(CFG.device)\n","inf_model.load_state_dict(torch.load('Task 4/' + inf_model_name + '.pth', map_location=torch.device(CFG.device))['model'])\n","inf_model"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 13/13 [00:10<00:00,  1.21it/s]"]},{"name":"stdout","output_type":"stream","text":["[110002, 110005, 110012, 110017, 110020, 110022, 110035, 110036, 110037, 110039, 110047, 110051, 110065, 110076, 110090, 110091, 110096, 110099, 110104, 110115, 110117, 110120, 110123, 110128, 110131, 110144, 110147, 110154, 110155, 110161, 110162, 110173, 110181, 110187, 110190, 110191, 110198, 110201, 110202, 110203, 110207, 110217, 110226, 110235, 110242, 110246, 110254, 110263, 110265, 110269, 110285, 110294, 110302, 110318, 110331, 110336, 110338, 110357, 110370, 110379, 110380, 110392, 110393, 110396, 110397, 110398, 110400, 110401, 110404, 110413, 110418, 110419, 110453, 110456, 110460, 110467, 110470, 110475, 110488, 110489, 110493, 110497, 110500, 110503, 110511, 110513, 110516, 110525, 110538, 110541, 110547, 110551, 110560, 110563, 110564, 110570, 110575, 110581, 110587, 110596, 110601, 110607, 110609, 110617, 110624, 110626, 110628, 110634, 110636, 110640, 110641, 110642, 110647, 110649, 110657, 110659, 110660, 110664, 110676, 110682, 110684, 110685, 110699, 110700, 110703, 110704, 110710, 110714, 110718, 110729, 110733, 110741, 110748, 110751, 110754, 110764, 110767, 110770, 110774, 110776, 110780, 110785, 110792, 110796, 110798, 110805, 110816, 110826, 110831, 110834, 110836, 110838, 110851, 110852, 110854, 110855, 110861, 110864, 110871, 110873, 110877, 110878, 110879, 110881, 110885, 110896, 110897, 110921, 110954, 110955, 110956, 110957, 110958, 110960, 110961, 110972, 110973, 110976, 110978, 110981, 110992, 110993, 110996, 110997, 111009, 111013, 111016, 111017, 111021, 111022, 111029, 111039, 111046, 111052, 111060, 111061, 111063, 111066, 111067, 111070, 111077, 111078, 111082, 111083, 111093, 111096, 111116, 111120, 111123, 111127, 111130, 111131, 111137, 111140, 111142, 111148, 111149, 111151, 111153, 111154, 111155, 111156, 111157, 111159, 111163, 111167, 111168, 111181, 111184, 111185, 111192, 111198, 111206, 111210, 111213, 111216, 111218, 111219, 111220, 111228, 111239, 111244, 111258, 111268, 111276, 111283, 111292, 111295, 111297, 111298, 111301, 111307, 111313, 111325, 111328, 111347, 111349, 111355, 111364, 111366, 111368, 111370, 111389, 111391, 111401, 111409, 111410, 111416, 111417, 111435, 111439, 111440, 111441, 111444, 111446, 111471, 111479, 111480, 111483, 111485, 111486, 111493, 111496, 111497, 111501, 111505, 111516, 111517, 111520, 111521, 111523, 111528, 111529, 111530, 111535, 111541, 111543, 111549, 111569, 111571, 111572, 111580, 111586, 111590, 111596, 111598, 111604, 111626, 111631, 111632, 111635, 111636, 111637, 111639, 111644, 111649, 111650, 111662, 111664, 111665, 111677, 111679, 111680, 111681, 111683, 111686, 111687, 111688, 111694, 111696, 111697, 111699, 111705, 111706, 111708, 111716, 111723, 111734, 111735, 111752, 111758, 111759, 111760, 111769, 111774, 111782, 111783, 111786, 111788, 111795, 111797, 111800, 111803, 111807, 111811, 111817, 111820, 111822, 111824, 111828, 111842, 111844, 111854, 111857, 111864, 111882, 111885, 111891, 111893, 111896, 111900, 111904, 111907, 111920, 111924, 111931, 111932, 111956, 111960, 111970, 111975, 111982, 111983, 111987, 111999, 112007, 112028, 210005, 210008, 210014, 210016, 210023, 210028, 210029, 210032, 210035, 210037, 210041, 210043, 210049, 210052, 210055, 210068, 210076, 210102, 210106, 210108, 210110, 210113, 210123, 210127, 210136, 210149, 210158, 210164, 210165, 210166, 210167, 210172, 210174, 210181, 210184, 210191, 210202, 210204, 210206, 210220, 210222, 210231, 210232, 210234, 210244, 210245, 210261, 210267, 210268, 210272, 210278, 210284, 210291, 210293, 210294, 210298, 210303, 210310, 210319, 210328, 210330, 210335, 210352, 210353, 210355, 210358, 210360, 210394, 210399, 210400, 210402, 210411, 210412, 210416, 210417, 210421, 210422, 210446, 210452, 210456, 210458, 210459, 210469, 210471, 210478, 210485, 210487, 210488, 210491, 210499, 210504, 210506, 210511, 210513, 210523, 210524, 210525, 210526, 210532, 210535, 210536, 210539, 210565, 210571, 210579, 210580, 210583, 210584, 210592, 210602, 210607, 210619, 210627, 210642, 210647, 210648, 210657, 210660, 210662, 210668, 210670, 210672, 210677, 210696, 210698, 210700, 210701, 210702, 210704, 210705, 210711, 210714, 210734, 210740, 210741, 210744, 210749, 210753, 210757, 210763, 210764, 210766, 210773, 210775, 210776, 210778, 210781, 210783, 210791, 210804, 210805, 210806, 210809, 210815, 210816, 210820, 210830, 210836, 210837, 210842, 210846, 210855, 210863, 210868, 210871, 210875, 210878, 210881, 210886, 210890, 210893, 210898, 210905, 210906, 210911, 210912, 210917, 210926, 210927, 210928, 210934, 210942, 210943, 210944, 210949, 210950, 210960, 210962, 210966, 210969, 210970, 210972, 210976, 210984, 210996, 211007, 211017, 211018, 211026, 211027, 211029, 211032, 211034, 211035, 211036, 211040, 211047, 211054, 211057, 211059, 211063, 211066, 211071, 211075, 211077, 211079, 211085, 211086, 211087, 211091, 211101, 211107, 211108, 211112, 211113, 211114, 211119, 211124, 211137, 211138, 211141, 211142, 211150, 211151, 211158, 211164, 211169, 211186, 211189, 211201, 211203, 211209, 211210, 211214, 211218, 211222, 211228, 211234, 211239, 211256, 211261, 211263, 211265, 211269, 211271, 211275, 211279, 211281, 211282, 211288, 211291, 211292, 211294, 211309, 211310, 211315, 211318, 211321, 211323, 211326, 211336, 211340, 211346, 211347, 211352, 211356, 211361, 211364, 211380, 211384, 211385, 211386, 211387, 211388, 211392, 211397, 211398, 211403, 211411, 211412, 211413, 211423, 211424, 211425, 211426, 211428, 211429, 211431, 211437, 211438, 211441, 211445, 211451, 211452, 211466, 211474, 211477, 211479, 211484, 211500, 211514, 211523, 211528, 211546, 211548, 211549, 211550, 211554, 211561, 211572, 211578, 211588, 211592, 211594, 211599, 211604, 211605, 211610, 211611, 211612, 211613, 211616, 211627, 211640, 211641, 211642, 211647, 211648, 211663, 211682, 211689, 211696, 211702, 211703, 211704, 211707, 211710, 211713, 211715, 211720, 211729, 211730, 211732, 211736, 211738, 211739, 211740, 211741, 211743, 211745, 211748, 211750, 211757, 211763, 211765, 211766, 211773, 211776, 211777, 211779, 211780, 211787, 211794, 211795, 211796, 211798, 211807, 211808, 211810, 211812, 211821, 211825, 211827, 211835, 211840, 211842, 211845, 211847, 211849, 211851, 211857, 211858, 211860, 211870, 211885, 211887, 211889, 211895, 211901, 211902, 211905, 211909, 211910, 211912, 211915, 211916, 211923, 211924, 211927, 211932, 211934, 211946, 211958, 211961, 211975, 211978, 211979, 211982, 211993, 211994, 211995, 211999]\n","[1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1]\n","[[0.006848189514130354, 0.9931517839431763], [0.9859523773193359, 0.014047622680664062], [0.9869387149810791, 0.013061322271823883], [0.0070415521040558815, 0.9929584264755249], [0.0060181766748428345, 0.9939817786216736], [0.006450675427913666, 0.9935492873191833], [0.006147486157715321, 0.9938524961471558], [0.005796103738248348, 0.9942038655281067], [0.9804924726486206, 0.019507523626089096], [0.26333504915237427, 0.7366649508476257], [0.005712877959012985, 0.9942871928215027], [0.005998691543936729, 0.9940013289451599], [0.005785941146314144, 0.9942141175270081], [0.9859434366226196, 0.014056595042347908], [0.008847297169268131, 0.9911527037620544], [0.005754918325692415, 0.9942451119422913], [0.009695831686258316, 0.990304172039032], [0.005885059013962746, 0.9941149353981018], [0.644457995891571, 0.35554197430610657], [0.9438016414642334, 0.056198421865701675], [0.9821048378944397, 0.017895225435495377], [0.0064950138330459595, 0.9935050010681152], [0.015135369263589382, 0.9848645925521851], [0.006386317312717438, 0.9936136603355408], [0.9877269864082336, 0.012273003347218037], [0.006081757601350546, 0.9939181804656982], [0.9842367172241211, 0.015763260424137115], [0.00784991029649973, 0.992150068283081], [0.006009067874401808, 0.993990957736969], [0.005909741390496492, 0.9940902590751648], [0.9845536947250366, 0.015446276403963566], [0.005763196852058172, 0.9942368268966675], [0.0058501241728663445, 0.994149923324585], [0.8837655186653137, 0.11623441427946091], [0.005860324017703533, 0.9941396713256836], [0.9704464673995972, 0.029553577303886414], [0.22321052849292755, 0.7767894268035889], [0.9202614426612854, 0.07973863184452057], [0.023191027343273163, 0.9768089652061462], [0.00577554339542985, 0.994224488735199], [0.007004800718277693, 0.9929952025413513], [0.9796516299247742, 0.020348338410258293], [0.9864387512207031, 0.013561295345425606], [0.006290474906563759, 0.9937095642089844], [0.9869241118431091, 0.013075877912342548], [0.01372663863003254, 0.9862733483314514], [0.0064655449241399765, 0.9935344457626343], [0.005892472807317972, 0.9941074848175049], [0.010142189450562, 0.9898577332496643], [0.9851043820381165, 0.014895591884851456], [0.03460674732923508, 0.9653932452201843], [0.007377877365797758, 0.9926221370697021], [0.9042216539382935, 0.09577835351228714], [0.9820747971534729, 0.017925148829817772], [0.008649719879031181, 0.9913502931594849], [0.005851482506841421, 0.9941484928131104], [0.9858055710792542, 0.014194448478519917], [0.009832075797021389, 0.9901679754257202], [0.024044735357165337, 0.9759553074836731], [0.006147028878331184, 0.993852972984314], [0.005812117829918861, 0.9941878318786621], [0.9032501578330994, 0.09674982726573944], [0.9869727492332458, 0.013027244247496128], [0.005799207370728254, 0.9942008256912231], [0.005884894635528326, 0.9941151142120361], [0.9859446287155151, 0.014055444858968258], [0.01111714169383049, 0.988882839679718], [0.00647654477506876, 0.9935234785079956], [0.006525568198412657, 0.9934744238853455], [0.006410873495042324, 0.9935891628265381], [0.669165313243866, 0.33083468675613403], [0.005976260639727116, 0.9940237402915955], [0.805473804473877, 0.19452616572380066], [0.008050940930843353, 0.9919490814208984], [0.9867700338363647, 0.013229960575699806], [0.9867130517959595, 0.013286997564136982], [0.01033090054988861, 0.9896690249443054], [0.9872840642929077, 0.012715990655124187], [0.006063562817871571, 0.9939364790916443], [0.9866153001785278, 0.013384724967181683], [0.011146388947963715, 0.9888535737991333], [0.24871647357940674, 0.7512835264205933], [0.006192661356180906, 0.9938072562217712], [0.006942946929484606, 0.9930570125579834], [0.986804723739624, 0.013195293955504894], [0.00729903532192111, 0.9927009344100952], [0.9778391122817993, 0.022160913795232773], [0.00584727106615901, 0.9941527247428894], [0.008294500410556793, 0.9917055368423462], [0.005941246636211872, 0.9940587282180786], [0.009001798927783966, 0.9909982681274414], [0.007475459482520819, 0.9925245642662048], [0.9864641427993774, 0.013535892590880394], [0.6909470558166504, 0.3090529143810272], [0.005883934907615185, 0.9941160678863525], [0.4393841624259949, 0.5606158375740051], [0.008061910979449749, 0.991938054561615], [0.1185322180390358, 0.8814677596092224], [0.00771283870562911, 0.9922871589660645], [0.007325673010200262, 0.9926742911338806], [0.9754697680473328, 0.024530254304409027], [0.5640857219696045, 0.4359142780303955], [0.23276914656162262, 0.7672308683395386], [0.9834789037704468, 0.016521109268069267], [0.03242837265133858, 0.9675716161727905], [0.9565075039863586, 0.04349251836538315], [0.006985966116189957, 0.9930140376091003], [0.006888652686029673, 0.9931113719940186], [0.01109427772462368, 0.988905668258667], [0.986486554145813, 0.013513408601284027], [0.9864761829376221, 0.013523774221539497], [0.9863184690475464, 0.013681496493518353], [0.00875039491802454, 0.9912495613098145], [0.985824704170227, 0.014175297692418098], [0.06918948143720627, 0.9308105707168579], [0.9814666509628296, 0.018533335998654366], [0.9874978065490723, 0.012502252124249935], [0.007500720210373402, 0.9924992918968201], [0.9853391647338867, 0.014660844579339027], [0.008428975939750671, 0.9915710687637329], [0.9823489785194397, 0.01765107735991478], [0.9825242161750793, 0.017475733533501625], [0.9843519330024719, 0.01564803346991539], [0.005801921244710684, 0.9941980838775635], [0.9866048693656921, 0.013395066373050213], [0.0059065623208880424, 0.9940934777259827], [0.006112147122621536, 0.9938878417015076], [0.006642358377575874, 0.9933575987815857], [0.9854236245155334, 0.014576302841305733], [0.9831794500350952, 0.016820495948195457], [0.9321229457855225, 0.06787708401679993], [0.005797929130494595, 0.9942020773887634], [0.006057662423700094, 0.9939423203468323], [0.5823975801467896, 0.41760241985321045], [0.005947048310190439, 0.9940529465675354], [0.006275475956499577, 0.993724524974823], [0.005917612463235855, 0.9940823912620544], [0.006519932299852371, 0.9934800863265991], [0.0057580131106078625, 0.9942420125007629], [0.006118311546742916, 0.9938817024230957], [0.9866229891777039, 0.013377043418586254], [0.009405798278748989, 0.9905941486358643], [0.006061582826077938, 0.9939384460449219], [0.006139119155704975, 0.9938608407974243], [0.006263153627514839, 0.9937368631362915], [0.9319239258766174, 0.06807604432106018], [0.007552610710263252, 0.9924473762512207], [0.005889248102903366, 0.9941107630729675], [0.006757825147360563, 0.9932422041893005], [0.006362431216984987, 0.9936375617980957], [0.9867438077926636, 0.013256174512207508], [0.9833468198776245, 0.01665324531495571], [0.005927401129156351, 0.9940726161003113], [0.005758979357779026, 0.9942409992218018], [0.005948144942522049, 0.9940518736839294], [0.009991859085857868, 0.9900081157684326], [0.006553759332746267, 0.9934461712837219], [0.9846453070640564, 0.015354697592556477], [0.0062584360130131245, 0.9937415719032288], [0.006699835415929556, 0.993300199508667], [0.016450226306915283, 0.9835497140884399], [0.008675887249410152, 0.9913240671157837], [0.006779867224395275, 0.9932200908660889], [0.9804203510284424, 0.01957966573536396], [0.005784421227872372, 0.9942155480384827], [0.0079420804977417, 0.9920579791069031], [0.9767577052116394, 0.02324230596423149], [0.007365100551396608, 0.9926349520683289], [0.006891184486448765, 0.9931087493896484], [0.005953123327344656, 0.9940469264984131], [0.00569926155731082, 0.9943007230758667], [0.0063264393247663975, 0.99367356300354], [0.008773098699748516, 0.9912269711494446], [0.9858561754226685, 0.014143767766654491], [0.01860441081225872, 0.9813955426216125], [0.005894205532968044, 0.9941058158874512], [0.00676043052226305, 0.9932395219802856], [0.005792082287371159, 0.9942078590393066], [0.007959000766277313, 0.9920409321784973], [0.9807363748550415, 0.01926356554031372], [0.011358238756656647, 0.9886417984962463], [0.005762371700257063, 0.9942376613616943], [0.0060755405575037, 0.9939244389533997], [0.9869055151939392, 0.013094532303512096], [0.0061807697638869286, 0.9938191771507263], [0.9844359159469604, 0.015564040280878544], [0.005904778838157654, 0.9940952062606812], [0.005930475890636444, 0.9940695762634277], [0.009411050006747246, 0.990588903427124], [0.006439329124987125, 0.9935606718063354], [0.0067111412063241005, 0.9932888150215149], [0.9714447259902954, 0.02855527400970459], [0.0067146518267691135, 0.9932854175567627], [0.0058206492103636265, 0.994179368019104], [0.9874610304832458, 0.012538908049464226], [0.9872891902923584, 0.012710878625512123], [0.9452401995658875, 0.05475980415940285], [0.02979445271193981, 0.9702056050300598], [0.005727109964936972, 0.9942728877067566], [0.03722308948636055, 0.9627769589424133], [0.9253768920898438, 0.07462315261363983], [0.009017578326165676, 0.9909824728965759], [0.008761192671954632, 0.9912387728691101], [0.9713638424873352, 0.028636092320084572], [0.006078801117837429, 0.993921160697937], [0.005847725551575422, 0.9941522479057312], [0.006148733664304018, 0.9938513040542603], [0.9430010318756104, 0.05699894577264786], [0.1185322180390358, 0.8814677596092224], [0.005804099608212709, 0.994195818901062], [0.013806266710162163, 0.9861937165260315], [0.006104929838329554, 0.9938951134681702], [0.005854110233485699, 0.9941458702087402], [0.9863889813423157, 0.013611063361167908], [0.00667948042973876, 0.9933205842971802], [0.9873418211936951, 0.012658256106078625], [0.00610315939411521, 0.9938969016075134], [0.0069297789596021175, 0.9930701851844788], [0.005926898214966059, 0.9940730929374695], [0.0060587995685637, 0.9939411878585815], [0.005754296202212572, 0.994245707988739], [0.677450954914093, 0.32254907488822937], [0.02087523601949215, 0.9791247248649597], [0.005633143242448568, 0.9943668246269226], [0.0056805661879479885, 0.9943194389343262], [0.006712006404995918, 0.993287980556488], [0.006364152766764164, 0.993635892868042], [0.9629979729652405, 0.037002015858888626], [0.017513182014226913, 0.9824867844581604], [0.0538584366440773, 0.9461415410041809], [0.29441016912460327, 0.7055898308753967], [0.9748967289924622, 0.0251032505184412], [0.006694074720144272, 0.9933059811592102], [0.006794672925025225, 0.9932053089141846], [0.9771981239318848, 0.02280185930430889], [0.009331410750746727, 0.9906685948371887], [0.006134326569736004, 0.9938656687736511], [0.9863866567611694, 0.013613302260637283], [0.00691973278298974, 0.9930803179740906], [0.005972465965896845, 0.9940274953842163], [0.007462123408913612, 0.9925379157066345], [0.0061416043899953365, 0.9938583970069885], [0.029708053916692734, 0.9702919721603394], [0.005774388089776039, 0.9942256808280945], [0.17169798910617828, 0.8283020257949829], [0.9855416417121887, 0.014458388090133667], [0.0058713993057608604, 0.9941285848617554], [0.9847901463508606, 0.01520980428904295], [0.006047914735972881, 0.9939520955085754], [0.006865324452519417, 0.993134617805481], [0.025419017300009727, 0.9745809435844421], [0.006723071448504925, 0.9932768940925598], [0.00610838457942009, 0.9938915967941284], [0.9819300770759583, 0.018069885671138763], [0.006297283340245485, 0.99370276927948], [0.005794840399175882, 0.9942051768302917], [0.0071152751334011555, 0.9928846955299377], [0.005778210237622261, 0.9942217469215393], [0.0056351604871451855, 0.994364857673645], [0.012102876789867878, 0.9878971576690674], [0.005701072048395872, 0.9942989349365234], [0.006396898068487644, 0.9936030507087708], [0.006537964101880789, 0.993462085723877], [0.00637433398514986, 0.9936256408691406], [0.9198232889175415, 0.08017673343420029], [0.005870523862540722, 0.9941295385360718], [0.9814866185188293, 0.01851338893175125], [0.006022965535521507, 0.9939770698547363], [0.006360613740980625, 0.9936394095420837], [0.007771207485347986, 0.9922288060188293], [0.006560842040926218, 0.9934391379356384], [0.9854989051818848, 0.014501072466373444], [0.01967911422252655, 0.980320930480957], [0.9865186810493469, 0.01348134595900774], [0.005710199475288391, 0.994289755821228], [0.007286607287824154, 0.9927133917808533], [0.0097329281270504, 0.9902670979499817], [0.9849094748497009, 0.015090461820363998], [0.005996025167405605, 0.99400395154953], [0.7050312757492065, 0.29496875405311584], [0.5598794221878052, 0.4401206076145172], [0.00589789729565382, 0.9941020607948303], [0.34971481561660767, 0.6502851247787476], [0.08988888561725616, 0.910111129283905], [0.987544059753418, 0.012455945834517479], [0.9589138627052307, 0.04108612239360809], [0.005843065213412046, 0.9941569566726685], [0.0064850919879972935, 0.993514895439148], [0.005706827621906996, 0.994293212890625], [0.006212495267391205, 0.9937875270843506], [0.9840077757835388, 0.0159923005849123], [0.32641366124153137, 0.673586368560791], [0.014371911063790321, 0.9856281280517578], [0.005954043008387089, 0.9940459728240967], [0.9867562055587769, 0.013243730179965496], [0.006324661895632744, 0.9936752915382385], [0.0061807697638869286, 0.9938191771507263], [0.006145738996565342, 0.993854284286499], [0.005690410733222961, 0.9943095445632935], [0.005792565643787384, 0.9942073822021484], [0.005958514753729105, 0.9940415024757385], [0.005690696649253368, 0.9943093061447144], [0.006151053588837385, 0.993848979473114], [0.9824272990226746, 0.017572719603776932], [0.9844260215759277, 0.01557401567697525], [0.9749240279197693, 0.02507602423429489], [0.0061243572272360325, 0.9938756823539734], [0.9592860341072083, 0.04071399196982384], [0.006172188092023134, 0.993827760219574], [0.9873678088188171, 0.012632107362151146], [0.948352038860321, 0.051648013293743134], [0.008530663326382637, 0.9914693236351013], [0.9864439368247986, 0.013556091114878654], [0.008507851511240005, 0.9914922118186951], [0.9844270348548889, 0.015572926960885525], [0.005826825276017189, 0.9941732287406921], [0.9874610304832458, 0.012538897804915905], [0.005903995595872402, 0.994096040725708], [0.005989022087305784, 0.9940109848976135], [0.012905976735055447, 0.987093985080719], [0.015378289856016636, 0.9846217632293701], [0.006369141861796379, 0.9936308264732361], [0.005874969530850649, 0.9941250085830688], [0.9813621640205383, 0.01863781549036503], [0.00582469068467617, 0.994175374507904], [0.006157744210213423, 0.9938422441482544], [0.9850008487701416, 0.01499909907579422], [0.006000659894198179, 0.9939993619918823], [0.006056204438209534, 0.9939437508583069], [0.006546089891344309, 0.9934539794921875], [0.00979521032422781, 0.9902048110961914], [0.005728888791054487, 0.9942711591720581], [0.010010753758251667, 0.9899892807006836], [0.00660835113376379, 0.9933916330337524], [0.9864523410797119, 0.013547657057642937], [0.00593543378636241, 0.9940646290779114], [0.0057877348735928535, 0.9942122101783752], [0.005971475970000029, 0.9940285682678223], [0.005739942658692598, 0.9942600727081299], [0.005832941737025976, 0.9941670894622803], [0.005857095122337341, 0.9941429495811462], [0.01938316971063614, 0.9806168079376221], [0.006871241144835949, 0.993128776550293], [0.9865860939025879, 0.013413948938250542], [0.008863333612680435, 0.9911366701126099], [0.006029357202351093, 0.9939706325531006], [0.008396005257964134, 0.9916040301322937], [0.9728304743766785, 0.02716956101357937], [0.005764732602983713, 0.9942353367805481], [0.9834823608398438, 0.01651759259402752], [0.936718761920929, 0.06328121572732925], [0.006417272612452507, 0.9935826659202576], [0.006480386946350336, 0.9935196042060852], [0.005714657250791788, 0.9942852854728699], [0.015922371298074722, 0.9840775728225708], [0.007765853777527809, 0.9922341108322144], [0.006377397570759058, 0.9936226010322571], [0.00674398010596633, 0.9932559728622437], [0.982689619064331, 0.017310403287410736], [0.056279826909303665, 0.9437202215194702], [0.00603188993409276, 0.99396812915802], [0.006812091451138258, 0.9931879043579102], [0.006554262712597847, 0.9934456944465637], [0.9872435927391052, 0.01275640819221735], [0.9816356897354126, 0.018364325165748596], [0.986200749874115, 0.013799244537949562], [0.006258085835725069, 0.9937419295310974], [0.006158677861094475, 0.993841290473938], [0.005824354011565447, 0.9941756725311279], [0.006288784556090832, 0.9937112331390381], [0.9568002223968506, 0.043199773877859116], [0.006000068504363298, 0.9939999580383301], [0.9864165782928467, 0.013583357445895672], [0.9861769080162048, 0.013823159039020538], [0.005725950468331575, 0.9942740797996521], [0.45889654755592346, 0.5411034822463989], [0.005861502606421709, 0.9941384792327881], [0.006264215800911188, 0.9937357902526855], [0.007924164645373821, 0.9920758008956909], [0.010180867277085781, 0.9898191094398499], [0.9772564172744751, 0.02274361439049244], [0.005751203279942274, 0.9942487478256226], [0.005814879667013884, 0.9941851496696472], [0.9720664620399475, 0.027933500707149506], [0.00901409238576889, 0.9909859895706177], [0.005776742473244667, 0.9942232966423035], [0.9714003205299377, 0.028599685057997704], [0.9872969388961792, 0.012703077867627144], [0.06733224540948868, 0.9326677918434143], [0.0068982988595962524, 0.9931017160415649], [0.0072088222950696945, 0.9927911758422852], [0.9862095713615417, 0.013790383003652096], [0.9867181181907654, 0.013281846418976784], [0.9845722913742065, 0.01542773935943842], [0.006079694721847773, 0.9939203262329102], [0.010216082446277142, 0.9897839426994324], [0.0060241189785301685, 0.9939759373664856], [0.9870304465293884, 0.012969600036740303], [0.9578188061714172, 0.04218122363090515], [0.007093230728060007, 0.9929068088531494], [0.012367140501737595, 0.9876328706741333], [0.9871779680252075, 0.012822035700082779], [0.9841302037239075, 0.015869785100221634], [0.006326696835458279, 0.9936733245849609], [0.8556535243988037, 0.14434649050235748], [0.006660464219748974, 0.993339478969574], [0.008815012872219086, 0.9911850094795227], [0.9864214658737183, 0.01357854064553976], [0.6297667026519775, 0.37023332715034485], [0.9802061319351196, 0.01979389227926731], [0.006152975372970104, 0.9938470721244812], [0.9871418476104736, 0.012858147732913494], [0.9727140069007874, 0.027286019176244736], [0.005779251456260681, 0.9942207336425781], [0.9859904050827026, 0.01400959212332964], [0.007158062886446714, 0.9928419589996338], [0.006014264654368162, 0.9939857125282288], [0.00646174093708396, 0.9935382008552551], [0.918272852897644, 0.08172713965177536], [0.006603326182812452, 0.9933966398239136], [0.006266601849347353, 0.9937333464622498], [0.006705461069941521, 0.9932945370674133], [0.006341908127069473, 0.9936581254005432], [0.9876359105110168, 0.012364041060209274], [0.006903361063450575, 0.993096649646759], [0.15139402449131012, 0.8486059308052063], [0.9871672987937927, 0.012832686305046082], [0.8428601026535034, 0.15713995695114136], [0.9574815630912781, 0.042518388479948044], [0.006496740505099297, 0.9935032725334167], [0.9845166802406311, 0.015483349561691284], [0.00581952091306448, 0.9941805601119995], [0.8286170959472656, 0.17138294875621796], [0.9808165431022644, 0.019183507189154625], [0.9839062690734863, 0.016093729063868523], [0.6626906991004944, 0.337309330701828], [0.9839650392532349, 0.016035007312893867], [0.9848393797874451, 0.015160543844103813], [0.9790045022964478, 0.02099553495645523], [0.006157989148050547, 0.9938420057296753], [0.9832469820976257, 0.016753042116761208], [0.00595271959900856, 0.9940472841262817], [0.9870842099189758, 0.012915809638798237], [0.9866607189178467, 0.013339286670088768], [0.006797933951020241, 0.9932020306587219], [0.007029267493635416, 0.9929707646369934], [0.9744146466255188, 0.02558540552854538], [0.9790144562721252, 0.020985526964068413], [0.009634744375944138, 0.9903653264045715], [0.9425367116928101, 0.05746326223015785], [0.8373806476593018, 0.16261932253837585], [0.006033819634467363, 0.9939661622047424], [0.9859143495559692, 0.014085648581385612], [0.9836559295654297, 0.01634405367076397], [0.9872669577598572, 0.012733074836432934], [0.006249811965972185, 0.9937501549720764], [0.9755190014839172, 0.024480976164340973], [0.9820516705513, 0.01794830895960331], [0.9872028231620789, 0.012797106988728046], [0.006679676007479429, 0.9933203458786011], [0.006016881670802832, 0.9939830899238586], [0.0057657272554934025, 0.9942342638969421], [0.0059698112308979034, 0.994030237197876], [0.005852506961673498, 0.994147539138794], [0.0067578949965536594, 0.993242084980011], [0.9838468432426453, 0.01615307666361332], [0.0060065011493861675, 0.9939934611320496], [0.9874230623245239, 0.012576928362250328], [0.00651441840454936, 0.9934856295585632], [0.006899781990796328, 0.9931001663208008], [0.006015188526362181, 0.9939848780632019], [0.006001012399792671, 0.9939990043640137], [0.0059946272522211075, 0.9940053820610046], [0.9871962070465088, 0.01280379667878151], [0.9614834189414978, 0.0385165773332119], [0.006037759128957987, 0.9939622282981873], [0.00605345843359828, 0.9939466118812561], [0.005606560967862606, 0.9943934679031372], [0.9783631563186646, 0.021636832505464554], [0.0077438983134925365, 0.9922560453414917], [0.0059522707015275955, 0.9940477609634399], [0.00701947882771492, 0.9929805397987366], [0.006848676595836878, 0.9931513071060181], [0.010137260891497135, 0.9898627996444702], [0.00593775836750865, 0.9940622448921204], [0.005923118442296982, 0.9940768480300903], [0.5112064480781555, 0.48879361152648926], [0.010128824971616268, 0.9898712038993835], [0.0090597840026021, 0.9909402132034302], [0.9408923983573914, 0.059107597917318344], [0.009723594412207603, 0.9902764558792114], [0.7561833262443542, 0.24381667375564575], [0.00986038614064455, 0.9901395440101624], [0.0063450997695326805, 0.9936549663543701], [0.9847397804260254, 0.015260297805070877], [0.007386473007500172, 0.9926135540008545], [0.009190571494400501, 0.990809440612793], [0.007525489199906588, 0.9924744963645935], [0.9848665595054626, 0.015133414417505264], [0.00990726426243782, 0.9900926947593689], [0.9827868938446045, 0.017213091254234314], [0.00581909017637372, 0.9941808581352234], [0.9836746454238892, 0.016325388103723526], [0.006009241100400686, 0.9939907789230347], [0.9836238622665405, 0.01637609675526619], [0.2484986037015915, 0.7515013813972473], [0.9405556321144104, 0.0594443753361702], [0.5490538477897644, 0.4509461224079132], [0.005880577489733696, 0.99411940574646], [0.008363597095012665, 0.991636335849762], [0.005988271441310644, 0.9940117001533508], [0.08299768716096878, 0.9170023202896118], [0.9864557981491089, 0.013544159010052681], [0.9873282313346863, 0.012671827338635921], [0.9870530962944031, 0.012946856208145618], [0.9746459126472473, 0.025354091078042984], [0.9873554110527039, 0.012644579634070396], [0.9859311580657959, 0.01406878512352705], [0.006013586185872555, 0.9939863681793213], [0.08712679892778397, 0.9128732085227966], [0.005672287195920944, 0.99432772397995], [0.9821166396141052, 0.017883319407701492], [0.7721919417381287, 0.2278081327676773], [0.9838159680366516, 0.01618400774896145], [0.02858368679881096, 0.9714162945747375], [0.7974246740341187, 0.20257529616355896], [0.9866530299186707, 0.013346951454877853], [0.00617603026330471, 0.9938240051269531], [0.9868490695953369, 0.013150886632502079], [0.9843748211860657, 0.015625199303030968], [0.007462921552360058, 0.9925370812416077], [0.9729446172714233, 0.027055349200963974], [0.9795551896095276, 0.020444775000214577], [0.9774426221847534, 0.0225573368370533], [0.9756755828857422, 0.02432439662516117], [0.9786005616188049, 0.021399451419711113], [0.005866100080311298, 0.9941338896751404], [0.9825511574745178, 0.017448851838707924], [0.09268966317176819, 0.9073103666305542], [0.020383482798933983, 0.9796165227890015], [0.8871931433677673, 0.11280690878629684], [0.007057189010083675, 0.9929428100585938], [0.2735937535762787, 0.7264062762260437], [0.9858910441398621, 0.014108923263847828], [0.984703779220581, 0.015296254307031631], [0.9823830127716064, 0.017617013305425644], [0.3105353116989136, 0.6894646883010864], [0.9861505627632141, 0.0138494111597538], [0.9869728684425354, 0.01302720233798027], [0.006317734252661467, 0.9936822652816772], [0.006399305071681738, 0.9936006665229797], [0.005983148235827684, 0.9940168857574463], [0.006292399950325489, 0.993707537651062], [0.005867969244718552, 0.9941319823265076], [0.005876286420971155, 0.9941237568855286], [0.9819710850715637, 0.018028883263468742], [0.006333787459880114, 0.9936662316322327], [0.006439249496906996, 0.993560791015625], [0.006729207932949066, 0.9932708144187927], [0.9809911251068115, 0.019008856266736984], [0.03608691319823265, 0.963913083076477], [0.006380253937095404, 0.9936197400093079], [0.09089363366365433, 0.9091063737869263], [0.00850143376737833, 0.9914985299110413], [0.007173342630267143, 0.9928267002105713], [0.0057786512188613415, 0.9942213296890259], [0.005805305205285549, 0.9941946864128113], [0.008169034495949745, 0.9918310046195984], [0.9864971041679382, 0.01350285392254591], [0.007331337779760361, 0.992668628692627], [0.0063419705256819725, 0.9936580061912537], [0.9868183135986328, 0.013181716203689575], [0.00666193850338459, 0.9933381080627441], [0.007304152939468622, 0.9926958084106445], [0.03503841534256935, 0.964961588382721], [0.050255268812179565, 0.9497447609901428], [0.006427132058888674, 0.9935729503631592], [0.006091949995607138, 0.9939080476760864], [0.006829431746155024, 0.9931706190109253], [0.007835711352527142, 0.9921642541885376], [0.006616388913244009, 0.9933835864067078], [0.005945996381342411, 0.9940540194511414], [0.008230401203036308, 0.991769552230835], [0.006244400981813669, 0.993755578994751], [0.9863791465759277, 0.013620860874652863], [0.006523676682263613, 0.9934763312339783], [0.006988242734223604, 0.9930117726325989], [0.013873977586627007, 0.9861260056495667], [0.9828082919120789, 0.017191637307405472], [0.9870302081108093, 0.012969795614480972], [0.0065292418003082275, 0.9934707880020142], [0.006170906592160463, 0.993829071521759], [0.006801280193030834, 0.9931986927986145], [0.006135488860309124, 0.9938644766807556], [0.9699727892875671, 0.030027199536561966], [0.015539293177425861, 0.9844606518745422], [0.9868434071540833, 0.01315657515078783], [0.007582822814583778, 0.9924172163009644], [0.015543503686785698, 0.984456479549408], [0.006127429194748402, 0.9938726425170898], [0.005859763827174902, 0.9941402077674866], [0.00717755826190114, 0.9928224682807922], [0.024311963468790054, 0.975688099861145], [0.9862363934516907, 0.013763684779405594], [0.9853425025939941, 0.014657469466328621], [0.007614810951054096, 0.9923851490020752], [0.986750066280365, 0.013249926269054413], [0.005869054235517979, 0.9941309094429016], [0.9426479339599609, 0.057352062314748764], [0.9663355350494385, 0.03366447985172272], [0.9860975742340088, 0.013902358710765839], [0.2792290449142456, 0.7207709550857544], [0.009381260722875595, 0.9906187653541565], [0.9871726036071777, 0.012827347964048386], [0.005965381395071745, 0.9940345883369446], [0.9852898716926575, 0.014710107818245888], [0.005810244474560022, 0.9941897392272949], [0.9716123938560486, 0.02838759310543537], [0.015623798593878746, 0.9843761920928955], [0.009221600368618965, 0.9907784461975098], [0.008725849911570549, 0.9912741780281067], [0.007622915785759687, 0.9923770427703857], [0.01145094446837902, 0.9885490536689758], [0.9849425554275513, 0.01505745854228735], [0.9413391351699829, 0.05866085737943649], [0.9773306846618652, 0.022669386118650436], [0.6777345538139343, 0.3222654461860657], [0.9856014847755432, 0.014398491941392422], [0.006239407695829868, 0.9937605261802673], [0.987274169921875, 0.012725780718028545], [0.9539491534233093, 0.04605083167552948], [0.8651809096336365, 0.13481910526752472], [0.008281557820737362, 0.9917184114456177], [0.3022351861000061, 0.6977648138999939], [0.9860410094261169, 0.01395900547504425], [0.9857236742973328, 0.01427628193050623], [0.9354338645935059, 0.06456618756055832], [0.005843311548233032, 0.9941567182540894], [0.9854099750518799, 0.01458998117595911], [0.9747102856636047, 0.025289786979556084], [0.00575253926217556, 0.9942474365234375], [0.04587867110967636, 0.9541213512420654], [0.006350748706609011, 0.9936493039131165], [0.21721182763576508, 0.7827882170677185], [0.006631373893469572, 0.9933686852455139], [0.07121095806360245, 0.9287890195846558], [0.9846389889717102, 0.01536109484732151], [0.007201529573649168, 0.9927984476089478], [0.8800601363182068, 0.1199398785829544], [0.006008617114275694, 0.9939913153648376], [0.5566344261169434, 0.44336551427841187], [0.9870411157608032, 0.012958829291164875], [0.9827744364738464, 0.017225483432412148], [0.006154610775411129, 0.9938454031944275], [0.8935266733169556, 0.10647337138652802], [0.005887271836400032, 0.9941127896308899], [0.9867734909057617, 0.013226537965238094], [0.9859920144081116, 0.014007985591888428], [0.010368474759161472, 0.9896315932273865], [0.007187728304415941, 0.9928122162818909], [0.9847405552864075, 0.015259481966495514], [0.8577849268913269, 0.1422150582075119], [0.603814959526062, 0.3961850106716156], [0.9701502919197083, 0.02984975464642048], [0.09568281471729279, 0.9043172001838684], [0.9795620441436768, 0.02043796516954899], [0.006338758859783411, 0.9936611652374268], [0.006865978240966797, 0.9931340217590332], [0.01233955193310976, 0.9876604080200195], [0.009832463227212429, 0.990167498588562], [0.015954725444316864, 0.9840452671051025], [0.006343320477753878, 0.9936566948890686], [0.9839940071105957, 0.01600603759288788], [0.986554741859436, 0.013445207849144936], [0.006200833711773157, 0.9937991499900818], [0.986775815486908, 0.013224128633737564], [0.006273002363741398, 0.9937269687652588], [0.006130600813776255, 0.993869423866272], [0.02815970964729786, 0.9718403220176697], [0.9870004057884216, 0.012999573722481728], [0.010826156474649906, 0.9891738891601562], [0.005989645142108202, 0.994010329246521], [0.9532153010368347, 0.04678473249077797], [0.009422549977898598, 0.9905774593353271], [0.9875019788742065, 0.012498071417212486], [0.984837532043457, 0.015162446536123753], [0.02457319013774395, 0.9754267930984497], [0.0062676891684532166, 0.9937322735786438], [0.40966665744781494, 0.5903332829475403], [0.006454888265579939, 0.9935451745986938], [0.9834797382354736, 0.016520336270332336], [0.9870647192001343, 0.012935320846736431], [0.9870916604995728, 0.012908303178846836], [0.0061807697638869286, 0.9938191771507263], [0.6638355255126953, 0.33616453409194946], [0.007064065895974636, 0.9929359555244446], [0.9834409952163696, 0.016559023410081863], [0.005894811823964119, 0.9941052198410034], [0.006174554582685232, 0.9938254356384277], [0.9264590740203857, 0.07354092597961426], [0.5321879982948303, 0.46781203150749207], [0.9828512668609619, 0.017148733139038086], [0.006849356926977634, 0.9931506514549255], [0.15839754045009613, 0.8416023850440979], [0.006454722490161657, 0.9935452938079834], [0.009715731255710125, 0.990284264087677], [0.006482075899839401, 0.9935179948806763], [0.9868980646133423, 0.013101935386657715], [0.9842549562454224, 0.015745118260383606], [0.9865477681159973, 0.013452217914164066], [0.06539145112037659, 0.934608519077301], [0.00857129879295826, 0.9914286732673645], [0.00623461976647377, 0.9937653541564941], [0.018772143870592117, 0.9812278151512146], [0.9861506819725037, 0.013849261216819286], [0.8765413165092468, 0.12345867604017258], [0.9864913821220398, 0.013508591800928116], [0.00689841341227293, 0.9931015968322754], [0.02436867356300354, 0.9756313562393188], [0.9869807362556458, 0.013019227422773838], [0.9839634299278259, 0.016036517918109894], [0.9867209196090698, 0.013279016129672527], [0.9878354668617249, 0.012164485640823841], [0.005762753542512655, 0.9942371845245361], [0.9839956164360046, 0.016004333272576332], [0.0057799420319497585, 0.9942200183868408], [0.006311229895800352, 0.9936887621879578], [0.9870981574058533, 0.01290186494588852], [0.9772031307220459, 0.022796792909502983], [0.9867831468582153, 0.013216850347816944], [0.0393371619284153, 0.960662841796875], [0.9863290190696716, 0.013670973479747772], [0.9853563904762268, 0.014643597416579723], [0.9854596257209778, 0.01454029232263565], [0.9842876195907593, 0.01571233570575714], [0.012381644919514656, 0.9876183271408081], [0.9865070581436157, 0.013492931611835957], [0.005797132384032011, 0.9942029118537903], [0.9264833331108093, 0.07351668924093246], [0.0156917292624712, 0.9843083024024963], [0.9855092167854309, 0.014490806497633457], [0.005712836980819702, 0.9942871928215027], [0.005957879591733217, 0.9940420985221863], [0.007997802458703518, 0.9920022487640381], [0.009950613602995872, 0.9900493621826172], [0.9539005160331726, 0.046099480241537094], [0.9805167317390442, 0.019483305513858795], [0.3003975450992584, 0.699602484703064], [0.9863872528076172, 0.013612733222544193], [0.006229446269571781, 0.9937705397605896], [0.0060175093822181225, 0.9939824938774109], [0.00729905953630805, 0.9927009344100952], [0.006241817958652973, 0.9937582015991211], [0.012443247251212597, 0.9875566959381104], [0.006383891683071852, 0.9936161041259766], [0.023446330800652504, 0.9765536785125732], [0.9847036004066467, 0.015296484343707561], [0.9876884818077087, 0.0123114800080657], [0.0062020267359912395, 0.9937979578971863], [0.9645532965660095, 0.03544670715928078], [0.9848859906196594, 0.015113996341824532], [0.0056815845891833305, 0.994318425655365], [0.9345329403877258, 0.06546702980995178], [0.9815372228622437, 0.018462801352143288], [0.6734163165092468, 0.32658371329307556], [0.9780673384666443, 0.021932628005743027], [0.6545740962028503, 0.34542590379714966], [0.9292914271354675, 0.07070852816104889], [0.4111386835575104, 0.5888612866401672], [0.12930142879486084, 0.8706985712051392], [0.03180646523833275, 0.968193531036377], [0.0058540827594697475, 0.9941458702087402], [0.8219037055969238, 0.17809627950191498], [0.9839984178543091, 0.016001546755433083], [0.984025776386261, 0.015974247828125954], [0.9814774394035339, 0.018522534519433975], [0.03797091543674469, 0.9620290994644165], [0.006040581036359072, 0.9939594268798828], [0.9126993417739868, 0.08730067312717438], [0.5578658580780029, 0.44213417172431946], [0.007319268304854631, 0.9926807284355164], [0.006247762590646744, 0.9937521815299988], [0.9864416718482971, 0.013558411970734596], [0.0057237111032009125, 0.9942763447761536], [0.00586468493565917, 0.9941352605819702], [0.006141767371445894, 0.993858277797699], [0.007760506588965654, 0.9922394752502441], [0.007734004873782396, 0.9922659993171692], [0.1269211322069168, 0.8730788826942444], [0.9063996076583862, 0.09360036253929138], [0.9775654077529907, 0.02243460714817047], [0.005791775416582823, 0.9942082166671753], [0.9869017004966736, 0.013098347000777721], [0.6099284291267395, 0.3900715708732605], [0.022345703095197678, 0.9776542782783508], [0.9872877597808838, 0.0127122076228261], [0.9511707425117493, 0.048829201608896255], [0.007046535145491362, 0.9929534792900085], [0.00574212521314621, 0.9942578077316284], [0.9870229959487915, 0.012976969592273235], [0.9846499562263489, 0.015350069850683212], [0.006127515807747841, 0.9938725233078003], [0.0070389327593147755, 0.9929611086845398], [0.006033519748598337, 0.9939664602279663], [0.9675402641296387, 0.03245975449681282], [0.9865352511405945, 0.013464716263115406], [0.02083897590637207, 0.9791610836982727], [0.005854269023984671, 0.9941457509994507], [0.0059765721671283245, 0.9940233826637268]]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["ids, hards, softs = test_loop(inf_model, valid_dataloader)\n","hards = hards.tolist()\n","softs = softs.tolist()\n","print(ids)\n","print(hards)\n","print(softs)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["hard_path = inf_model_name + '_val_hard'\n","soft_path = inf_model_name + '_val_soft'"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["hard_dicts = []\n","for identity, hard in zip(ids, hards):\n","    hard_dicts.append({\n","        'test_case': 'EXIST2024',\n","        'id': str(identity),\n","        'value': 'YES' if hard == 1 else 'NO'\n","    })\n","with open(f'{hard_path}.json', 'w') as fp:\n","    json.dump(hard_dicts, fp)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["soft_dicts = []\n","for identity, soft in zip(ids, softs):\n","    soft_dicts.append({\n","        'test_case': 'EXIST2024',\n","        'id': str(identity),\n","        'value': {\n","            'YES': soft[1],\n","            'NO': soft[0]\n","        }\n","    })\n","with open(f'{soft_path}.json', 'w') as fp:\n","    json.dump(soft_dicts, fp)"]},{"cell_type":"markdown","metadata":{},"source":["# PyEvALL Test"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["class NpEncoder(json.JSONEncoder):\n","    def default(self, obj):\n","        if isinstance(obj, np.integer):\n","            return int(obj)\n","        if isinstance(obj, np.floating):\n","            return float(obj)\n","        if isinstance(obj, np.ndarray):\n","            return obj.tolist()\n","        return super(NpEncoder, self).default(obj)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-05-31 19:36:51,539 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure', 'Accuracy']\n","2024-05-31 19:36:51,610 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n","2024-05-31 19:36:51,796 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n","2024-05-31 19:36:51,797 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n","2024-05-31 19:36:51,984 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n","2024-05-31 19:36:52,163 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n","2024-05-31 19:36:52,341 - pyevall.metrics.metrics - INFO -             evaluate() - Executing accuracy evaluation method\n","cargado 24\n","This is a table PyEvALL report, so no warnings or errors are shown. Please, check the embedded report to check errors if any metric has the value \"-\" or is an empty value or table.\n","+----+---------------------------------------------------------+-----------+------------+----------+----------+\n","|    | files                                                   |       ICM |   ICM-Norm |       F1 |      Acc |\n","|----+---------------------------------------------------------+-----------+------------+----------+----------|\n","|  0 | openai-clip-vit-base-patch32_score_0.8837_val_hard.json | -0.219626 |   0.385741 | 0.559198 | 0.621277 |\n","+----+---------------------------------------------------------+-----------+------------+----------+----------+\n","+----+-------------------------------------------------------------------+-----------+------------+----------+----------+\n","|    | files                                                             |       ICM |   ICM-Norm |       F1 |      Acc |\n","|----+-------------------------------------------------------------------+-----------+------------+----------+----------|\n","|  0 | openai-clip-vit-base-patch32_score_0.8837_val_hard.json_EXIST2024 | -0.219626 |   0.385741 | 0.559198 | 0.621277 |\n","+----+-------------------------------------------------------------------+-----------+------------+----------+----------+\n","+----+-------------------------------------------------------------------+----------+----------+\n","|    | files                                                             |   F1_YES |    F1_NO |\n","|----+-------------------------------------------------------------------+----------+----------|\n","|  0 | openai-clip-vit-base-patch32_score_0.8837_val_hard.json_EXIST2024 | 0.641711 | 0.476684 |\n","+----+-------------------------------------------------------------------+----------+----------+\n"]}],"source":["from pyevall.evaluation import PyEvALLEvaluation\n","from pyevall.utils.utils import PyEvALLUtils\n","from pyevall.metrics.metricfactory import MetricFactory\n","\n","gold_hard = 'EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task4_gold_hard.json'\n","gold_soft = 'EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task4_gold_soft.json'\n","\n","gold_val_hard = 'task4_val_hard_gold.json'\n","gold_val_soft = 'task4_val_soft_gold.json'\n","\n","gold_hard_df = pd.read_json(gold_hard)\n","gold_hard_df = gold_hard_df[gold_hard_df['id'].isin(X_val['id_EXIST'])]\n","gold_hard_df['id'] = gold_hard_df['id'].astype(str)\n","gold_hard_df.to_json(gold_val_hard, index=False, orient='records')\n","\n","gold_soft_df = pd.read_json(gold_soft)\n","gold_soft_df = gold_soft_df[gold_soft_df['id'].isin(X_val['id_EXIST'])]\n","gold_soft_df['id'] = gold_soft_df['id'].astype(str)\n","gold_soft_df.to_json(gold_val_soft, index=False, orient='records')\n","\n","predictions_hard = f'{hard_path}.json'\n","predictions_soft = f'{soft_path}.json'\n","\n","test = PyEvALLEvaluation()\n","metrics_hard=[MetricFactory.ICM.value, MetricFactory.ICMNorm.value, MetricFactory.FMeasure.value, MetricFactory.Accuracy.value]\n","metrics_soft=[MetricFactory.ICMSoft.value, MetricFactory.ICMSoftNorm.value, MetricFactory.CrossEntropy.value]\n","\n","params = {\n","    PyEvALLUtils.PARAM_FORMAT: PyEvALLUtils.PARAM_OPTION_FORMAT_JSON,\n","    PyEvALLUtils.PARAM_REPORT: PyEvALLUtils.PARAM_OPTION_REPORT_DATAFRAME\n","}\n","\n","report_hard = test.evaluate(predictions_hard, gold_val_hard, metrics_hard, **params)\n","with open(f'{hard_path}_results.json', 'w') as fp:\n","    json.dump(report_hard.report, fp, indent=4)\n","report_hard.print_report()\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-05-31 19:36:52,353 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICMSoft', 'ICMSoftNorm', 'CrossEntropy']\n","2024-05-31 19:36:52,521 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Soft evaluation method\n","2024-05-31 19:36:53,088 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM-Soft Normalized evaluation method\n","2024-05-31 19:36:53,089 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Soft evaluation method\n","2024-05-31 19:36:53,737 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Soft evaluation method\n","2024-05-31 19:36:54,276 - pyevall.metrics.metrics - INFO -             evaluate() - Executing Cross Entropy evaluation method\n","This is a table PyEvALL report, so no warnings or errors are shown. Please, check the embedded report to check errors if any metric has the value \"-\" or is an empty value or table.\n","+----+---------------------------------------------------------+------------+-----------------+---------+\n","|    | files                                                   |   ICM-Soft |   ICM-Soft-Norm |      CE |\n","|----+---------------------------------------------------------+------------+-----------------+---------|\n","|  0 | openai-clip-vit-base-patch32_score_0.8837_val_soft.json |   -1.95886 |         0.19035 | 2.55348 |\n","+----+---------------------------------------------------------+------------+-----------------+---------+\n","+----+-------------------------------------------------------------------+------------+-----------------+---------+\n","|    | files                                                             |   ICM-Soft |   ICM-Soft-Norm |      CE |\n","|----+-------------------------------------------------------------------+------------+-----------------+---------|\n","|  0 | openai-clip-vit-base-patch32_score_0.8837_val_soft.json_EXIST2024 |   -1.95886 |         0.19035 | 2.55348 |\n","+----+-------------------------------------------------------------------+------------+-----------------+---------+\n"]}],"source":["report_soft = test.evaluate(predictions_soft, gold_val_soft, metrics_soft, **params)\n","with open(f'{soft_path}_results.json', 'w') as fp:\n","    json.dump(report_soft.report, fp, indent=4)\n","report_soft.print_report()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4894786,"sourceId":8249731,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
