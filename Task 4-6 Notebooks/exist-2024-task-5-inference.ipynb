{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Preamble: Install and Import Packages"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:15:16.598715Z","iopub.status.busy":"2024-05-06T18:15:16.597882Z","iopub.status.idle":"2024-05-06T18:15:25.498522Z","shell.execute_reply":"2024-05-06T18:15:25.497700Z","shell.execute_reply.started":"2024-05-06T18:15:16.598676Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\pachinkomachine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import Resize\n","from torchvision.io import read_image, ImageReadMode\n","from multilingual_clip import Config_MCLIP\n","import open_clip\n","import json\n","import pandas as pd\n","import random\n","from pathlib import Path\n","import numpy as np\n","import transformers as hf\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from PIL import Image\n","import os\n","import time\n","import math"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:15:44.872551Z","iopub.status.busy":"2024-05-06T18:15:44.871975Z","iopub.status.idle":"2024-05-06T18:15:44.877783Z","shell.execute_reply":"2024-05-06T18:15:44.876660Z","shell.execute_reply.started":"2024-05-06T18:15:44.872513Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4.40.1\n"]},{"data":{"text/plain":["<torch.autograd.anomaly_mode.set_detect_anomaly at 0x2807fcbd9d0>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["print(hf.__version__)\n","torch.autograd.set_detect_anomaly(True)"]},{"cell_type":"markdown","metadata":{},"source":["# Initialise the Configuration and Random Seeds"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:38.260806Z","iopub.status.busy":"2024-05-06T18:18:38.259845Z","iopub.status.idle":"2024-05-06T18:18:38.990037Z","shell.execute_reply":"2024-05-06T18:18:38.989149Z","shell.execute_reply.started":"2024-05-06T18:18:38.260764Z"},"trusted":true},"outputs":[],"source":["_text_model_config = {}\n","\n","_image_model_config = {\n","    \"attention_probs_dropout_prob\": 0.0,\n","    \"encoder_stride\": 16,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.0,\n","    \"hidden_size\": 768,\n","    \"image_size\": 224,\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"layer_norm_eps\": 1e-12,\n","    \"num_attention_heads\": 12,\n","    \"num_channels\": 3,\n","    \"num_hidden_layers\": 0,\n","    \"patch_size\": 16,\n","    \"qkv_bias\": True,\n","}\n","\n","# Dual encoder/Concat\n","tokeniser_model_id = 'xlm-roberta-base'\n","text_model_id = 'xlm-roberta-base'\n","image_model_id = 'google/vit-base-patch16-224-in21k'\n","\n","# CLIP\n","multimodal_model_id = 'openai/clip-vit-base-patch32'\n","\n","# M-CLIP\n","# tokeniser_model_id = 'M-CLIP/XLM-Roberta-Large-Vit-B-16Plus'\n","# text_model_id = 'M-CLIP/XLM-Roberta-Large-Vit-B-16Plus'\n","# image_model_id = 'ViT-B-16-plus-240'\n","image_training_id = 'laion400m_e32'\n","\n","# ViLT\n","# multimodal_model_id = 'dandelin/vilt-b32-mlm'\n","\n","\n","class CFG:\n","    use_multimodal = True\n","    use_dualencoder = False\n","    split_lang = False\n","    save_models = False\n","    use_lstm = False\n","    use_attn = False\n","    use_mask_split = False\n","    use_modal_attn = True\n","    is_mclip = False\n","    init_weights = False\n","    tokeniser_model_id = tokeniser_model_id\n","    text_model_id = text_model_id\n","    image_model_id = image_model_id\n","    multimodal_model_id = multimodal_model_id\n","    image_training_id = image_training_id\n","    text_model_config = hf.AutoConfig.from_pretrained(text_model_id) if not 'M-CLIP' in text_model_id else None\n","    image_model_config = hf.AutoConfig.from_pretrained(image_model_id) if not 'M-CLIP' in text_model_id else None\n","    multimodal_model_config = hf.AutoConfig.from_pretrained(multimodal_model_id, text_config=_text_model_config, vision_config=_image_model_config)\n","    images_base_path = Path(f'EXIST 2024 Lab/EXIST 2024 Memes Dataset/training/memes')\n","    images_base_path_test = Path('EXIST 2024 Lab/EXIST 2024 Memes Dataset/test/memes')\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    debug = True\n","    print_freq = 300\n","    apex = True # for faster training\n","    epochs = 10\n","    learning_rate = 2e-4  # for adam optimizer\n","    eps = 1e-6\n","    betas = (0.9, 0.999)  # for adam optimizer\n","    batch_size = 32\n","    max_len = 512\n","    weight_decay = 0.01  # for adam optimizer regulaization parameter\n","    gradient_accumulation_steps = 1\n","    max_grad_norm = 1000\n","    seed = 42\n","    train = True\n","    num_class = 3\n","    mlp_hidden_size = 256\n","    mlp_hidden_layers = 0\n","    mlp_dropout = 0.1\n","    mlp_grad_clip = 1.0\n","    mlp_init_range = 0.2\n","    mlp_attn_dim = 256"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:16:08.601112Z","iopub.status.busy":"2024-05-06T18:16:08.600732Z","iopub.status.idle":"2024-05-06T18:16:08.610179Z","shell.execute_reply":"2024-05-06T18:16:08.609275Z","shell.execute_reply.started":"2024-05-06T18:16:08.601082Z"},"trusted":true},"outputs":[],"source":["def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(CFG.seed)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:16:13.511690Z","iopub.status.busy":"2024-05-06T18:16:13.511328Z","iopub.status.idle":"2024-05-06T18:16:13.542982Z","shell.execute_reply":"2024-05-06T18:16:13.542212Z","shell.execute_reply.started":"2024-05-06T18:16:13.511661Z"},"trusted":true},"outputs":[],"source":["class MultilingualCLIP(hf.PreTrainedModel):\n","    config_class = Config_MCLIP.MCLIPConfig\n","\n","    def __init__(self, config, *args, **kwargs):\n","        super().__init__(config, *args, **kwargs)\n","        self.transformer = hf.AutoModel.from_pretrained(config.modelBase, cache_dir=kwargs.get(\"cache_dir\"))\n","        self.LinearTransformation = torch.nn.Linear(in_features=config.transformerDimensions,\n","                                                    out_features=config.numDims)\n","\n","    def forward(self, tokens, mask):\n","        embs = self.transformer(tokens, attention_mask=mask)[0]\n","        embs = (embs * mask.unsqueeze(2)).sum(dim=1) / mask.sum(dim=1)[:, None]\n","        return self.LinearTransformation(embs)\n","\n","    @classmethod\n","    def _load_state_dict_into_model(cls, model, state_dict, pretrained_model_name_or_path, _fast_init=True):\n","        model.load_state_dict(state_dict)\n","        return model, [], [], []"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocess the Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:08.228459Z","iopub.status.busy":"2024-05-06T18:18:08.227674Z","iopub.status.idle":"2024-05-06T18:18:08.559596Z","shell.execute_reply":"2024-05-06T18:18:08.558616Z","shell.execute_reply.started":"2024-05-06T18:18:08.228415Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(4044, 16)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>lang</th>\n","      <th>text</th>\n","      <th>meme</th>\n","      <th>path_memes</th>\n","      <th>number_annotators</th>\n","      <th>annotators</th>\n","      <th>gender_annotators</th>\n","      <th>age_annotators</th>\n","      <th>ethnicities_annotators</th>\n","      <th>study_levels_annotators</th>\n","      <th>countries_annotators</th>\n","      <th>labels_task4</th>\n","      <th>labels_task5</th>\n","      <th>labels_task6</th>\n","      <th>split</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>110001</th>\n","      <td>110001</td>\n","      <td>es</td>\n","      <td>2+2=5 MITO Albert Einstein tenía bajo rendimie...</td>\n","      <td>110001.jpeg</td>\n","      <td>memes/110001.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[YES, YES, YES, YES, YES, YES]</td>\n","      <td>[DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, DIRECT]</td>\n","      <td>[[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>110002</th>\n","      <td>110002</td>\n","      <td>es</td>\n","      <td>CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS</td>\n","      <td>110002.jpeg</td>\n","      <td>memes/110002.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[YES, YES, YES, YES, YES, YES]</td>\n","      <td>[DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, JUDGE...</td>\n","      <td>[[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>110003</th>\n","      <td>110003</td>\n","      <td>es</td>\n","      <td>ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...</td>\n","      <td>110003.jpeg</td>\n","      <td>memes/110003.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[YES, YES, NO, NO, NO, NO]</td>\n","      <td>[DIRECT, DIRECT, -, -, -, -]</td>\n","      <td>[[STEREOTYPING-DOMINANCE, OBJECTIFICATION, MIS...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>110004</th>\n","      <td>110004</td>\n","      <td>es</td>\n","      <td>Paises que \"apoyan\" los derechos de la mujer A...</td>\n","      <td>110004.jpeg</td>\n","      <td>memes/110004.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[YES, YES, NO, NO, YES, NO]</td>\n","      <td>[JUDGEMENTAL, JUDGEMENTAL, -, -, JUDGEMENTAL, -]</td>\n","      <td>[[IDEOLOGICAL-INEQUALITY], [IDEOLOGICAL-INEQUA...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","    <tr>\n","      <th>110005</th>\n","      <td>110005</td>\n","      <td>es</td>\n","      <td>Ya verás como este 8 de marzo hay uno que te s...</td>\n","      <td>110005.jpeg</td>\n","      <td>memes/110005.jpeg</td>\n","      <td>6</td>\n","      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n","      <td>[F, F, F, M, M, M]</td>\n","      <td>[18-22, 23-45, 46+, 46+, 18-22, 23-45]</td>\n","      <td>[Hispano or Latino, Hispano or Latino, Hispano...</td>\n","      <td>[High school degree or equivalent, Master’s de...</td>\n","      <td>[Mexico, Spain, Argentina, Spain, Mexico, Mexico]</td>\n","      <td>[NO, YES, NO, NO, YES, NO]</td>\n","      <td>[-, JUDGEMENTAL, -, -, DIRECT, -]</td>\n","      <td>[[-], [IDEOLOGICAL-INEQUALITY], [-], [-], [IDE...</td>\n","      <td>TRAIN-MEME_ES</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id_EXIST lang                                               text  \\\n","110001   110001   es  2+2=5 MITO Albert Einstein tenía bajo rendimie...   \n","110002   110002   es     CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS    \n","110003   110003   es  ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...   \n","110004   110004   es  Paises que \"apoyan\" los derechos de la mujer A...   \n","110005   110005   es  Ya verás como este 8 de marzo hay uno que te s...   \n","\n","               meme         path_memes number_annotators  \\\n","110001  110001.jpeg  memes/110001.jpeg                 6   \n","110002  110002.jpeg  memes/110002.jpeg                 6   \n","110003  110003.jpeg  memes/110003.jpeg                 6   \n","110004  110004.jpeg  memes/110004.jpeg                 6   \n","110005  110005.jpeg  memes/110005.jpeg                 6   \n","\n","                                               annotators   gender_annotators  \\\n","110001  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","110002  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","110003  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","110004  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","110005  [Annotator_1, Annotator_2, Annotator_3, Annota...  [F, F, F, M, M, M]   \n","\n","                                age_annotators  \\\n","110001  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","110002  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","110003  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","110004  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","110005  [18-22, 23-45, 46+, 46+, 18-22, 23-45]   \n","\n","                                   ethnicities_annotators  \\\n","110001  [Hispano or Latino, Hispano or Latino, Hispano...   \n","110002  [Hispano or Latino, Hispano or Latino, Hispano...   \n","110003  [Hispano or Latino, Hispano or Latino, Hispano...   \n","110004  [Hispano or Latino, Hispano or Latino, Hispano...   \n","110005  [Hispano or Latino, Hispano or Latino, Hispano...   \n","\n","                                  study_levels_annotators  \\\n","110001  [High school degree or equivalent, Master’s de...   \n","110002  [High school degree or equivalent, Master’s de...   \n","110003  [High school degree or equivalent, Master’s de...   \n","110004  [High school degree or equivalent, Master’s de...   \n","110005  [High school degree or equivalent, Master’s de...   \n","\n","                                     countries_annotators  \\\n","110001  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","110002  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","110003  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","110004  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","110005  [Mexico, Spain, Argentina, Spain, Mexico, Mexico]   \n","\n","                          labels_task4  \\\n","110001  [YES, YES, YES, YES, YES, YES]   \n","110002  [YES, YES, YES, YES, YES, YES]   \n","110003      [YES, YES, NO, NO, NO, NO]   \n","110004     [YES, YES, NO, NO, YES, NO]   \n","110005      [NO, YES, NO, NO, YES, NO]   \n","\n","                                             labels_task5  \\\n","110001   [DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, DIRECT]   \n","110002  [DIRECT, DIRECT, DIRECT, DIRECT, DIRECT, JUDGE...   \n","110003                       [DIRECT, DIRECT, -, -, -, -]   \n","110004   [JUDGEMENTAL, JUDGEMENTAL, -, -, JUDGEMENTAL, -]   \n","110005                  [-, JUDGEMENTAL, -, -, DIRECT, -]   \n","\n","                                             labels_task6          split  \n","110001  [[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...  TRAIN-MEME_ES  \n","110002  [[IDEOLOGICAL-INEQUALITY, STEREOTYPING-DOMINAN...  TRAIN-MEME_ES  \n","110003  [[STEREOTYPING-DOMINANCE, OBJECTIFICATION, MIS...  TRAIN-MEME_ES  \n","110004  [[IDEOLOGICAL-INEQUALITY], [IDEOLOGICAL-INEQUA...  TRAIN-MEME_ES  \n","110005  [[-], [IDEOLOGICAL-INEQUALITY], [-], [-], [IDE...  TRAIN-MEME_ES  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["with open('EXIST 2024 Lab/EXIST 2024 Memes Dataset/training/EXIST2024_training.json', 'r', encoding='utf-8') as fp:\n","    annotations = json.load(fp)\n","df = pd.DataFrame.from_dict(annotations).T\n","print(df.shape)\n","df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:08.962373Z","iopub.status.busy":"2024-05-06T18:18:08.962006Z","iopub.status.idle":"2024-05-06T18:18:08.981050Z","shell.execute_reply":"2024-05-06T18:18:08.980036Z","shell.execute_reply.started":"2024-05-06T18:18:08.962344Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>meme</th>\n","      <th>text</th>\n","      <th>lang</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>110001</td>\n","      <td>110001.jpeg</td>\n","      <td>2+2=5 MITO Albert Einstein tenía bajo rendimie...</td>\n","      <td>es</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>110002</td>\n","      <td>110002.jpeg</td>\n","      <td>CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS</td>\n","      <td>es</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>110003</td>\n","      <td>110003.jpeg</td>\n","      <td>ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...</td>\n","      <td>es</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>110004</td>\n","      <td>110004.jpeg</td>\n","      <td>Paises que \"apoyan\" los derechos de la mujer A...</td>\n","      <td>es</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>110005</td>\n","      <td>110005.jpeg</td>\n","      <td>Ya verás como este 8 de marzo hay uno que te s...</td>\n","      <td>es</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id_EXIST         meme                                               text  \\\n","0    110001  110001.jpeg  2+2=5 MITO Albert Einstein tenía bajo rendimie...   \n","1    110002  110002.jpeg     CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS    \n","2    110003  110003.jpeg  ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...   \n","3    110004  110004.jpeg  Paises que \"apoyan\" los derechos de la mujer A...   \n","4    110005  110005.jpeg  Ya verás como este 8 de marzo hay uno que te s...   \n","\n","  lang  \n","0   es  \n","1   es  \n","2   es  \n","3   es  \n","4   es  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["mini_df = df[['id_EXIST', 'meme', 'text', 'lang']].reset_index(drop=True)\n","mini_df['id_EXIST'] = pd.to_numeric(mini_df['id_EXIST'])\n","mini_df.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:09.679379Z","iopub.status.busy":"2024-05-06T18:18:09.678690Z","iopub.status.idle":"2024-05-06T18:18:09.740465Z","shell.execute_reply":"2024-05-06T18:18:09.739514Z","shell.execute_reply.started":"2024-05-06T18:18:09.679345Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4044\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>meme</th>\n","      <th>text</th>\n","      <th>lang</th>\n","      <th>label_task5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>110001</td>\n","      <td>110001.jpeg</td>\n","      <td>2+2=5 MITO Albert Einstein tenía bajo rendimie...</td>\n","      <td>es</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>110002</td>\n","      <td>110002.jpeg</td>\n","      <td>CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS</td>\n","      <td>es</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>110003</td>\n","      <td>110003.jpeg</td>\n","      <td>ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...</td>\n","      <td>es</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>110004</td>\n","      <td>110004.jpeg</td>\n","      <td>Paises que \"apoyan\" los derechos de la mujer A...</td>\n","      <td>es</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>110005</td>\n","      <td>110005.jpeg</td>\n","      <td>Ya verás como este 8 de marzo hay uno que te s...</td>\n","      <td>es</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id_EXIST         meme                                               text  \\\n","0    110001  110001.jpeg  2+2=5 MITO Albert Einstein tenía bajo rendimie...   \n","1    110002  110002.jpeg     CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS    \n","2    110003  110003.jpeg  ІЯ ЕГЕЯ Е MOA ¿El Partido Republicano busca pe...   \n","3    110004  110004.jpeg  Paises que \"apoyan\" los derechos de la mujer A...   \n","4    110005  110005.jpeg  Ya verás como este 8 de marzo hay uno que te s...   \n","\n","  lang  label_task5  \n","0   es            1  \n","1   es            1  \n","2   es            0  \n","3   es            0  \n","4   es            0  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["task4_gold_path = Path('EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task4_gold_hard.json')\n","task5_gold_path = Path('EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task5_gold_hard.json')\n","task6_gold_path = Path('EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task6_gold_hard.json')\n","task5_gold = pd.read_json(task5_gold_path)\n","\n","choices = ['DIRECT', 'JUDGEMENTAL', 'NO']\n","mini_df = pd.merge(mini_df, task5_gold, left_on='id_EXIST', right_on='id', how='left').drop(columns=['id', 'test_case']).rename(columns={'value': 'label_task5'})\n","mini_df['label_task5'] = mini_df['label_task5'].apply(lambda x: np.random.choice(choices) if pd.isna(x) else x)\n","mini_df['label_task5'] = pd.to_numeric(mini_df['label_task5'].map({'DIRECT': 1, 'JUDGEMENTAL': 2, 'NO': 0}))\n","print(len(mini_df))\n","mini_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Initialise the Processors/Tokenisers/Models"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:18:44.737506Z","iopub.status.busy":"2024-05-06T18:18:44.737103Z","iopub.status.idle":"2024-05-06T18:19:08.560431Z","shell.execute_reply":"2024-05-06T18:19:08.559371Z","shell.execute_reply.started":"2024-05-06T18:18:44.737475Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\pachinkomachine\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]}],"source":["if CFG.is_mclip:\n","    tokenizer = hf.AutoTokenizer.from_pretrained(CFG.tokeniser_model_id)\n","    text_model = MultilingualCLIP.from_pretrained(CFG.text_model_id).to(CFG.device)\n","    image_model, _, image_processor = open_clip.create_model_and_transforms(CFG.image_model_id, pretrained=CFG.image_training_id)\n","    image_model = image_model.to(CFG.device)\n","elif CFG.use_multimodal:\n","    mm_processor = hf.AutoProcessor.from_pretrained(CFG.multimodal_model_id)\n","    mm_model = hf.AutoModel.from_pretrained(CFG.multimodal_model_id).to(CFG.device)\n","elif CFG.use_dualencoder:\n","    tokenizer = hf.AutoTokenizer.from_pretrained(CFG.tokeniser_model_id, padding=True, truncation=True)\n","    processor = hf.AutoImageProcessor.from_pretrained(CFG.image_model_id)\n","    de_processor = hf.VisionTextDualEncoderProcessor(image_processor=processor, tokenizer=tokenizer)\n","    text_model = hf.AutoModel.from_pretrained(CFG.text_model_id).to(CFG.device)\n","    image_model = hf.AutoModel.from_pretrained(CFG.image_model_id).to(CFG.device)\n","    de_model = hf.VisionTextDualEncoderModel(vision_model=image_model, text_model=text_model)\n","else:\n","    tokenizer = hf.AutoTokenizer.from_pretrained(CFG.tokeniser_model_id)\n","    text_model = hf.AutoModel.from_pretrained(CFG.text_model_id).to(CFG.device)\n","    # Adding a config to the image_model gets rid of lots of pretrained weights\n","    image_model = hf.AutoModel.from_pretrained(CFG.image_model_id).to(CFG.device)"]},{"cell_type":"markdown","metadata":{},"source":["# Train/Val Split"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:12.849175Z","iopub.status.busy":"2024-05-06T18:19:12.848090Z","iopub.status.idle":"2024-05-06T18:19:12.871009Z","shell.execute_reply":"2024-05-06T18:19:12.870233Z","shell.execute_reply.started":"2024-05-06T18:19:12.849140Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id_EXIST</th>\n","      <th>meme</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>110002</td>\n","      <td>110002.jpeg</td>\n","      <td>CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>110005</td>\n","      <td>110005.jpeg</td>\n","      <td>Ya verás como este 8 de marzo hay uno que te s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>110012</td>\n","      <td>110012.jpeg</td>\n","      <td>A LOS QUE NO ME SALUDAN POR EL DIA DE LA MUJER...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>110017</td>\n","      <td>110017.jpeg</td>\n","      <td>SE ACERCA EL DIA DE LA MUJER, SE ACEPTAN POSTR...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>110020</td>\n","      <td>110020.jpeg</td>\n","      <td>Día de la Mujer Expectativa Realidad</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id_EXIST         meme                                               text\n","0    110002  110002.jpeg     CUANDO UNA MUJER VA A LUCHAR POR SUS DERECHOS \n","1    110005  110005.jpeg  Ya verás como este 8 de marzo hay uno que te s...\n","2    110012  110012.jpeg  A LOS QUE NO ME SALUDAN POR EL DIA DE LA MUJER...\n","3    110017  110017.jpeg  SE ACERCA EL DIA DE LA MUJER, SE ACEPTAN POSTR...\n","4    110020  110020.jpeg              Día de la Mujer Expectativa Realidad "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["def dataframe_train_test_split(df, target_label, seed=CFG.seed, test_size=0.2, split_labels=True):\n","    train = df.sample(frac=(1.0 - test_size), random_state=seed)\n","    test = df.drop(train.index).reset_index(drop=True)\n","\n","    train.reset_index(drop=True, inplace=True)\n","\n","    if split_labels:\n","        return train.drop(columns=target_label), test.drop(columns=target_label), train[target_label], test[target_label]\n","    else:\n","        return train, test\n","\n","X_train, X_val, y_train, y_val = dataframe_train_test_split(mini_df[['id_EXIST', 'meme', 'text', 'label_task5']], 'label_task5', test_size=0.2, seed=CFG.seed)\n","X_val.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Custom Dataset Definition"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:14.449356Z","iopub.status.busy":"2024-05-06T18:19:14.448759Z","iopub.status.idle":"2024-05-06T18:19:14.463944Z","shell.execute_reply":"2024-05-06T18:19:14.462848Z","shell.execute_reply.started":"2024-05-06T18:19:14.449326Z"},"trusted":true},"outputs":[],"source":["class ExistDataset(Dataset):\n","    def __init__(self, features, img_dir, labels=None, test=False, img_transform=None, caption_transform=None, target_transform=None):\n","        self.features = features\n","        self.labels = labels\n","        self.img_dir = img_dir\n","        self.test = test\n","        self.img_transform = img_transform\n","        self.caption_transform = caption_transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, idx):\n","        img_path = str(self.img_dir.joinpath(self.features['meme'].iloc[idx]))\n","        if CFG.is_mclip:\n","            image = Image.open(img_path)\n","        else:\n","            image = read_image(img_path, mode=ImageReadMode.RGB).to(device=CFG.device)\n","        caption = self.features['text'].iloc[idx]\n","        \n","        if not self.test:\n","            label = self.labels.iloc[idx]\n","        else:\n","            identity = self.features['id_EXIST'].iloc[idx]\n","        \n","        if self.img_transform:\n","            image = self.img_transform(image)\n","        if self.caption_transform:\n","            caption = self.caption_transform(caption)\n","        if not self.test and self.target_transform:\n","            label = self.target_transform(label)\n","            \n","        if CFG.split_lang:\n","            caption = f'Language: {self.features[\"lang\"].iloc[idx]} - {caption}'\n","            \n","        if CFG.is_mclip:\n","            processed = tokenizer(caption, padding=True, return_tensors='pt')\n","            seq = processed['input_ids']\n","            mask = processed['attention_mask']\n","            image = image_processor(image)\n","        elif CFG.use_multimodal:\n","            processed = mm_processor(text=caption, images=image, return_tensors=\"pt\", padding=True, truncation=True)\n","            seq = processed['input_ids']\n","            mask = processed['attention_mask']\n","            image = processed['pixel_values']\n","        elif CFG.use_dualencoder:\n","            processed = de_processor(text=caption, images=image, return_tensors=\"pt\")\n","            seq = processed['input_ids']\n","            mask = processed['attention_mask']\n","            image = processed['pixel_values']\n","        else:\n","            processed = tokenizer.encode_plus(\n","                caption,\n","                padding='longest',\n","                truncation=True,\n","                return_tensors='pt'\n","            )\n","            seq = processed['input_ids']\n","            mask = processed['attention_mask']\n","        \n","        if not self.test:\n","            label = torch.tensor([label]).long()\n","            return image, seq, mask, label\n","        \n","        return identity, image, seq, mask"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:14.912249Z","iopub.status.busy":"2024-05-06T18:19:14.911773Z","iopub.status.idle":"2024-05-06T18:19:14.920983Z","shell.execute_reply":"2024-05-06T18:19:14.919959Z","shell.execute_reply.started":"2024-05-06T18:19:14.912215Z"},"trusted":true},"outputs":[],"source":["class Collator(object):\n","    def __init__(self, test=False):\n","        self.test = test\n","    def __call__(self, batch):\n","        if not self.test:\n","            images, seqs, masks, labels = zip(*batch)\n","            labels = torch.stack(labels)\n","        else:\n","            ids, images, seqs, masks = zip(*batch)\n","\n","        seqs = [seq.squeeze(dim=0) for seq in seqs]\n","        masks = [mask.squeeze(dim=0) for mask in masks]\n","        images = [image.squeeze(dim=0) for image in images]\n","\n","        seqs = nn.utils.rnn.pad_sequence(seqs, batch_first=True)\n","        masks = nn.utils.rnn.pad_sequence(masks, batch_first=True)\n","\n","        images = torch.stack(images)\n","        \n","        if not self.test:\n","            return images, seqs, masks, labels\n","        \n","        return ids, images, seqs, masks"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:15.535724Z","iopub.status.busy":"2024-05-06T18:19:15.535132Z","iopub.status.idle":"2024-05-06T18:19:15.540414Z","shell.execute_reply":"2024-05-06T18:19:15.539547Z","shell.execute_reply.started":"2024-05-06T18:19:15.535690Z"},"trusted":true},"outputs":[],"source":["resizer = Resize((224, 224), antialias=True)\n","\n","def resize_images(img_tensor):\n","    return resizer(img_tensor)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Initialisation"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:21.839823Z","iopub.status.busy":"2024-05-06T18:19:21.839454Z","iopub.status.idle":"2024-05-06T18:19:21.846397Z","shell.execute_reply":"2024-05-06T18:19:21.845390Z","shell.execute_reply.started":"2024-05-06T18:19:21.839793Z"},"trusted":true},"outputs":[{"data":{"text/plain":["809"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["val_dataset = ExistDataset(X_val, CFG.images_base_path, labels=y_val, img_transform=resize_images, test=True)\n","len(val_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["# Model Architecture"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:25.859218Z","iopub.status.busy":"2024-05-06T18:19:25.858470Z","iopub.status.idle":"2024-05-06T18:19:25.882149Z","shell.execute_reply":"2024-05-06T18:19:25.881167Z","shell.execute_reply.started":"2024-05-06T18:19:25.859188Z"},"trusted":true},"outputs":[],"source":["class ConcatArch(nn.Module):\n","    def __init__(self, hidden_size, hidden_layers, dropout, num_classes, use_multimodal=False, use_dualencoder=False, is_mclip=False):\n","        super().__init__()\n","        \n","        self.hidden_size = hidden_size\n","        self.hidden_layers = hidden_layers\n","        self.use_multimodal = use_multimodal\n","        self.use_dualencoder = use_dualencoder\n","        self.is_mclip = is_mclip\n","        self.is_vilt = 'ViltForMaskedLM' in CFG.multimodal_model_config.architectures\n","        \n","        if self.is_mclip:\n","            self.text_model = text_model\n","            self.image_model = image_model\n","        elif self.use_multimodal:\n","            self.mm_model = mm_model\n","        elif self.use_dualencoder:\n","            self.de_model = de_model\n","        else:\n","            self.text_model = text_model\n","            self.image_model = image_model\n","        \n","        if self.is_mclip:\n","            self.fc1 = nn.Linear(1280, self.hidden_size)\n","        elif self.use_multimodal:\n","            if self.is_vilt and CFG.use_lstm:\n","                out_channels = CFG.mlp_hidden_size + CFG.multimodal_model_config.hidden_size\n","                self.lstm = nn.LSTM(CFG.multimodal_model_config.hidden_size, CFG.mlp_hidden_size, batch_first=True)\n","            elif self.is_vilt and CFG.use_mask_split:\n","                out_channels = CFG.multimodal_model_config.hidden_size * 3\n","            elif self.is_vilt and CFG.use_attn:\n","                self.attn = nn.Sequential(\n","                    nn.Linear(CFG.multimodal_model_config.hidden_size, CFG.mlp_attn_dim),\n","                    nn.Tanh(),\n","                    nn.Linear(CFG.mlp_attn_dim, 1),\n","                    nn.Softmax(dim=1)\n","                )\n","            elif self.is_vilt and CFG.use_modal_attn:\n","                self.attn1 = nn.Sequential(\n","                    nn.Linear(CFG.multimodal_model_config.hidden_size, CFG.mlp_attn_dim),\n","                    nn.Tanh(),\n","                    nn.Linear(CFG.mlp_attn_dim, 1),\n","                    nn.Softmax(dim=1)\n","                )\n","                self.attn2 = nn.Sequential(\n","                    nn.Linear(CFG.multimodal_model_config.hidden_size, CFG.mlp_attn_dim),\n","                    nn.Tanh(),\n","                    nn.Linear(CFG.mlp_attn_dim, 1),\n","                    nn.Softmax(dim=1)\n","                )\n","                out_channels = CFG.multimodal_model_config.hidden_size * 2\n","            elif self.is_vilt:\n","                out_channels = CFG.multimodal_model_config.hidden_size\n","            else:\n","                out_channels = 2 * CFG.multimodal_model_config.projection_dim\n","            self.fc1 = nn.Linear(out_channels, self.hidden_size)\n","        elif self.use_dualencoder:\n","            self.fc1 = nn.Linear(2 * 512, self.hidden_size)\n","        else:\n","            self.fc1 = nn.Linear(CFG.text_model_config.hidden_size + CFG.image_model_config.hidden_size, self.hidden_size)\n","        self.hiddens = nn.ModuleList([nn.Linear(self.hidden_size, self.hidden_size) for _ in range(self.hidden_layers)])\n","        self.fc2 = nn.Linear(self.hidden_size, num_classes)\n","        self.activation = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","        \n","        if CFG.init_weights:\n","            self._init_weights(self.fc1)\n","            for hidden in self.hiddens:\n","                self._init_weights(hidden)\n","            self._init_weights(self.fc2)\n","\n","    def forward(self, tokens, mask, image):\n","        if self.is_mclip:\n","            emb_text = self.text_model.forward(tokens, mask)\n","            emb_img = self.image_model.encode_image(image)\n","            x = torch.cat([emb_text, emb_img], dim=1)\n","        elif self.use_multimodal:\n","            mm_output = self.mm_model(input_ids=tokens, attention_mask=mask, pixel_values=image, output_hidden_states=True)\n","            cats = [mm_output.pooler_output] if self.is_vilt else [mm_output.text_embeds, mm_output.image_embeds]\n","            \n","            if self.is_vilt and CFG.use_lstm:\n","                # First hidden state is apparently the embedding output\n","                # https://discuss.huggingface.co/t/hidden-states-embedding-tensors/3549/\n","                layerwise_cls = torch.stack([h[:, 0, :] for h in mm_output.hidden_states[1:]], dim=1)\n","                _, (h, _) = self.lstm(layerwise_cls)\n","                h = h.squeeze(dim=0)\n","                cats.append(h)\n","\n","            if self.is_vilt and CFG.use_mask_split:\n","                last_h = mm_output.last_hidden_state\n","                mask_len = mask.shape[1]\n","                mean_pooled_text = torch.mean(last_h[:, :mask_len, :], dim=1)\n","                mean_pooled_img = torch.mean(last_h[:, mask_len:, :], dim=1)\n","                cats += [mean_pooled_text, mean_pooled_img]\n","\n","            if self.is_vilt and CFG.use_attn:\n","                last_h = mm_output.last_hidden_state\n","                attentions = self.attn(last_h)\n","                x = torch.sum(attentions * last_h, dim=1)\n","\n","                cls = last_h[:, 0, :]\n","                x += cls\n","            elif self.is_vilt and CFG.use_modal_attn:\n","                last_h = mm_output.last_hidden_state\n","                mask_len = mask.shape[1]\n","                text_split = last_h[:, :mask_len, :]\n","                img_split = last_h[:, mask_len:, :]\n","                text_attentions = self.attn1(text_split)\n","                img_attentions = self.attn2(img_split)\n","                x1 = torch.sum(text_attentions * text_split, dim=1)\n","                x2 = torch.sum(img_attentions * img_split, dim=1)\n","\n","                x = torch.cat([x1, x2], dim=1)\n","\n","                cls = last_h[:, 0, :]\n","                cls = torch.cat([cls, cls], dim=1)\n","                x += cls\n","            else:\n","                x = torch.cat(cats, dim=1)\n","        elif self.use_dualencoder:\n","            de_output = self.de_model(input_ids=tokens, attention_mask=mask, pixel_values=image)\n","            x = torch.cat([de_output.text_embeds, de_output.image_embeds], dim=1)\n","        else:\n","            cls_text = self.text_model(tokens, attention_mask=mask).last_hidden_state[:, 0, :]\n","            cls_img = self.image_model(image).last_hidden_state[:, 0, :]\n","            x = torch.cat([cls_text, cls_img], dim=1)\n","\n","        x = self.fc1(x)\n","        x = self.activation(x)\n","        x = self.dropout(x)\n","        for hidden in self.hiddens:\n","            x = hidden(x)\n","            x = self.activation(x)\n","            x = self.dropout(x)\n","        x = self.fc2(x)\n","        \n","        output = x\n","        return output.float()\n","    \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=CFG.mlp_init_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=CFG.mlp_init_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)"]},{"cell_type":"markdown","metadata":{},"source":["# Utility Functions"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:31.296299Z","iopub.status.busy":"2024-05-06T18:19:31.295514Z","iopub.status.idle":"2024-05-06T18:19:31.304096Z","shell.execute_reply":"2024-05-06T18:19:31.302978Z","shell.execute_reply.started":"2024-05-06T18:19:31.296263Z"},"trusted":true},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:31.726713Z","iopub.status.busy":"2024-05-06T18:19:31.726335Z","iopub.status.idle":"2024-05-06T18:19:31.731481Z","shell.execute_reply":"2024-05-06T18:19:31.730490Z","shell.execute_reply.started":"2024-05-06T18:19:31.726682Z"},"trusted":true},"outputs":[],"source":["def get_score(y_trues, y_preds):\n","    macro_f1 = f1_score(y_trues, y_preds, average='macro')\n","    return macro_f1"]},{"cell_type":"markdown","metadata":{},"source":["# Train/Val/Test Loops"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T18:19:41.312411Z","iopub.status.busy":"2024-05-06T18:19:41.311584Z","iopub.status.idle":"2024-05-06T18:19:41.320936Z","shell.execute_reply":"2024-05-06T18:19:41.319856Z","shell.execute_reply.started":"2024-05-06T18:19:41.312379Z"},"trusted":true},"outputs":[],"source":["def test_loop(model, test_dataloader):\n","    all_soft = []\n","    all_hard = []\n","    all_ids = []\n","    \n","    model.eval()\n","    \n","    for identity, image, seq, mask in tqdm(test_dataloader):\n","        test_image = image.to(device=CFG.device)\n","        test_seq = seq.to(device=CFG.device)\n","        test_mask = mask.to(device=CFG.device)\n","\n","        with torch.no_grad():\n","            output = model(test_seq, test_mask, test_image)\n","        \n","        soft = nn.functional.softmax(output, dim=1)\n","        hard = output.argmax(dim=1)\n","        \n","        all_ids += list(identity)\n","        all_soft.append(soft)\n","        all_hard.append(hard)\n","        \n","    all_soft = torch.cat(all_soft, dim=0)\n","    all_hard = torch.cat(all_hard, dim=0)\n","    \n","    return all_ids, all_hard, all_soft"]},{"cell_type":"markdown","metadata":{},"source":["# Inference From Checkpoint"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["ConcatArch(\n","  (mm_model): CLIPModel(\n","    (text_model): CLIPTextTransformer(\n","      (embeddings): CLIPTextEmbeddings(\n","        (token_embedding): Embedding(49408, 512)\n","        (position_embedding): Embedding(77, 512)\n","      )\n","      (encoder): CLIPEncoder(\n","        (layers): ModuleList(\n","          (0-11): 12 x CLIPEncoderLayer(\n","            (self_attn): CLIPAttention(\n","              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","            )\n","            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","            (mlp): CLIPMLP(\n","              (activation_fn): QuickGELUActivation()\n","              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","            )\n","            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","      )\n","      (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (vision_model): CLIPVisionTransformer(\n","      (embeddings): CLIPVisionEmbeddings(\n","        (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n","        (position_embedding): Embedding(50, 768)\n","      )\n","      (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (encoder): CLIPEncoder(\n","        (layers): ModuleList(\n","          (0-11): 12 x CLIPEncoderLayer(\n","            (self_attn): CLIPAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (mlp): CLIPMLP(\n","              (activation_fn): QuickGELUActivation()\n","              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","      )\n","      (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n","    (text_projection): Linear(in_features=512, out_features=512, bias=False)\n","  )\n","  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n","  (hiddens): ModuleList()\n","  (fc2): Linear(in_features=256, out_features=3, bias=True)\n","  (activation): ReLU()\n","  (dropout): Dropout(p=0.1, inplace=False)\n",")"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["collate = Collator(test=True)\n","valid_dataloader = DataLoader(val_dataset, batch_size=CFG.batch_size, collate_fn=collate)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","inf_model_name = 'openai-clip-vit-base-patch32_score_0.8345'\n","inf_model = ConcatArch(\n","    hidden_size=CFG.mlp_hidden_size,\n","    hidden_layers=CFG.mlp_hidden_layers,\n","    dropout=CFG.mlp_dropout,\n","    num_classes=CFG.num_class,\n","    use_multimodal=CFG.use_multimodal,\n","    use_dualencoder=CFG.use_dualencoder,\n","    is_mclip=CFG.is_mclip\n",").to(CFG.device)\n","inf_model.load_state_dict(torch.load('Task 5/' + inf_model_name + '.pth', map_location=torch.device(CFG.device))['model'])\n","inf_model"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 26/26 [00:10<00:00,  2.57it/s]"]},{"name":"stdout","output_type":"stream","text":["[110002, 110005, 110012, 110017, 110020, 110022, 110035, 110036, 110037, 110039, 110047, 110051, 110065, 110076, 110090, 110091, 110096, 110099, 110104, 110115, 110117, 110120, 110123, 110128, 110131, 110144, 110147, 110154, 110155, 110161, 110162, 110173, 110181, 110187, 110190, 110191, 110198, 110201, 110202, 110203, 110207, 110217, 110226, 110235, 110242, 110246, 110254, 110263, 110265, 110269, 110285, 110294, 110302, 110318, 110331, 110336, 110338, 110357, 110370, 110379, 110380, 110392, 110393, 110396, 110397, 110398, 110400, 110401, 110404, 110413, 110418, 110419, 110453, 110456, 110460, 110467, 110470, 110475, 110488, 110489, 110493, 110497, 110500, 110503, 110511, 110513, 110516, 110525, 110538, 110541, 110547, 110551, 110560, 110563, 110564, 110570, 110575, 110581, 110587, 110596, 110601, 110607, 110609, 110617, 110624, 110626, 110628, 110634, 110636, 110640, 110641, 110642, 110647, 110649, 110657, 110659, 110660, 110664, 110676, 110682, 110684, 110685, 110699, 110700, 110703, 110704, 110710, 110714, 110718, 110729, 110733, 110741, 110748, 110751, 110754, 110764, 110767, 110770, 110774, 110776, 110780, 110785, 110792, 110796, 110798, 110805, 110816, 110826, 110831, 110834, 110836, 110838, 110851, 110852, 110854, 110855, 110861, 110864, 110871, 110873, 110877, 110878, 110879, 110881, 110885, 110896, 110897, 110921, 110954, 110955, 110956, 110957, 110958, 110960, 110961, 110972, 110973, 110976, 110978, 110981, 110992, 110993, 110996, 110997, 111009, 111013, 111016, 111017, 111021, 111022, 111029, 111039, 111046, 111052, 111060, 111061, 111063, 111066, 111067, 111070, 111077, 111078, 111082, 111083, 111093, 111096, 111116, 111120, 111123, 111127, 111130, 111131, 111137, 111140, 111142, 111148, 111149, 111151, 111153, 111154, 111155, 111156, 111157, 111159, 111163, 111167, 111168, 111181, 111184, 111185, 111192, 111198, 111206, 111210, 111213, 111216, 111218, 111219, 111220, 111228, 111239, 111244, 111258, 111268, 111276, 111283, 111292, 111295, 111297, 111298, 111301, 111307, 111313, 111325, 111328, 111347, 111349, 111355, 111364, 111366, 111368, 111370, 111389, 111391, 111401, 111409, 111410, 111416, 111417, 111435, 111439, 111440, 111441, 111444, 111446, 111471, 111479, 111480, 111483, 111485, 111486, 111493, 111496, 111497, 111501, 111505, 111516, 111517, 111520, 111521, 111523, 111528, 111529, 111530, 111535, 111541, 111543, 111549, 111569, 111571, 111572, 111580, 111586, 111590, 111596, 111598, 111604, 111626, 111631, 111632, 111635, 111636, 111637, 111639, 111644, 111649, 111650, 111662, 111664, 111665, 111677, 111679, 111680, 111681, 111683, 111686, 111687, 111688, 111694, 111696, 111697, 111699, 111705, 111706, 111708, 111716, 111723, 111734, 111735, 111752, 111758, 111759, 111760, 111769, 111774, 111782, 111783, 111786, 111788, 111795, 111797, 111800, 111803, 111807, 111811, 111817, 111820, 111822, 111824, 111828, 111842, 111844, 111854, 111857, 111864, 111882, 111885, 111891, 111893, 111896, 111900, 111904, 111907, 111920, 111924, 111931, 111932, 111956, 111960, 111970, 111975, 111982, 111983, 111987, 111999, 112007, 112028, 210005, 210008, 210014, 210016, 210023, 210028, 210029, 210032, 210035, 210037, 210041, 210043, 210049, 210052, 210055, 210068, 210076, 210102, 210106, 210108, 210110, 210113, 210123, 210127, 210136, 210149, 210158, 210164, 210165, 210166, 210167, 210172, 210174, 210181, 210184, 210191, 210202, 210204, 210206, 210220, 210222, 210231, 210232, 210234, 210244, 210245, 210261, 210267, 210268, 210272, 210278, 210284, 210291, 210293, 210294, 210298, 210303, 210310, 210319, 210328, 210330, 210335, 210352, 210353, 210355, 210358, 210360, 210394, 210399, 210400, 210402, 210411, 210412, 210416, 210417, 210421, 210422, 210446, 210452, 210456, 210458, 210459, 210469, 210471, 210478, 210485, 210487, 210488, 210491, 210499, 210504, 210506, 210511, 210513, 210523, 210524, 210525, 210526, 210532, 210535, 210536, 210539, 210565, 210571, 210579, 210580, 210583, 210584, 210592, 210602, 210607, 210619, 210627, 210642, 210647, 210648, 210657, 210660, 210662, 210668, 210670, 210672, 210677, 210696, 210698, 210700, 210701, 210702, 210704, 210705, 210711, 210714, 210734, 210740, 210741, 210744, 210749, 210753, 210757, 210763, 210764, 210766, 210773, 210775, 210776, 210778, 210781, 210783, 210791, 210804, 210805, 210806, 210809, 210815, 210816, 210820, 210830, 210836, 210837, 210842, 210846, 210855, 210863, 210868, 210871, 210875, 210878, 210881, 210886, 210890, 210893, 210898, 210905, 210906, 210911, 210912, 210917, 210926, 210927, 210928, 210934, 210942, 210943, 210944, 210949, 210950, 210960, 210962, 210966, 210969, 210970, 210972, 210976, 210984, 210996, 211007, 211017, 211018, 211026, 211027, 211029, 211032, 211034, 211035, 211036, 211040, 211047, 211054, 211057, 211059, 211063, 211066, 211071, 211075, 211077, 211079, 211085, 211086, 211087, 211091, 211101, 211107, 211108, 211112, 211113, 211114, 211119, 211124, 211137, 211138, 211141, 211142, 211150, 211151, 211158, 211164, 211169, 211186, 211189, 211201, 211203, 211209, 211210, 211214, 211218, 211222, 211228, 211234, 211239, 211256, 211261, 211263, 211265, 211269, 211271, 211275, 211279, 211281, 211282, 211288, 211291, 211292, 211294, 211309, 211310, 211315, 211318, 211321, 211323, 211326, 211336, 211340, 211346, 211347, 211352, 211356, 211361, 211364, 211380, 211384, 211385, 211386, 211387, 211388, 211392, 211397, 211398, 211403, 211411, 211412, 211413, 211423, 211424, 211425, 211426, 211428, 211429, 211431, 211437, 211438, 211441, 211445, 211451, 211452, 211466, 211474, 211477, 211479, 211484, 211500, 211514, 211523, 211528, 211546, 211548, 211549, 211550, 211554, 211561, 211572, 211578, 211588, 211592, 211594, 211599, 211604, 211605, 211610, 211611, 211612, 211613, 211616, 211627, 211640, 211641, 211642, 211647, 211648, 211663, 211682, 211689, 211696, 211702, 211703, 211704, 211707, 211710, 211713, 211715, 211720, 211729, 211730, 211732, 211736, 211738, 211739, 211740, 211741, 211743, 211745, 211748, 211750, 211757, 211763, 211765, 211766, 211773, 211776, 211777, 211779, 211780, 211787, 211794, 211795, 211796, 211798, 211807, 211808, 211810, 211812, 211821, 211825, 211827, 211835, 211840, 211842, 211845, 211847, 211849, 211851, 211857, 211858, 211860, 211870, 211885, 211887, 211889, 211895, 211901, 211902, 211905, 211909, 211910, 211912, 211915, 211916, 211923, 211924, 211927, 211932, 211934, 211946, 211958, 211961, 211975, 211978, 211979, 211982, 211993, 211994, 211995, 211999]\n","[2, 1, 1, 1, 2, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0, 2, 1, 2, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 2, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 0, 1, 2, 0, 1, 0, 2, 1, 1, 0, 2, 1, 0, 0, 1, 1, 0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 0, 1, 2, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 2, 1, 0, 1, 2, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1, 0, 2, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 2, 1, 0, 1, 0, 0, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 0, 1, 0, 1, 1, 0, 2, 0, 2, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 2, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 2, 0, 2, 1, 1, 1, 1, 1, 0, 0, 2, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 0, 2, 1, 1, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 2, 2, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 1, 2, 0, 2, 1, 0, 0, 0, 2, 1, 0, 2, 2, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 1, 0, 0, 1, 0, 1, 2, 0, 1, 0, 2, 0, 2, 2, 0, 2, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 2, 0, 1, 1, 2, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 1, 2, 0, 0, 0, 2, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 2, 1, 0, 1, 1, 2, 2, 0, 2, 0, 1, 2, 0, 2, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 2, 0, 1, 2, 1, 0, 0, 1, 2, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 2, 2, 0, 0, 0, 1, 2, 0, 1, 0, 0, 2, 0, 1, 0, 0, 2, 1, 2, 1, 1, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 0, 1, 0, 1, 1, 2, 2, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 2, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 2, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 1, 0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 2, 1, 2, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0, 1, 1, 1, 2, 0, 0, 2, 2, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 0, 2, 1, 1]\n","[[0.004275993909686804, 0.0069547961466014385, 0.9887691736221313], [0.007318026386201382, 0.9728745818138123, 0.019807403907179832], [0.4098958671092987, 0.5536372661590576, 0.03646688908338547], [0.01618926227092743, 0.9632917046546936, 0.02051905356347561], [0.0038790246471762657, 0.009338376112282276, 0.9867826700210571], [0.9671047925949097, 0.01360528264194727, 0.01928999088704586], [0.9679111242294312, 0.012773575261235237, 0.019315337762236595], [0.005619784817099571, 0.9724695682525635, 0.021910643205046654], [0.013158383779227734, 0.9667028188705444, 0.020138844847679138], [0.9690914750099182, 0.010442429222166538, 0.02046617679297924], [0.9459312558174133, 0.03518601879477501, 0.01888269931077957], [0.00624737236648798, 0.972379744052887, 0.0213729590177536], [0.9659357070922852, 0.007536645047366619, 0.026527563109993935], [0.00685920100659132, 0.9729971289634705, 0.02014370821416378], [0.9530050754547119, 0.028680214658379555, 0.018314743414521217], [0.046711526811122894, 0.9290989637374878, 0.024189438670873642], [0.005402496550232172, 0.9569836854934692, 0.037613850086927414], [0.005554679781198502, 0.9723424315452576, 0.022102896124124527], [0.006093455012887716, 0.9728737473487854, 0.02103281021118164], [0.056573253124952316, 0.9176991581916809, 0.025727618485689163], [0.01467612013220787, 0.9651573300361633, 0.02016649767756462], [0.9350505471229553, 0.04521496966481209, 0.019734354689717293], [0.02286274917423725, 0.9555862545967102, 0.02155107632279396], [0.34771886467933655, 0.615375816822052, 0.036905307322740555], [0.011621244251728058, 0.9685390591621399, 0.019839735701680183], [0.005236133001744747, 0.967103123664856, 0.02766069583594799], [0.0037488301750272512, 0.010901975445449352, 0.9853492379188538], [0.006453663110733032, 0.9730927348136902, 0.020453620702028275], [0.008900973945856094, 0.9684914350509644, 0.022607535123825073], [0.015967480838298798, 0.9634629487991333, 0.020569512620568275], [0.4292350709438324, 0.534041166305542, 0.0367237813770771], [0.005704229697585106, 0.9718928933143616, 0.022402813658118248], [0.9609500765800476, 0.020097380504012108, 0.018952542915940285], [0.956152081489563, 0.02553689479827881, 0.018311047926545143], [0.9533756971359253, 0.028041794896125793, 0.018582548946142197], [0.008094534277915955, 0.4705842137336731, 0.5213212370872498], [0.8241239786148071, 0.005150900222361088, 0.17072510719299316], [0.5664291977882385, 0.00491050910204649, 0.4286602735519409], [0.2742515206336975, 0.0038730015512555838, 0.7218754291534424], [0.008561577647924423, 0.9718475341796875, 0.01959090866148472], [0.02229071967303753, 0.0025387618225067854, 0.9751705527305603], [0.9538430571556091, 0.027860919013619423, 0.018295999616384506], [0.9532837271690369, 0.006318770814687014, 0.04039757326245308], [0.014538069255650043, 0.9652557373046875, 0.020206229761242867], [0.9680882096290588, 0.012627922929823399, 0.019283808767795563], [0.9623761177062988, 0.006852565333247185, 0.03077133558690548], [0.012011514976620674, 0.9681388139724731, 0.019849728792905807], [0.008737423457205296, 0.9715837836265564, 0.019678756594657898], [0.005296125076711178, 0.9699119925498962, 0.024791816249489784], [0.9676787853240967, 0.008189518935978413, 0.024131760001182556], [0.9689420461654663, 0.011360936798155308, 0.019697099924087524], [0.9492624998092651, 0.03212752938270569, 0.01860993728041649], [0.7120627760887146, 0.2560881972312927, 0.03184903413057327], [0.9466177821159363, 0.034563686698675156, 0.018818436190485954], [0.9497582912445068, 0.03166602924466133, 0.01857571490108967], [0.9646009802818298, 0.007321247830986977, 0.02807781845331192], [0.9639548659324646, 0.0071288044564425945, 0.02891629934310913], [0.0053845657967031, 0.8777063488960266, 0.11690910160541534], [0.8281060457229614, 0.005237298551946878, 0.16665668785572052], [0.008798201568424702, 0.9716549515724182, 0.019546812400221825], [0.03479704633355141, 0.0554303340613842, 0.9097726941108704], [0.6890011429786682, 0.005057039670646191, 0.30594179034233093], [0.4446256458759308, 0.51633220911026, 0.03904213383793831], [0.007080880459398031, 0.003164056222885847, 0.9897549748420715], [0.968062698841095, 0.012141253799200058, 0.019796118140220642], [0.9604129791259766, 0.02126750536262989, 0.01831957884132862], [0.9689680337905884, 0.01151895523071289, 0.019512996077537537], [0.004524264018982649, 0.0961172804236412, 0.8993585109710693], [0.004225048702210188, 0.006311116274446249, 0.9894638061523438], [0.9650298953056335, 0.015925703570246696, 0.01904434524476528], [0.9142582416534424, 0.005468565504997969, 0.08027317374944687], [0.9636107087135315, 0.014967548660933971, 0.021421760320663452], [0.6735295057296753, 0.2934516370296478, 0.03301886469125748], [0.9679613709449768, 0.008849562145769596, 0.023189015686511993], [0.9503289461135864, 0.031078191474080086, 0.018592797219753265], [0.9424615502357483, 0.038411594927310944, 0.019126838073134422], [0.506400465965271, 0.4576704800128937, 0.03592908754944801], [0.09535466879606247, 0.873019814491272, 0.03162559121847153], [0.0852462649345398, 0.8870392441749573, 0.027714427560567856], [0.9276240468025208, 0.05194912478327751, 0.020426835864782333], [0.9328559041023254, 0.047121256589889526, 0.02002282813191414], [0.012562780641019344, 0.9671573042869568, 0.020279942080378532], [0.9426919221878052, 0.03810201212763786, 0.01920609548687935], [0.9380345940589905, 0.042458806186914444, 0.019506681710481644], [0.948674738407135, 0.0061061084270477295, 0.045219168066978455], [0.9508745074272156, 0.006291747558861971, 0.04283370077610016], [0.8479495644569397, 0.005292979069054127, 0.14675749838352203], [0.006331118289381266, 0.48644542694091797, 0.5072234869003296], [0.005250665359199047, 0.9679434299468994, 0.026805948466062546], [0.011630955152213573, 0.9685652256011963, 0.019803833216428757], [0.9536088109016418, 0.028027137741446495, 0.018364083021879196], [0.006914820056408644, 0.9731199145317078, 0.01996520906686783], [0.9648615717887878, 0.016829658299684525, 0.01830870285630226], [0.005931579973548651, 0.9726881980895996, 0.021380163729190826], [0.005747364368289709, 0.8036834001541138, 0.1905691772699356], [0.9474079012870789, 0.03394068777561188, 0.018651431426405907], [0.958433210849762, 0.006592399440705776, 0.034974463284015656], [0.8802656531333923, 0.09575076401233673, 0.023983467370271683], [0.9652947187423706, 0.016431814059615135, 0.01827343925833702], [0.003618797054514289, 0.021414121612906456, 0.9749670624732971], [0.9685744047164917, 0.010835534892976284, 0.020590027794241905], [0.9120385050773621, 0.06499666720628738, 0.022964851930737495], [0.9639321565628052, 0.017837228253483772, 0.018230687826871872], [0.34980887174606323, 0.004132189322263002, 0.646058976650238], [0.012127694673836231, 0.967979907989502, 0.019892357289791107], [0.9689363241195679, 0.0087548503652215, 0.022308871150016785], [0.00894260685890913, 0.9702212810516357, 0.020836101844906807], [0.005322765558958054, 0.9710719585418701, 0.023605231195688248], [0.3063761591911316, 0.6578632593154907, 0.035760585218667984], [0.0059319427236914635, 0.9724819660186768, 0.021586129441857338], [0.969211757183075, 0.009524294175207615, 0.0212639719247818], [0.9641975164413452, 0.01759371906518936, 0.018208786845207214], [0.9692054390907288, 0.010263452306389809, 0.02053108625113964], [0.02545386552810669, 0.9528488516807556, 0.02169722691178322], [0.00708607817068696, 0.9715569019317627, 0.021357044577598572], [0.9666057825088501, 0.014801095239818096, 0.018593179062008858], [0.9492904543876648, 0.032154057174921036, 0.01855551078915596], [0.008164269849658012, 0.9721170663833618, 0.019718710333108902], [0.775201141834259, 0.19533610343933105, 0.029462739825248718], [0.724615216255188, 0.24374596774578094, 0.03163876757025719], [0.038985271006822586, 0.9374708533287048, 0.023543907329440117], [0.9568082690238953, 0.006629032548516989, 0.03656260296702385], [0.9598285555839539, 0.006776901893317699, 0.03339449688792229], [0.005683641880750656, 0.9725740551948547, 0.021742234006524086], [0.09502442181110382, 0.49658000469207764, 0.40839552879333496], [0.9595573544502258, 0.022246796637773514, 0.01819583959877491], [0.046743061393499374, 0.929048478603363, 0.024208446964621544], [0.906928300857544, 0.07077886164188385, 0.0222928449511528], [0.9501248002052307, 0.03133196756243706, 0.018543263897299767], [0.9164401888847351, 0.006437639240175486, 0.07712207734584808], [0.005169342737644911, 0.9550971984863281, 0.039733484387397766], [0.012510823085904121, 0.9676234126091003, 0.019865743815898895], [0.006126252468675375, 0.34442418813705444, 0.6494495272636414], [0.5653996467590332, 0.0048841508105397224, 0.42971622943878174], [0.965965747833252, 0.015623322688043118, 0.018410848453640938], [0.9692431092262268, 0.010699997656047344, 0.02005697973072529], [0.02906586229801178, 0.002748001366853714, 0.9681861996650696], [0.017878219485282898, 0.008614780381321907, 0.9735069274902344], [0.1335972398519516, 0.8351061344146729, 0.031296610832214355], [0.5368304252624512, 0.42754116654396057, 0.03562840074300766], [0.007375932764261961, 0.003098753746598959, 0.989525318145752], [0.902585506439209, 0.007349972613155842, 0.09006460756063461], [0.9675642848014832, 0.00792993325740099, 0.024505792185664177], [0.9664690494537354, 0.007658987306058407, 0.02587207406759262], [0.9658204913139343, 0.007862616330385208, 0.026316799223423004], [0.00517273461446166, 0.9660872220993042, 0.02874000370502472], [0.016735807061195374, 0.0027774455957114697, 0.9804866909980774], [0.9656280875205994, 0.015407511033117771, 0.0189644917845726], [0.005183645058423281, 0.9684449434280396, 0.026371484622359276], [0.93508380651474, 0.045194439589977264, 0.01972171850502491], [0.004240413662046194, 0.029870161786675453, 0.9658894538879395], [0.09441255033016205, 0.8767275214195251, 0.028859946876764297], [0.00511397048830986, 0.9608697295188904, 0.03401628136634827], [0.9685564041137695, 0.01209691446274519, 0.01934664696455002], [0.01609303057193756, 0.002717057941481471, 0.9811899662017822], [0.0065048155374825, 0.9729060530662537, 0.020589103922247887], [0.9680827260017395, 0.00918392650783062, 0.02273346111178398], [0.9578798413276672, 0.023839114233851433, 0.018281115218997], [0.008052922785282135, 0.9723114371299744, 0.01963563822209835], [0.012481034733355045, 0.9674876928329468, 0.02003127709031105], [0.5948506593704224, 0.3692525625228882, 0.03589670732617378], [0.9035477638244629, 0.0740930438041687, 0.022359086200594902], [0.009852057322859764, 0.9705016016960144, 0.01964636892080307], [0.00454803928732872, 0.016780270263552666, 0.978671669960022], [0.9511635303497314, 0.0303554255515337, 0.01848103106021881], [0.9263689517974854, 0.05305596441030502, 0.020575111731886864], [0.9481796622276306, 0.03319672495126724, 0.018623556941747665], [0.9587455987930298, 0.022973790764808655, 0.018280528485774994], [0.009091172367334366, 0.9713147282600403, 0.019594071432948112], [0.006684178952127695, 0.9732149839401245, 0.020100891590118408], [0.006831599399447441, 0.9731734395027161, 0.01999501697719097], [0.005980913992971182, 0.9728594422340393, 0.021159669384360313], [0.003780956845730543, 0.035759635269641876, 0.9604593515396118], [0.0038556151557713747, 0.012683509849011898, 0.9834609031677246], [0.897054135799408, 0.08017732203006744, 0.022768493741750717], [0.009681157767772675, 0.97069251537323, 0.019626369699835777], [0.004426316358149052, 0.005760690663009882, 0.9898129105567932], [0.004984350875020027, 0.9600613713264465, 0.0349542610347271], [0.9634679555892944, 0.007098958361893892, 0.02943318337202072], [0.9569734334945679, 0.006475032772868872, 0.03655149042606354], [0.9519943594932556, 0.02811945229768753, 0.01988610439002514], [0.006634040270000696, 0.9730464220046997, 0.0203195009380579], [0.9642443656921387, 0.017541998997330666, 0.01821352168917656], [0.9694123268127441, 0.00977237243205309, 0.020815275609493256], [0.00509271677583456, 0.9661652445793152, 0.028742071241140366], [0.861358642578125, 0.10342787951231003, 0.03521351143717766], [0.005533892661333084, 0.855627179145813, 0.13883891701698303], [0.9548854827880859, 0.006363243795931339, 0.03875124827027321], [0.01255708560347557, 0.9675439596176147, 0.019898904487490654], [0.00449340557679534, 0.07145456224679947, 0.9240521192550659], [0.010619176551699638, 0.966000497341156, 0.023380354046821594], [0.9449840188026428, 0.006006583105772734, 0.04900944232940674], [0.009350515902042389, 0.9709035754203796, 0.019745899364352226], [0.0057373009622097015, 0.2667134702205658, 0.7275492548942566], [0.9683603048324585, 0.008355074562132359, 0.023284662514925003], [0.9604752063751221, 0.021102214232087135, 0.018422594293951988], [0.9118838906288147, 0.06641026586294174, 0.02170576900243759], [0.9321775436401367, 0.047842975705862045, 0.0199794452637434], [0.020124293863773346, 0.95882648229599, 0.021049218252301216], [0.9447424411773682, 0.03631267696619034, 0.018944907933473587], [0.0144038749858737, 0.9654224514961243, 0.020173652097582817], [0.0041725849732756615, 0.006466457154601812, 0.9893608689308167], [0.8957203030586243, 0.08145283907651901, 0.022826867178082466], [0.964359700679779, 0.007088101468980312, 0.028552167117595673], [0.005252887960523367, 0.9703869223594666, 0.02436014637351036], [0.9433815479278564, 0.03734505549073219, 0.01927340403199196], [0.00582134909927845, 0.7954451441764832, 0.19873347878456116], [0.013427140191197395, 0.9660789966583252, 0.020493820309638977], [0.8802656531333923, 0.09575076401233673, 0.023983467370271683], [0.9502890110015869, 0.006175733171403408, 0.04353523254394531], [0.008481240831315517, 0.9719322323799133, 0.019586581736803055], [0.005121137015521526, 0.9565838575363159, 0.038295064121484756], [0.004984220489859581, 0.9496766924858093, 0.04533909633755684], [0.0052186427637934685, 0.9365711212158203, 0.05821023881435394], [0.005602201912552118, 0.9720227718353271, 0.02237500064074993], [0.911666214466095, 0.066585473716259, 0.021748265251517296], [0.015385073609650135, 0.9642816185951233, 0.020333237946033478], [0.004312105476856232, 0.006196855567395687, 0.9894910454750061], [0.9047215580940247, 0.07271421700716019, 0.02256418764591217], [0.08219367265701294, 0.8891775608062744, 0.028628753498196602], [0.9672756195068359, 0.00804087147116661, 0.024683482944965363], [0.01049325056374073, 0.02587573416531086, 0.9636309742927551], [0.017911694943904877, 0.9612396955490112, 0.020848622545599937], [0.5283200144767761, 0.4350593090057373, 0.036620695143938065], [0.005377812776714563, 0.9714059233665466, 0.023216240108013153], [0.006549084093421698, 0.9731018543243408, 0.020349010825157166], [0.958389401435852, 0.006749416701495647, 0.03486126661300659], [0.9651987552642822, 0.007419896777719259, 0.02738131210207939], [0.9387883543968201, 0.041782040148973465, 0.019429655745625496], [0.9256100654602051, 0.053757499903440475, 0.020632442086935043], [0.005129245109856129, 0.9474816918373108, 0.047389086335897446], [0.9199625849723816, 0.05899171158671379, 0.021045755594968796], [0.0037663173861801624, 0.014200717210769653, 0.9820329546928406], [0.005296624731272459, 0.9706693291664124, 0.024034082889556885], [0.9666762948036194, 0.01470204908400774, 0.01862165704369545], [0.010174560360610485, 0.9701113104820251, 0.01971411518752575], [0.9627282023429871, 0.019110461696982384, 0.018161240965127945], [0.9609462022781372, 0.02067367173731327, 0.018380198627710342], [0.016439320519566536, 0.9630531668663025, 0.020507536828517914], [0.0051433248445391655, 0.9112637042999268, 0.08359293639659882], [0.007807555142790079, 0.9724159836769104, 0.019776375964283943], [0.0037858271971344948, 0.011246711947023869, 0.9849674105644226], [0.003676072461530566, 0.012146709486842155, 0.9841772317886353], [0.005672643426805735, 0.9724872708320618, 0.021840082481503487], [0.9626233577728271, 0.019168367609381676, 0.01820828765630722], [0.005226220469921827, 0.9685176014900208, 0.026256203651428223], [0.012958493083715439, 0.9671000242233276, 0.019941503182053566], [0.005461393389850855, 0.9721049666404724, 0.022433562204241753], [0.004999950993806124, 0.9557483196258545, 0.03925172984600067], [0.00860475841909647, 0.9717153906822205, 0.019679918885231018], [0.96036297082901, 0.021469034254550934, 0.018168121576309204], [0.844052255153656, 0.12941350042819977, 0.02653425559401512], [0.01373641099780798, 0.9660229682922363, 0.020240599289536476], [0.9588812589645386, 0.022751308977603912, 0.018367433920502663], [0.006401518359780312, 0.9718414545059204, 0.021757040172815323], [0.004806338343769312, 0.1257648468017578, 0.869428813457489], [0.9406241774559021, 0.040087323635816574, 0.019288502633571625], [0.9628678560256958, 0.006985499523580074, 0.030146678909659386], [0.006435545161366463, 0.9730460047721863, 0.02051851525902748], [0.9676443934440613, 0.012494395487010479, 0.01986120082437992], [0.5260448455810547, 0.4375929534435272, 0.036362174898386], [0.7707516551017761, 0.1956586241722107, 0.03358981013298035], [0.0057584671303629875, 0.9726960062980652, 0.021545542404055595], [0.9263319373130798, 0.05305085703730583, 0.02061719447374344], [0.006136946380138397, 0.972937285900116, 0.020925769582390785], [0.003956424538046122, 0.047894686460494995, 0.9481489062309265], [0.9428184032440186, 0.006004073191434145, 0.05117753520607948], [0.005708532873541117, 0.9726399183273315, 0.021651562303304672], [0.9673346281051636, 0.012443135492503643, 0.020222287625074387], [0.015463806688785553, 0.9641575217247009, 0.020378639921545982], [0.006403070874512196, 0.9730527400970459, 0.020544173195958138], [0.9671071171760559, 0.013510726392269135, 0.019382165744900703], [0.020246604457497597, 0.0026379874907433987, 0.9771153926849365], [0.9676716327667236, 0.013394017703831196, 0.018934376537799835], [0.00392192741855979, 0.008465285412967205, 0.987612783908844], [0.941606879234314, 0.039146993309259415, 0.019246084615588188], [0.8553615808486938, 0.119061678647995, 0.025576744228601456], [0.06144798547029495, 0.9127274751663208, 0.02582450956106186], [0.9667816758155823, 0.014663937501609325, 0.018554285168647766], [0.6731488108634949, 0.29349035024642944, 0.033360835164785385], [0.9014747142791748, 0.07590971142053604, 0.022615564987063408], [0.0037889848463237286, 0.03373127803206444, 0.9624797701835632], [0.005514643620699644, 0.9721721410751343, 0.02231319062411785], [0.8779506683349609, 0.0053964280523359776, 0.11665280163288116], [0.9690817594528198, 0.009023807011544704, 0.021894430741667747], [0.7359750270843506, 0.005159831140190363, 0.2588651478290558], [0.0051410505548119545, 0.9683337807655334, 0.02652515470981598], [0.07658889144659042, 0.8962172865867615, 0.02719387598335743], [0.07005053013563156, 0.9035049676895142, 0.026444552466273308], [0.005755534395575523, 0.9725751876831055, 0.021669264882802963], [0.9688323736190796, 0.008809183724224567, 0.022358465939760208], [0.9688639044761658, 0.011405951343476772, 0.019730085507035255], [0.004699782934039831, 0.11430861800909042, 0.8809916973114014], [0.006400595884770155, 0.9730784893035889, 0.02052091434597969], [0.965604841709137, 0.015095455572009087, 0.01929975114762783], [0.9303596019744873, 0.049358122050762177, 0.0202821996062994], [0.00509271677583456, 0.9661652445793152, 0.028742071241140366], [0.005615771282464266, 0.9725542068481445, 0.021830039098858833], [0.9673961997032166, 0.008016394451260567, 0.02458740770816803], [0.9594551920890808, 0.0069575682282447815, 0.03358721733093262], [0.004935890436172485, 0.9484219551086426, 0.04664212465286255], [0.051380325108766556, 0.9236865639686584, 0.02493317611515522], [0.1334051787853241, 0.8353093862533569, 0.031285423785448074], [0.0068146600387990475, 0.9726179242134094, 0.02056735008955002], [0.004526526667177677, 0.005404420662671328, 0.9900690913200378], [0.9590010046958923, 0.006734877824783325, 0.03426407277584076], [0.9682971239089966, 0.011872443370521069, 0.019830381497740746], [0.9683772921562195, 0.012331276200711727, 0.01929149590432644], [0.014395574107766151, 0.9652233123779297, 0.02038109302520752], [0.006937567610293627, 0.9731029868125916, 0.019959397614002228], [0.013128526508808136, 0.9669463038444519, 0.019925197586417198], [0.01354437880218029, 0.966399073600769, 0.02005649544298649], [0.006976492702960968, 0.9730846881866455, 0.019938809797167778], [0.015440649352967739, 0.9641101956367493, 0.02044912986457348], [0.005107102449983358, 0.9395164847373962, 0.05537644028663635], [0.7160100340843201, 0.2510656416416168, 0.03292430192232132], [0.2869800329208374, 0.6725139617919922, 0.04050601273775101], [0.006180194206535816, 0.9731010794639587, 0.02071879431605339], [0.23814667761325836, 0.7272045612335205, 0.034648749977350235], [0.9349055290222168, 0.0451996885240078, 0.0198947936296463], [0.005092741455882788, 0.9665348529815674, 0.028372447937726974], [0.7869130373001099, 0.1839754581451416, 0.029111523181200027], [0.006684434600174427, 0.972947895526886, 0.02036767266690731], [0.9150890707969666, 0.06349622458219528, 0.02141464315354824], [0.005423283204436302, 0.861099123954773, 0.1334775686264038], [0.8711535930633545, 0.0052360487170517445, 0.12361025810241699], [0.015127738006412983, 0.9645446538925171, 0.020327595993876457], [0.018441444262862206, 0.960480272769928, 0.02107824571430683], [0.010789583437144756, 0.9694886207580566, 0.019721822813153267], [0.44798144698143005, 0.5159200429916382, 0.03609847649931908], [0.05394291877746582, 0.9210447072982788, 0.02501233108341694], [0.0061724986881017685, 0.39270398020744324, 0.6011235117912292], [0.0076828463934361935, 0.9725950360298157, 0.019722068682312965], [0.9622739553451538, 0.019513797014951706, 0.018212229013442993], [0.9537620544433594, 0.02771139144897461, 0.01852649822831154], [0.3872362971305847, 0.5766588449478149, 0.036104846745729446], [0.006143319886177778, 0.9728648662567139, 0.020991846919059753], [0.006972811184823513, 0.9730912446975708, 0.019935889169573784], [0.005055172834545374, 0.964870810508728, 0.030074020847678185], [0.005927938502281904, 0.3335272967815399, 0.660544753074646], [0.009847805835306644, 0.9702099561691284, 0.019942283630371094], [0.011852607131004333, 0.9683471322059631, 0.01980026252567768], [0.02038096822798252, 0.9570974707603455, 0.02252154052257538], [0.009355421178042889, 0.970711350440979, 0.01993325538933277], [0.9577793478965759, 0.02398427203297615, 0.018236346542835236], [0.9257048964500427, 0.05360719561576843, 0.020687879994511604], [0.04828549176454544, 0.0033245058730244637, 0.948390007019043], [0.8955934047698975, 0.005376304965466261, 0.0990302711725235], [0.024588070809841156, 0.0026198674459010363, 0.9727919697761536], [0.015879658982157707, 0.9635469317436218, 0.020573385059833527], [0.008600800298154354, 0.9717640280723572, 0.01963522657752037], [0.07506213337182999, 0.8950928449630737, 0.029844965785741806], [0.2086891084909439, 0.7578022480010986, 0.03350866213440895], [0.010880163870751858, 0.969137966632843, 0.019981924444437027], [0.9645222425460815, 0.01712748035788536, 0.018350211903452873], [0.9691632390022278, 0.011056344024837017, 0.01978040486574173], [0.0060665602795779705, 0.37078067660331726, 0.6231527924537659], [0.0065020970068871975, 0.9730858206748962, 0.020412087440490723], [0.9687591791152954, 0.011569003574550152, 0.01967190019786358], [0.9670578837394714, 0.007698223926126957, 0.02524389885365963], [0.9572001099586487, 0.02443007193505764, 0.018369777128100395], [0.016989553347229958, 0.9623485207557678, 0.020661944523453712], [0.026304876431822777, 0.9517285823822021, 0.02196652814745903], [0.06517709791660309, 0.9081571698188782, 0.02666572481393814], [0.9634926319122314, 0.017773160710930824, 0.018734296783804893], [0.9513900876045227, 0.007340506184846163, 0.04126937314867973], [0.00524643249809742, 0.9701815843582153, 0.024571988731622696], [0.07687850296497345, 0.8959988355636597, 0.0271226204931736], [0.020067814737558365, 0.9587833881378174, 0.021148746833205223], [0.9551756978034973, 0.026536189019680023, 0.01828806661069393], [0.969375491142273, 0.009400497190654278, 0.021224070340394974], [0.016476619988679886, 0.9630963802337646, 0.020427029579877853], [0.965255856513977, 0.016484571620821953, 0.018259556964039803], [0.3801434636116028, 0.00580200320109725, 0.6140545010566711], [0.9590907692909241, 0.006712730973958969, 0.03419653698801994], [0.9012157320976257, 0.07630228251218796, 0.02248203568160534], [0.9507009983062744, 0.030841922387480736, 0.01845712587237358], [0.008416798897087574, 0.002940188627690077, 0.9886431097984314], [0.00568278506398201, 0.8231574892997742, 0.17115968465805054], [0.005251447204500437, 0.9680394530296326, 0.026709116995334625], [0.9658917784690857, 0.015803901478648186, 0.01830427162349224], [0.005425938870757818, 0.971921980381012, 0.022652046754956245], [0.003688295604661107, 0.01221439428627491, 0.9840972423553467], [0.9328338503837585, 0.005699693690985441, 0.06146644428372383], [0.938321053981781, 0.04214736446738243, 0.01953165791928768], [0.938746452331543, 0.04143061116337776, 0.019822869449853897], [0.9338918328285217, 0.04617920145392418, 0.01992889679968357], [0.9686313271522522, 0.008720417506992817, 0.022648289799690247], [0.004081587307155132, 0.007145038340240717, 0.9887734055519104], [0.004875342361629009, 0.004570139106363058, 0.9905545115470886], [0.005411104299128056, 0.8662917613983154, 0.12829715013504028], [0.005483997520059347, 0.9410954713821411, 0.05342055484652519], [0.06577740609645844, 0.9079022407531738, 0.026320423930883408], [0.01682376116514206, 0.002692603738978505, 0.9804835915565491], [0.013463785871863365, 0.9657431244850159, 0.020793139934539795], [0.006288984790444374, 0.5534233450889587, 0.44028764963150024], [0.010034849867224693, 0.9700084924697876, 0.019956717267632484], [0.9361996054649353, 0.044177498668432236, 0.01962284743785858], [0.9413773417472839, 0.03882167115807533, 0.019800929352641106], [0.5422106385231018, 0.4214847683906555, 0.036304619163274765], [0.9397416710853577, 0.04086499661207199, 0.019393211230635643], [0.9485360383987427, 0.03278893604874611, 0.01867501251399517], [0.01416077185422182, 0.9657406806945801, 0.020098548382520676], [0.9379496574401855, 0.04252411052584648, 0.019526273012161255], [0.9437764883041382, 0.0369311161339283, 0.019292471930384636], [0.9568585753440857, 0.02471993863582611, 0.018421508371829987], [0.007124424912035465, 0.9728912711143494, 0.01998431608080864], [0.9578775763511658, 0.006507360842078924, 0.03561507910490036], [0.03947102278470993, 0.9366852045059204, 0.023843809962272644], [0.010951989330351353, 0.969277024269104, 0.01977103389799595], [0.04557221010327339, 0.9301062822341919, 0.02432146668434143], [0.005117555148899555, 0.05010535567998886, 0.9447771310806274], [0.0037387702614068985, 0.015207875519990921, 0.9810532927513123], [0.8968925476074219, 0.08010540902614594, 0.023002110421657562], [0.9609327912330627, 0.020876523107290268, 0.018190590664744377], [0.012679428793489933, 0.9673157930374146, 0.02000480704009533], [0.9543208479881287, 0.006293980870395899, 0.03938518464565277], [0.015280300751328468, 0.9640962481498718, 0.02062343992292881], [0.9506902098655701, 0.02977084182202816, 0.019538920372724533], [0.9119464755058289, 0.06577225774526596, 0.022281311452388763], [0.006036092992872, 0.7335532307624817, 0.26041069626808167], [0.010224070399999619, 0.9701517224311829, 0.01962417922914028], [0.9682077169418335, 0.01254945620894432, 0.019242823123931885], [0.0037507335655391216, 0.02414724975824356, 0.9721020460128784], [0.9030214548110962, 0.0745798721909523, 0.02239866741001606], [0.9598650336265564, 0.006773469969630241, 0.033361416310071945], [0.9638742208480835, 0.007084445562213659, 0.029041314497590065], [0.9677317142486572, 0.012499764561653137, 0.019768543541431427], [0.8743185997009277, 0.005357418209314346, 0.12032399326562881], [0.9196826815605164, 0.005523984786123037, 0.07479336857795715], [0.950285792350769, 0.03117462433874607, 0.018539508804678917], [0.004954304546117783, 0.01018446497619152, 0.9848611354827881], [0.015499279834330082, 0.964098334312439, 0.020402448251843452], [0.2912038564682007, 0.672335147857666, 0.03646097332239151], [0.9620689153671265, 0.019776390865445137, 0.018154680728912354], [0.96674644947052, 0.014705408364534378, 0.01854817010462284], [0.9522616267204285, 0.02936445362865925, 0.01837385632097721], [0.005142407491803169, 0.9661339521408081, 0.028723591938614845], [0.0037262975238263607, 0.031153971329331398, 0.9651197791099548], [0.9251291155815125, 0.005650105886161327, 0.06922083348035812], [0.00475265784189105, 0.00521925138309598, 0.9900280833244324], [0.044202130287885666, 0.9318203330039978, 0.02397761307656765], [0.9631279110908508, 0.007120695896446705, 0.029751302674412727], [0.9657458066940308, 0.0073192841373384, 0.02693498507142067], [0.943784773349762, 0.006013988051563501, 0.05020128935575485], [0.005652096588164568, 0.02570228837430477, 0.9686456322669983], [0.021956073120236397, 0.9565688967704773, 0.0214750487357378], [0.6270566582679749, 0.33881905674934387, 0.034124307334423065], [0.004498058930039406, 0.09663064032793045, 0.8988712430000305], [0.004865133669227362, 0.13810281455516815, 0.8570320010185242], [0.9369927048683167, 0.04222330078482628, 0.020784027874469757], [0.9693197011947632, 0.010703431442379951, 0.019976885989308357], [0.5956634283065796, 0.36805763840675354, 0.03627895936369896], [0.9617005586624146, 0.019536929205060005, 0.0187626164406538], [0.0076485746540129185, 0.9726071357727051, 0.019744303077459335], [0.02590007334947586, 0.9521533250808716, 0.021946556866168976], [0.0039504352025687695, 0.008114244788885117, 0.9879354238510132], [0.004151687957346439, 0.006608756259083748, 0.9892395734786987], [0.9436067938804626, 0.03733540326356888, 0.019057797268033028], [0.9665777087211609, 0.014271475374698639, 0.01915081776678562], [0.006058185361325741, 0.9730110764503479, 0.02093067392706871], [0.9692299962043762, 0.010197251103818417, 0.020572755485773087], [0.923651933670044, 0.05541197955608368, 0.020936012268066406], [0.019474543631076813, 0.959565281867981, 0.020960170775651932], [0.8796675205230713, 0.0952591672539711, 0.025073355063796043], [0.012636843137443066, 0.9671837687492371, 0.020179400220513344], [0.004915195982903242, 0.13131150603294373, 0.8637733459472656], [0.9579907059669495, 0.006675261072814465, 0.03533406928181648], [0.006218463648110628, 0.6316830515861511, 0.36209848523139954], [0.9648768901824951, 0.007316256407648325, 0.02780683897435665], [0.0042275539599359035, 0.006973954848945141, 0.9887984395027161], [0.4860582947731018, 0.4776197075843811, 0.03632200136780739], [0.0039017624221742153, 0.04494138062000275, 0.9511568546295166], [0.003743545152246952, 0.013539855368435383, 0.9827166795730591], [0.9616909623146057, 0.01929858699440956, 0.019010495394468307], [0.004440538119524717, 0.08163528144359589, 0.9139242172241211], [0.016893332824110985, 0.9624952673912048, 0.020611464977264404], [0.0038774542044848204, 0.031115733087062836, 0.9650067687034607], [0.015124672092497349, 0.9645187854766846, 0.020356575027108192], [0.9534550309181213, 0.02812626212835312, 0.01841874234378338], [0.009248354472219944, 0.9709826111793518, 0.019769098609685898], [0.004216575063765049, 0.006523541174829006, 0.9892598390579224], [0.8862462639808655, 0.009677299298346043, 0.10407640039920807], [0.9682672023773193, 0.008675659075379372, 0.023057173937559128], [0.004986911080777645, 0.9594461917877197, 0.03556688874959946], [0.007587406784296036, 0.9726354479789734, 0.01977715827524662], [0.09795324504375458, 0.8730446696281433, 0.02900211326777935], [0.6382095217704773, 0.0127810537815094, 0.3490094244480133], [0.9242508411407471, 0.044138990342617035, 0.031610157340765], [0.8198077082633972, 0.005317336414009333, 0.17487499117851257], [0.033280692994594574, 0.943912923336029, 0.022806407883763313], [0.3644361197948456, 0.004167515784502029, 0.6313963532447815], [0.005793197546154261, 0.9672845602035522, 0.02692224457859993], [0.009372462518513203, 0.9705149531364441, 0.02011260762810707], [0.9659422636032104, 0.007528625428676605, 0.026529090479016304], [0.9557398557662964, 0.006463360041379929, 0.03779684379696846], [0.9692127704620361, 0.010281260125339031, 0.020506059750914574], [0.7541684508323669, 0.21487416326999664, 0.030957402661442757], [0.9656165242195129, 0.016089187934994698, 0.01829429529607296], [0.003795510856434703, 0.030236652120947838, 0.9659677743911743], [0.854789137840271, 0.006691975984722376, 0.13851886987686157], [0.9690687656402588, 0.010614638216793537, 0.020316679030656815], [0.00678622629493475, 0.9730438590049744, 0.020169954746961594], [0.0065882098861038685, 0.9703344106674194, 0.023077407851815224], [0.01701520010828972, 0.00262680696323514, 0.9803579449653625], [0.9678606390953064, 0.00815261248499155, 0.02398671582341194], [0.01241499837487936, 0.9675931930541992, 0.0199918020516634], [0.022087590768933296, 0.9565846920013428, 0.021327652037143707], [0.003640629816800356, 0.021865438669919968, 0.9744939804077148], [0.9641945362091064, 0.0072387587279081345, 0.02856668084859848], [0.003657190129160881, 0.013196449726819992, 0.9831462502479553], [0.007325098849833012, 0.9728001952171326, 0.01987466774880886], [0.9460898637771606, 0.03499805927276611, 0.018912052735686302], [0.9334970712661743, 0.04654665291309357, 0.019956355914473534], [0.960370659828186, 0.0067647299729287624, 0.03286466374993324], [0.9145026803016663, 0.0640208050608635, 0.021476512774825096], [0.007026758976280689, 0.9729864001274109, 0.0199868343770504], [0.11604040116071701, 0.8539377450942993, 0.030021850019693375], [0.9666585922241211, 0.007807370275259018, 0.025534015148878098], [0.004986034240573645, 0.9463726282119751, 0.0486413910984993], [0.968864381313324, 0.011523783206939697, 0.019611861556768417], [0.01718936488032341, 0.002575731137767434, 0.9802349805831909], [0.006434799637645483, 0.5731438398361206, 0.42042139172554016], [0.006235167384147644, 0.8966781497001648, 0.09708670526742935], [0.005421018693596125, 0.9276778697967529, 0.0669010579586029], [0.005325185135006905, 0.9359647035598755, 0.05871008709073067], [0.968980073928833, 0.0110097611322999, 0.020010190084576607], [0.9685646891593933, 0.009007826447486877, 0.022427385672926903], [0.968525767326355, 0.009724722243845463, 0.021749496459960938], [0.9601715803146362, 0.015347477979958057, 0.024480953812599182], [0.0063060736283659935, 0.5031816363334656, 0.49051231145858765], [0.9649407267570496, 0.016716694459319115, 0.018342573195695877], [0.02236674353480339, 0.9562394022941589, 0.021393921226263046], [0.018480869010090828, 0.9606342315673828, 0.020884845405817032], [0.9677613973617554, 0.013521362096071243, 0.018717264756560326], [0.9515755772590637, 0.030001157894730568, 0.018423285335302353], [0.0058194976300001144, 0.9714229106903076, 0.02275758609175682], [0.00811937265098095, 0.9719247817993164, 0.019955851137638092], [0.005255318246781826, 0.9637098908424377, 0.03103473410010338], [0.005660473369061947, 0.9226992726325989, 0.07164021581411362], [0.9663816094398499, 0.015023333951830864, 0.01859509013593197], [0.0037916202563792467, 0.01008550077676773, 0.9861228466033936], [0.9662716388702393, 0.007667821366339922, 0.02606053277850151], [0.9667806625366211, 0.00798135343939066, 0.02523791790008545], [0.9686157703399658, 0.009918912313878536, 0.021465232595801353], [0.9690847396850586, 0.010976546443998814, 0.019938716664910316], [0.8424755334854126, 0.1312413364648819, 0.026283133774995804], [0.9413840174674988, 0.039287228137254715, 0.019328780472278595], [0.9463609457015991, 0.005992201156914234, 0.04764683172106743], [0.955635666847229, 0.02024669572710991, 0.024117695167660713], [0.0054400889202952385, 0.9720368385314941, 0.022523099556565285], [0.9250887632369995, 0.05427948385477066, 0.02063167095184326], [0.003974187653511763, 0.04859112203121185, 0.9474346041679382], [0.006894166115671396, 0.48096778988838196, 0.5121380090713501], [0.0037008621729910374, 0.027329012751579285, 0.9689701199531555], [0.09267059713602066, 0.8786802291870117, 0.02864917181432247], [0.0036429292522370815, 0.013509707525372505, 0.9828474521636963], [0.9490517973899841, 0.006561693735420704, 0.04438655823469162], [0.913783073425293, 0.005521619692444801, 0.08069534599781036], [0.9389516115188599, 0.04131120815873146, 0.019737161695957184], [0.003873539622873068, 0.009692705236375332, 0.986433744430542], [0.02992243319749832, 0.9476503133773804, 0.022427216172218323], [0.9676316976547241, 0.008014187216758728, 0.024354111403226852], [0.004964497406035662, 0.9560946226119995, 0.038940832018852234], [0.005024689249694347, 0.9398010969161987, 0.05517426133155823], [0.9689745306968689, 0.011447696015238762, 0.019577788189053535], [0.0066977995447814465, 0.9729706048965454, 0.020331554114818573], [0.005956238601356745, 0.9727202653884888, 0.02132347971200943], [0.06264106929302216, 0.9110098481178284, 0.02634904906153679], [0.9596389532089233, 0.022159015759825706, 0.018202081322669983], [0.9427671432495117, 0.03343375027179718, 0.023799143731594086], [0.0062939771451056, 0.6207665801048279, 0.37293943762779236], [0.013096990995109081, 0.9668220281600952, 0.02008097991347313], [0.010067474097013474, 0.9700558185577393, 0.019876666367053986], [0.004113828297704458, 0.03542165830731392, 0.9604645371437073], [0.007289876230061054, 0.9724438786506653, 0.020266218110919], [0.9532371759414673, 0.028433609753847122, 0.018329225480556488], [0.34239086508750916, 0.6215182542800903, 0.03609093651175499], [0.005581684410572052, 0.9721075892448425, 0.02231072448194027], [0.005784548819065094, 0.2901516556739807, 0.7040638327598572], [0.0036463334690779448, 0.012947418726980686, 0.9834061861038208], [0.9546701312065125, 0.026924978941679, 0.018404915928840637], [0.036060333251953125, 0.0026492448523640633, 0.9612904787063599], [0.9431681036949158, 0.037786658853292465, 0.019045265391469002], [0.04341164603829384, 0.9325588345527649, 0.024029502645134926], [0.0052744485437870026, 0.005185247398912907, 0.9895402789115906], [0.9691110849380493, 0.010479717515408993, 0.02040928788483143], [0.006622895132750273, 0.0033758634235709906, 0.9900012016296387], [0.9684767127037048, 0.008459020406007767, 0.023064255714416504], [0.007941626012325287, 0.9723846912384033, 0.01967371441423893], [0.9491341710090637, 0.03213648498058319, 0.01872936636209488], [0.7887698411941528, 0.1823425590991974, 0.02888759970664978], [0.007083606906235218, 0.9728485941886902, 0.020067740231752396], [0.0061922501772642136, 0.9730779528617859, 0.020729780197143555], [0.9600358605384827, 0.020731929689645767, 0.019232127815485], [0.004979990888386965, 0.956104040145874, 0.038915958255529404], [0.8485241532325745, 0.005188026465475559, 0.14628784358501434], [0.0162192415446043, 0.9632723331451416, 0.02050841972231865], [0.010750241577625275, 0.0040279473178088665, 0.985221803188324], [0.9677228927612305, 0.008127792738378048, 0.02414928562939167], [0.0050416444428265095, 0.9496238827705383, 0.04533446580171585], [0.2836243510246277, 0.004008536692708731, 0.7123671174049377], [0.11344613134860992, 0.8570042848587036, 0.029549550265073776], [0.9681335687637329, 0.008127721957862377, 0.023738818243145943], [0.9694352746009827, 0.009674319997429848, 0.0208903755992651], [0.005139991175383329, 0.92978835105896, 0.06507165729999542], [0.4077678620815277, 0.004400772508233786, 0.5878313779830933], [0.007137758191674948, 0.9728425145149231, 0.0200197771191597], [0.9683521389961243, 0.012647392228245735, 0.019000457599759102], [0.9559402465820312, 0.006443455349653959, 0.037616338580846786], [0.906423807144165, 0.00539338169619441, 0.08818282186985016], [0.9686055183410645, 0.011862583458423615, 0.019531911239027977], [0.043052684515714645, 0.9319519996643066, 0.02499537728726864], [0.9665288329124451, 0.007667324505746365, 0.025803767144680023], [0.012525237165391445, 0.967574954032898, 0.01989978924393654], [0.958388090133667, 0.006541010458022356, 0.035070907324552536], [0.01576613262295723, 0.962895393371582, 0.021338414400815964], [0.9651050567626953, 0.007243625819683075, 0.02765130065381527], [0.1583327054977417, 0.003338288515806198, 0.8383289575576782], [0.004086419474333525, 0.042488470673561096, 0.9534251093864441], [0.6256782412528992, 0.33974456787109375, 0.03457722067832947], [0.9625548720359802, 0.019192682579159737, 0.018252454698085785], [0.965390682220459, 0.007579057477414608, 0.027030302211642265], [0.006346285808831453, 0.8456407189369202, 0.14801299571990967], [0.003721353132277727, 0.014089087024331093, 0.9821895360946655], [0.9110550880432129, 0.06704095751047134, 0.02190396375954151], [0.005053752567619085, 0.9634771347045898, 0.03146912902593613], [0.9606655836105347, 0.021181732416152954, 0.01815255917608738], [0.9386507272720337, 0.04191560670733452, 0.019433580338954926], [0.015880344435572624, 0.0028275763615965843, 0.9812920093536377], [0.9625933170318604, 0.01901823654770851, 0.018388506025075912], [0.005042268428951502, 0.9574851989746094, 0.03747258335351944], [0.8915621042251587, 0.08526480942964554, 0.023173101246356964], [0.9606106877326965, 0.02069891430437565, 0.018690310418605804], [0.010070953518152237, 0.004253370221704245, 0.9856756925582886], [0.0068417941220104694, 0.9724493622779846, 0.020708803087472916], [0.006012906786054373, 0.28155556321144104, 0.7124314904212952], [0.0058970204554498196, 0.9729356169700623, 0.021167360246181488], [0.007657795213162899, 0.9726096987724304, 0.019732486456632614], [0.8930010199546814, 0.0053347330540418625, 0.10166419297456741], [0.9141908288002014, 0.06421881914138794, 0.021590352058410645], [0.9622018933296204, 0.019639696925878525, 0.0181583259254694], [0.1806466430425644, 0.7854053378105164, 0.03394800424575806], [0.9448075294494629, 0.03631234169006348, 0.0188800897449255], [0.9628087282180786, 0.018734224140644073, 0.018457001075148582], [0.019106348976492882, 0.0025053531862795353, 0.978388249874115], [0.6315814256668091, 0.004888319876044989, 0.3635302484035492], [0.8642430305480957, 0.10951205343008041, 0.02624485455453396], [0.9664308428764343, 0.007675278931856155, 0.025893907994031906], [0.0042998599819839, 0.06656578928232193, 0.9291343688964844], [0.006390404887497425, 0.9731096625328064, 0.020499996840953827], [0.12391839176416397, 0.8439397215843201, 0.03214185684919357], [0.9682998061180115, 0.008826855570077896, 0.022873368114233017], [0.016489842906594276, 0.9629951119422913, 0.020515065640211105], [0.9689146280288696, 0.009447192773222923, 0.02163822017610073], [0.9633190035820007, 0.017945490777492523, 0.01873546652495861], [0.9392070770263672, 0.006117105018347502, 0.05467582494020462], [0.9691320061683655, 0.01078592985868454, 0.020082024857401848], [0.8979248404502869, 0.06755582988262177, 0.034519366919994354], [0.0036851256154477596, 0.014604703523218632, 0.9817101359367371], [0.016257409006357193, 0.9630836844444275, 0.02065897546708584], [0.968795895576477, 0.011316674761474133, 0.01988738775253296], [0.00638409610837698, 0.5138446688652039, 0.4797712564468384], [0.008326868526637554, 0.971994161605835, 0.019678916782140732], [0.006392935756593943, 0.003482720348984003, 0.9901242852210999], [0.005589673295617104, 0.004094479605555534, 0.990315854549408], [0.0199403315782547, 0.9591050744056702, 0.020954633131623268], [0.024868624284863472, 0.9535241723060608, 0.021607141941785812], [0.03161247447133064, 0.945794939994812, 0.022592557594180107], [0.006978951394557953, 0.003235661657527089, 0.989785373210907], [0.00802817102521658, 0.9720157980918884, 0.019956029951572418], [0.0037086752709001303, 0.011399402283132076, 0.9848918914794922], [0.9598125219345093, 0.021837851032614708, 0.018349692225456238], [0.010918879881501198, 0.9692521691322327, 0.019828930497169495], [0.9494253993034363, 0.030540117993950844, 0.020034464076161385], [0.03213644027709961, 0.9446505904197693, 0.023212913423776627], [0.005215313285589218, 0.9694050550460815, 0.025379635393619537], [0.004513932857662439, 0.005686895921826363, 0.9897991418838501], [0.006671925541013479, 0.0033177086152136326, 0.9900103211402893], [0.34716248512268066, 0.010518396273255348, 0.6423191428184509], [0.7477302551269531, 0.22126974165439606, 0.031000036746263504], [0.022147441282868385, 0.9564064145088196, 0.021446188911795616], [0.9493781924247742, 0.0317101776599884, 0.01891157031059265], [0.024014541879296303, 0.9541462063789368, 0.021839259192347527], [0.9687961339950562, 0.009653969667851925, 0.02154986746609211], [0.948502242565155, 0.006116737611591816, 0.04538101330399513], [0.005274249706417322, 0.8870524764060974, 0.1076732948422432], [0.9494293332099915, 0.03169446066021919, 0.018876226618885994], [0.9674366116523743, 0.01393094751983881, 0.018632400780916214], [0.018050387501716614, 0.9608092904090881, 0.021140284836292267], [0.9501964449882507, 0.03125036880373955, 0.018553225323557854], [0.9588847756385803, 0.006559709552675486, 0.03455553203821182], [0.9574043154716492, 0.006501887924969196, 0.036093879491090775], [0.01732931099832058, 0.9614976048469543, 0.02117306925356388], [0.0218418650329113, 0.9569950699806213, 0.02116306871175766], [0.6836875081062317, 0.27998629212379456, 0.03632621467113495], [0.0354992039501667, 0.9411953687667847, 0.02330542914569378], [0.8938019275665283, 0.08257290720939636, 0.023625249043107033], [0.004670316819101572, 0.004926726222038269, 0.9904029369354248], [0.8914761543273926, 0.05023564025759697, 0.05828817933797836], [0.15464501082897186, 0.8137683868408203, 0.031586598604917526], [0.010550658218562603, 0.9697585105895996, 0.01969079300761223], [0.006926069501787424, 0.9730052351951599, 0.020068740472197533], [0.9611214995384216, 0.0206881295889616, 0.01819034479558468], [0.3251577913761139, 0.6391811966896057, 0.03566101938486099], [0.004997598007321358, 0.9596975445747375, 0.03530487045645714], [0.006507035810500383, 0.9730344414710999, 0.020458444952964783], [0.9691305756568909, 0.00928047951310873, 0.021588969975709915], [0.9686394929885864, 0.01149917021393776, 0.019861340522766113], [0.9672774076461792, 0.013188938610255718, 0.0195335503667593], [0.0054170479997992516, 0.9717981219291687, 0.022784871980547905], [0.9606058597564697, 0.021227506920695305, 0.01816663332283497], [0.19403387606143951, 0.7729321718215942, 0.03303391486406326], [0.9437990784645081, 0.03703216463327408, 0.01916869916021824], [0.03133557736873627, 0.9462283849716187, 0.022436019033193588], [0.005556510295718908, 0.8402988910675049, 0.15414457023143768], [0.9658201932907104, 0.015557985752820969, 0.01862175762653351], [0.02155498042702675, 0.9572328925132751, 0.021212181076407433], [0.9215896129608154, 0.05745701864361763, 0.020953478291630745], [0.9654489159584045, 0.007287173066288233, 0.0272639449685812], [0.007370990235358477, 0.9727050065994263, 0.019924016669392586], [0.9206355214118958, 0.058404795825481415, 0.02095976285636425], [0.010724831372499466, 0.9677493572235107, 0.021525824442505836], [0.07460857927799225, 0.00273589207790792, 0.9226555228233337], [0.8510374426841736, 0.12302692234516144, 0.025935713201761246], [0.006036604288965464, 0.9730269312858582, 0.020936518907546997], [0.968837320804596, 0.011799212545156479, 0.019363390281796455], [0.08919055759906769, 0.8825942277908325, 0.028215177357196808], [0.026671389117836952, 0.9513852000236511, 0.02194337174296379], [0.8822219371795654, 0.005340683739632368, 0.11243738979101181], [0.9690631628036499, 0.009271718561649323, 0.021665098145604134], [0.9191442728042603, 0.05962638929486275, 0.021229267120361328], [0.9664694666862488, 0.015062904916703701, 0.01846756972372532], [0.969131588935852, 0.00990946963429451, 0.020959019660949707], [0.9688436985015869, 0.008607710711658001, 0.022548632696270943], [0.9462741613388062, 0.03488326072692871, 0.01884252205491066], [0.9689763188362122, 0.009838778525590897, 0.021184924989938736], [0.9619952440261841, 0.007127721328288317, 0.03087703511118889], [0.9650507569313049, 0.0166434645652771, 0.01830577850341797], [0.9683682322502136, 0.012554978020489216, 0.01907673105597496], [0.9533204436302185, 0.006290471646934748, 0.040389079600572586], [0.044780928641557693, 0.9310258626937866, 0.024193253368139267], [0.021156679838895798, 0.9578359127044678, 0.021007398143410683], [0.6341595649719238, 0.33120301365852356, 0.0346374437212944], [0.8889578580856323, 0.08752711862325668, 0.023515062406659126], [0.0038181201089173555, 0.02964501827955246, 0.966536819934845], [0.03965236246585846, 0.936768651008606, 0.023578980937600136], [0.9382306933403015, 0.005815417971462011, 0.05595384165644646], [0.9627149701118469, 0.01893751509487629, 0.01834750548005104], [0.004301013424992561, 0.07658885419368744, 0.919110119342804], [0.9660117030143738, 0.007415149360895157, 0.026573220267891884], [0.9490523338317871, 0.03190261498093605, 0.01904507540166378], [0.006739907432347536, 0.0034101600758731365, 0.9898499250411987], [0.0054140854626894, 0.9718616008758545, 0.022724337875843048], [0.9442249536514282, 0.036807361990213394, 0.018967675045132637], [0.9626401662826538, 0.0070325895212590694, 0.03032729960978031], [0.004129615146666765, 0.007453698664903641, 0.9884166121482849], [0.004192258697003126, 0.009963267482817173, 0.9858444929122925], [0.0052838874980807304, 0.9071131944656372, 0.08760294318199158], [0.0037571291904896498, 0.010677720420062542, 0.9855651259422302], [0.8783981204032898, 0.0971781462430954, 0.02442377433180809], [0.006335005629807711, 0.9728829264640808, 0.020782116800546646], [0.9527801275253296, 0.027861453592777252, 0.01935841701924801], [0.006105814129114151, 0.7367308139801025, 0.2571633756160736], [0.005857642274349928, 0.0036159974988549948, 0.9905264377593994], [0.9684232473373413, 0.008843058720231056, 0.022733641788363457], [0.9621437191963196, 0.00693017290905118, 0.03092603199183941], [0.9633180499076843, 0.007014913484454155, 0.029667027294635773], [0.9654197096824646, 0.016267230734229088, 0.018313096836209297], [0.9686408638954163, 0.011004195548593998, 0.020355017855763435], [0.934971809387207, 0.005775962024927139, 0.05925232172012329], [0.05459964647889137, 0.9203851222991943, 0.02501525916159153], [0.005181400571018457, 0.9691891074180603, 0.02562950737774372], [0.9569306373596191, 0.02418273314833641, 0.018886582925915718], [0.9430198669433594, 0.03459008410573006, 0.02239006944000721], [0.9666155576705933, 0.014877049252390862, 0.018507374450564384], [0.9552639126777649, 0.026348477229475975, 0.01838764362037182], [0.0120908347889781, 0.0027873211074620485, 0.9851218461990356], [0.969216525554657, 0.009289334528148174, 0.02149410918354988], [0.0050813378766179085, 0.9474485516548157, 0.047470156103372574], [0.007969770580530167, 0.9705233573913574, 0.021506890654563904], [0.006149263586848974, 0.9730277061462402, 0.02082299441099167], [0.006243100855499506, 0.45228311419487, 0.5414738059043884], [0.9657096862792969, 0.007532837335020304, 0.02675749361515045], [0.9591460824012756, 0.022303812205791473, 0.018550092354416847], [0.08035049587488174, 0.003150148317217827, 0.9164993762969971], [0.14452698826789856, 0.003325667232275009, 0.8521474003791809], [0.8984175324440002, 0.07898455113172531, 0.022597935050725937], [0.004180789925158024, 0.00664273276925087, 0.9891764521598816], [0.00513172522187233, 0.9630357623100281, 0.03183251991868019], [0.005282691679894924, 0.8944233655929565, 0.10029397159814835], [0.005181261338293552, 0.9657649397850037, 0.029053831472992897], [0.005937408655881882, 0.9708794355392456, 0.02318321354687214], [0.005120659247040749, 0.9645702242851257, 0.03030908666551113], [0.8334420323371887, 0.13917753100395203, 0.027380445972085], [0.014569981954991817, 0.9653167128562927, 0.020113248378038406], [0.00678878603503108, 0.965039849281311, 0.02817131206393242], [0.0265171118080616, 0.9516366720199585, 0.02184617519378662], [0.3499906063079834, 0.6097458600997925, 0.040263544768095016], [0.0036428694147616625, 0.014122345484793186, 0.9822348952293396], [0.01097765564918518, 0.9685797691345215, 0.020442597568035126], [0.0049422369338572025, 0.00450164033100009, 0.9905560612678528], [0.028926212340593338, 0.0043661873787641525, 0.9667075872421265], [0.005180651787668467, 0.963241457939148, 0.031577929854393005], [0.04143151640892029, 0.9348364472389221, 0.023732023313641548], [0.9647589325904846, 0.007797306403517723, 0.027443692088127136], [0.00548775726929307, 0.036596573889255524, 0.9579156041145325], [0.0066366964019834995, 0.9732192754745483, 0.020143995061516762], [0.010601622052490711, 0.9694693684577942, 0.019929055124521255]]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["ids, hards, softs = test_loop(inf_model, valid_dataloader)\n","hards = hards.tolist()\n","softs = softs.tolist()\n","print(ids)\n","print(hards)\n","print(softs)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["def mapper(value):\n","    match value:\n","        case 0:\n","            return 'NO'\n","        case 1:\n","            return 'DIRECT'\n","        case 2:\n","            return 'JUDGEMENTAL'"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["hard_path = inf_model_name + '_val_hard'\n","soft_path = inf_model_name + '_val_soft'"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["\n","hard_dicts = []\n","for identity, hard in zip(ids, hards):\n","    hard_dicts.append({\n","        'test_case': 'EXIST2024',\n","        'id': str(identity),\n","        'value': mapper(hard)\n","    })\n","with open(f'{hard_path}.json', 'w') as fp:\n","    json.dump(hard_dicts, fp)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["soft_dicts = []\n","for identity, soft in zip(ids, softs):\n","    soft_dicts.append({\n","        'test_case': 'EXIST2024',\n","        'id': str(identity),\n","        'value': {\n","            'DIRECT': soft[1],\n","            'NO': soft[0],\n","            'JUDGEMENTAL': soft[2],\n","        }\n","    })\n","with open(f'{soft_path}.json', 'w') as fp:\n","    json.dump(soft_dicts, fp)"]},{"cell_type":"markdown","metadata":{},"source":["# PyEvALL Test"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["class NpEncoder(json.JSONEncoder):\n","    def default(self, obj):\n","        if isinstance(obj, np.integer):\n","            return int(obj)\n","        if isinstance(obj, np.floating):\n","            return float(obj)\n","        if isinstance(obj, np.ndarray):\n","            return obj.tolist()\n","        return super(NpEncoder, self).default(obj)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-05-31 19:58:20,031 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure', 'Accuracy']\n","2024-05-31 19:58:20,111 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n","2024-05-31 19:58:20,284 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n","2024-05-31 19:58:20,284 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n","2024-05-31 19:58:20,457 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n","2024-05-31 19:58:20,627 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n","2024-05-31 19:58:20,792 - pyevall.metrics.metrics - INFO -             evaluate() - Executing accuracy evaluation method\n","cargado 24\n","This is a table PyEvALL report, so no warnings or errors are shown. Please, check the embedded report to check errors if any metric has the value \"-\" or is an empty value or table.\n","+----+---------------------------------------------------------+---------+------------+----------+----------+\n","|    | files                                                   |     ICM |   ICM-Norm |       F1 |      Acc |\n","|----+---------------------------------------------------------+---------+------------+----------+----------|\n","|  0 | openai-clip-vit-base-patch32_score_0.8345_val_hard.json | -1.1371 |   0.116434 | 0.352647 | 0.439878 |\n","+----+---------------------------------------------------------+---------+------------+----------+----------+\n","+----+-------------------------------------------------------------------+---------+------------+----------+----------+\n","|    | files                                                             |     ICM |   ICM-Norm |       F1 |      Acc |\n","|----+-------------------------------------------------------------------+---------+------------+----------+----------|\n","|  0 | openai-clip-vit-base-patch32_score_0.8345_val_hard.json_EXIST2024 | -1.1371 |   0.116434 | 0.352647 | 0.439878 |\n","+----+-------------------------------------------------------------------+---------+------------+----------+----------+\n","+----+-------------------------------------------------------------------+-------------+----------+------------------+\n","|    | files                                                             |   F1_DIRECT |    F1_NO |   F1_JUDGEMENTAL |\n","|----+-------------------------------------------------------------------+-------------+----------+------------------|\n","|  0 | openai-clip-vit-base-patch32_score_0.8345_val_hard.json_EXIST2024 |    0.399323 | 0.460342 |         0.198276 |\n","+----+-------------------------------------------------------------------+-------------+----------+------------------+\n"]}],"source":["from pyevall.evaluation import PyEvALLEvaluation\n","from pyevall.utils.utils import PyEvALLUtils\n","from pyevall.metrics.metricfactory import MetricFactory\n","\n","gold_hard = 'EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task5_gold_hard.json'\n","gold_soft = 'EXIST 2024 Lab/evaluation/golds/EXIST2024_training_task5_gold_soft.json'\n","\n","gold_val_hard = 'task5_val_hard_gold.json'\n","gold_val_soft = 'task5_val_soft_gold.json'\n","\n","gold_hard_df = pd.read_json(gold_hard)\n","gold_hard_df = gold_hard_df[gold_hard_df['id'].isin(X_val['id_EXIST'])]\n","gold_hard_df['id'] = gold_hard_df['id'].astype(str)\n","gold_hard_df.to_json(gold_val_hard, index=False, orient='records')\n","\n","gold_soft_df = pd.read_json(gold_soft)\n","gold_soft_df = gold_soft_df[gold_soft_df['id'].isin(X_val['id_EXIST'])]\n","gold_soft_df['id'] = gold_soft_df['id'].astype(str)\n","gold_soft_df.to_json(gold_val_soft, index=False, orient='records')\n","\n","predictions_hard = f'{hard_path}.json'\n","predictions_soft = f'{soft_path}.json'\n","\n","test = PyEvALLEvaluation()\n","metrics_hard=[MetricFactory.ICM.value, MetricFactory.ICMNorm.value, MetricFactory.FMeasure.value, MetricFactory.Accuracy.value]\n","metrics_soft=[MetricFactory.ICMSoft.value, MetricFactory.ICMSoftNorm.value, MetricFactory.CrossEntropy.value]\n","\n","params = {\n","    PyEvALLUtils.PARAM_FORMAT: PyEvALLUtils.PARAM_OPTION_FORMAT_JSON,\n","    PyEvALLUtils.PARAM_REPORT: PyEvALLUtils.PARAM_OPTION_REPORT_DATAFRAME\n","}\n","\n","report_hard = test.evaluate(predictions_hard, gold_val_hard, metrics_hard, **params)\n","with open(f'{hard_path}_results.json', 'w') as fp:\n","    json.dump(report_hard.report, fp, indent=4)\n","report_hard.print_report()\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-05-31 19:58:20,803 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICMSoft', 'ICMSoftNorm', 'CrossEntropy']\n","2024-05-31 19:58:20,994 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Soft evaluation method\n","2024-05-31 19:58:21,612 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM-Soft Normalized evaluation method\n","2024-05-31 19:58:21,614 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Soft evaluation method\n","2024-05-31 19:58:22,342 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Soft evaluation method\n","2024-05-31 19:58:22,870 - pyevall.metrics.metrics - INFO -             evaluate() - Executing Cross Entropy evaluation method\n","This is a table PyEvALL report, so no warnings or errors are shown. Please, check the embedded report to check errors if any metric has the value \"-\" or is an empty value or table.\n","+----+---------------------------------------------------------+------------+-----------------+--------+\n","|    | files                                                   |   ICM-Soft |   ICM-Soft-Norm |     CE |\n","|----+---------------------------------------------------------+------------+-----------------+--------|\n","|  0 | openai-clip-vit-base-patch32_score_0.8345_val_soft.json |   -7.08172 |               0 | 3.4415 |\n","+----+---------------------------------------------------------+------------+-----------------+--------+\n","+----+-------------------------------------------------------------------+------------+-----------------+--------+\n","|    | files                                                             |   ICM-Soft |   ICM-Soft-Norm |     CE |\n","|----+-------------------------------------------------------------------+------------+-----------------+--------|\n","|  0 | openai-clip-vit-base-patch32_score_0.8345_val_soft.json_EXIST2024 |   -7.08172 |               0 | 3.4415 |\n","+----+-------------------------------------------------------------------+------------+-----------------+--------+\n"]}],"source":["report_soft = test.evaluate(predictions_soft, gold_val_soft, metrics_soft, **params)\n","with open(f'{soft_path}_results.json', 'w') as fp:\n","    json.dump(report_soft.report, fp, indent=4)\n","report_soft.print_report()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4894786,"sourceId":8249731,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
